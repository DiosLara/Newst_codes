{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "from preparacion_datos.src.preparacion_inter_puntos import prep\n",
    "import glob\n",
    "import tqdm as tqdm\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "import warnings\n",
    "from shapely.geometry import shape\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=gpd.read_file(r'C:\\Users\\dlara\\Naucalpan_new_casas.shp')\n",
    "# terrenos=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\naucalpancompleto\\new_terreno1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predial=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PREDIAL (16022022).xlsx')\n",
    "adeudo=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PREDIALADEUDO (16022022).xlsx')\n",
    "propietario=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PROPIETARIO (16022022).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred= pd.read_csv(r'C:\\Users\\dlara\\Downloads\\Predial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoloc2.Valor_Catastral.calculo_predial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curts= gpd.read_file(r'C:\\Users\\dlara\\Downloads\\098 Naucalpan\\NAUCALPAN_PREDIOS.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=pd.read_csv(r'C:\\Users\\dlara\\BASE_MEJORADA_NAUCALPAN_URLS_v2.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df_to_gpd(df: pd.DataFrame,\n",
    "                    lon_col: str = 'INTFIS_RS_FD_LON_1',\n",
    "                    lat_col: str = 'INTFIS_RS_FD_LAT_1', crs= 'EPSG:4326'):\n",
    "        '''Transforma base a partir de dos columnas de latitud y longitud'''\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df,\n",
    "            geometry=gpd.points_from_xy(\n",
    "                df[lon_col], df[lat_col]\n",
    "            ),\n",
    "            crs=crs,\n",
    "        )\n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC['INTFIS_RS_FD_LAT']= NAUC['INTFIS_RS_FD_LAT_1'].combine_first(NAUC['INTFIS_RS_FD_LAT'])\n",
    "NAUC['INTFIS_RS_FD_LON']= NAUC['INTFIS_RS_FD_LON_1'].combine_first(NAUC['INTFIS_RS_FD_LON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=transform_df_to_gpd(NAUC, lon_col= 'INTFIS_RS_FD_LON',lat_col = 'INTFIS_RS_FD_LAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED= NAUC.loc[NAUC['CLAVECATASTRAL'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manzanas=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\Full manzanas\\Full manzanas\\Manzana_Naucalpan.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manzanas['geometry']=Manzanas.buffer(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manz=Manzanas.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=NAUC.to_crs(Manz.crs)\n",
    "def new_func(NAUC):\n",
    "    return gpd.sjoin(NAUC,Manz).drop(columns=['index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])\n",
    "\n",
    "rectificado_nauc=new_func(NAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curts=curts.to_crs(Manz.crs)\n",
    "curts_rectificado=gpd.sjoin(curts,Manz).drop(columns=['index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=casas.to_crs(Manz.crs)\n",
    "casas['ID']=casas.reset_index()['index']\n",
    "casas_rectificado=gpd.sjoin(casas,Manz).drop(columns=[\t'index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2poli(BASE):    \n",
    "    linestring=BASE.loc[(BASE[\"geometry\"].map(lambda y: isinstance(y,MultiPolygon))==False)&(BASE[\"geometry\"].map(lambda y: isinstance(y,Polygon))==False)].dissolve()\n",
    "\n",
    "    ARR=linestring.geometry.astype(str)\n",
    "    print(ARR)\n",
    "    if len(ARR)>0:\n",
    "        # print(ARR)\n",
    "        \n",
    "        # print(l1)\n",
    "        for i in range(len(ARR)):\n",
    "            try:\n",
    "                # print(ARR)\n",
    "                l1=ARR.str.find('POLYGON')\n",
    "                print(ARR)\n",
    "                list_wkt = ARR.str.replace(\"GEOMETRYCOLLECTION (POLYGON \",'')\n",
    "                # print(ARR,list_wkt)\n",
    "                list_wkt= [list_wkt+str('))')]\n",
    "                # print(list_wkt)\n",
    "                list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "                multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "                print(multi)\n",
    "                # print('multi', multi)\n",
    "                linestring['geometry'] = multi\n",
    "\n",
    "            except:\n",
    "                # print(ARR)\n",
    "                l1=ARR.str.find('LINESTRING')\n",
    "                # print(ARR.str[:l1])\n",
    "                list_wkt = ARR.str.replace(ARR.str[:l1],'').str.replace(\"GEOMETRYCOLLECTION (LINESTRING \",'')\n",
    "                list_wkt= [list_wkt+str('))')]\n",
    "                # print(list_wkt)\n",
    "                list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "                multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "                # print('multi', multi)\n",
    "                linestring['geometry'] = multi\n",
    "                \n",
    "            for col in dictt['cata']:\n",
    "                try:\n",
    "                    \n",
    "                    BASE=BASE[~BASE[col].isin(linestring[col])]\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            BASE = pd.concat([BASE,linestring])\n",
    "\n",
    "            return(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring=shps_merged.loc[(shps_merged[\"geometry\"].map(lambda y: isinstance(y,MultiPolygon))==False)&(shps_merged[\"geometry\"].map(lambda y: isinstance(y,Polygon))==False)].dissolve()\n",
    "\n",
    "ARR=linestring.geometry.astype(str)\n",
    "print(ARR)\n",
    "\n",
    "if len(ARR)>0:\n",
    "    # print(ARR)\n",
    "    \n",
    "    # print(l1)\n",
    "    for i in range(len(ARR)):\n",
    "        try:\n",
    "            # print(ARR)\n",
    "            l1=ARR.str.find('POLYGON')\n",
    "            print(ARR.str.replace(\"GEOMETRYCOLLECTION (POLYGON \",''))\n",
    "            list_wkt = ARR.str.replace(\"GEOMETRYCOLLECTION (POLYGON \",'')\n",
    "            # print(ARR,list_wkt)\n",
    "            list_wkt= [list_wkt+str('))')]\n",
    "            # print(list_wkt)\n",
    "            list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "            multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "            print(multi)\n",
    "            # print('multi', multi)\n",
    "            linestring['geometry'] = multi\n",
    "\n",
    "        except:\n",
    "            # print(ARR)\n",
    "            l1=ARR.str.find('LINESTRING')\n",
    "            # print(ARR.str[:l1])\n",
    "            list_wkt = ARR.str.replace(ARR.str[:l1],'').str.replace(\"GEOMETRYCOLLECTION (LINESTRING \",'')\n",
    "            list_wkt= [list_wkt+str('))')]\n",
    "            # print(list_wkt)\n",
    "            list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "            multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "            # print('multi', multi)\n",
    "            linestring['geometry'] = multi\n",
    "            \n",
    "        for col in dictt['cata']:\n",
    "            try:\n",
    "                \n",
    "                shps_merged=shps_merged[~shps_merged[col].isin(linestring[col])]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        shps_merged = pd.concat([shps_merged,linestring])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt= {'cata':['id_cat','cve_cat','CLAVECATAS','CLAVECATASTRAL_1','CLAVECATASTRAL_2']}\n",
    "dictt['cata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Insumos_municipios_en_proceso\\*\"\n",
    "filenames= glob.glob(path)\n",
    "for files in tqdm.tqdm(filenames):\n",
    "\n",
    "    shapes={}\n",
    "       \n",
    "    i=0\n",
    "    files=files.replace('\\\\',\"/\")\n",
    "    path2=files.replace('\\\\',\"/\").replace('/*',\"/\")\n",
    "    \n",
    "    for file in glob.glob(path2 + '/*.shp'):\n",
    "        file= file.replace('/',\"\\\\\")\n",
    "        name=file.replace(path2.replace('/',\"\\\\\"),'').replace('.shp',\"\").replace('\\\\',\"\") \n",
    "        i=i+1\n",
    "        Nname= name + str(i)\n",
    "    #   \n",
    "        shapes[Nname]=gpd.read_file(file)\n",
    "        \n",
    "        # print(Nname)\n",
    "        # reemplazar id cat por clave catastral\n",
    "        \n",
    "        for col in dictt['cata']:\n",
    "            shapes[Nname].rename(columns={col:'CLAVECATASTRAL'}, inplace=True)\n",
    "        #Disolución de las geometrías a partir de clavecatastral \n",
    "        shapes[Nname]=shapes[Nname].dissolve(by='CLAVECATASTRAL').reset_index()\n",
    "        \n",
    "        if shapes[Nname].crs == 4326:\n",
    "            pass\n",
    "        else:\n",
    "            shapes[Nname]=shapes[Nname].to_crs(4326)\n",
    "\n",
    "    lista= list(shapes.keys())       \n",
    "    for i in tqdm.tqdm(range(len(lista))):\n",
    "        # if  (Nname.casefold() in i.casefold()):\n",
    "        #     # print(Nname.casefold(), i.casefold())\n",
    "        #     if Nname.casefold() == i.casefold():\n",
    "                # print((Nname.casefold(), i.casefold()),)\n",
    "                # continue\n",
    "            # else:\n",
    "        \n",
    "        shps_merged= shapes[lista[i]]\n",
    "        shps_merged.crs= 4326\n",
    "        try:\n",
    "            shps_merged=shapes[lista[i+1]].overlay(shps_merged, how='union',keep_geom_type=False)\n",
    "            # print(shps_merged)\n",
    "            shps_merged= line2poli(shps_merged)\n",
    "\n",
    "        except:\n",
    "            # print(shapes[lista[i]].head())\n",
    "            shps_merged= line2poli(shapes[lista[i]])\n",
    "\n",
    "            # print(name)\n",
    "            # print(shps_merged)\n",
    "            shps_merged.to_file(r'C:/Users/dlara/Desktop/MUNICIPIOS/' + Nname + \"_cruce_shapes.shp\")\n",
    "            # else: \n",
    "            # print('error')  \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED=pd.read_csv(r'C:\\Users\\dlara\\Atlacomulco_puntos.csv', encoding='utf-8-sig')\n",
    "PRED['CLAVECATASTRAL']=PRED['CLAVECATASTRAL'].astype(str).str.replace('.0','', regex=False).str.zfill(16)\n",
    "# \n",
    "PRED[['CLAVECATASTRAL', 'LONGITUD','LATITUD','CURT_1', 'curt','geometry','min_dist']].dropna()\n",
    "\n",
    "# prep.transform_df_to_gpd(PRED, 'LONGITUD_1', 'LATITUD_1', 3857).to_crs(4326)\n",
    "\n",
    "PRED.drop_duplicates('geometry', inplace=True)\n",
    "PRED.dropna(axis=1, inplace=True)\n",
    "puntos=prep.transform_df_to_gpd(PRED, 'LONGITUD_1', 'LATITUD_1', 3857)\n",
    "puntos.dropna(axis=1, inplace=True)\n",
    "rev_pred=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\final\\final\\test_igecem_final.shp')\n",
    "\n",
    "UNICOS=rev_pred.loc[rev_pred['CURT_1']==1]\n",
    "nounicos=rev_pred.loc[rev_pred['CURT_1'].fillna(0)!=1]\n",
    "nounicos=nounicos.to_crs(3857)\n",
    "puntos=puntos.set_geometry('geometry')\n",
    "rev_pred=rev_pred.set_geometry('geometry')\n",
    "rev_pred.drop_duplicates('CLAVECATAS', keep='first', inplace=True)\n",
    "# from preparacion_datos.src.preparacion_inter_puntos import ckdnearest\n",
    "\n",
    "j_puntos=prep.ckdnearest(puntos, puntos[['geometry']])\n",
    "cruce_check= gpd.sjoin(nounicos.to_crs(3857),j_puntos.loc[j_puntos['min_dist_2']>30][['geometry', 'LONGITUD_1', 'LATITUD_1','min_dist']], how='right')\n",
    "\n",
    "cruce_check.to_file('C:/Users/dlara/Atlacomulco_predial_final_curts_reps.shp')\n",
    "UNICOS.to_file('C:/Users/dlara/Atlacomulco_predial_final_curts_unicos.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruce_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate(geo_data: np.ndarray # shape == (N, 4)\n",
    "        ) -> np.ndarray:             # deduplicated data with origin order\n",
    "    data = geo_data.reshape(-1, 2, 2)\n",
    "    dt = f'f{data.itemsize}' # f4 or f8\n",
    "    data = data.view([('x', dt), ('y', dt)]) \n",
    "    # eliminate differences\n",
    "    ixs = np.argsort(data, -2, order=('x', 'y'))\n",
    "    data_no_df = np.take_along_axis(data, ixs, axis=-2) # sorted by 'x' then by 'y'\n",
    "    # get unique\n",
    "    unique_sorted_data, uni_ixs = np.unique(data_no_df, True, axis=0)\n",
    "    uni_ixs.sort() # inplace sort 1d-array\n",
    "    data_deduplicated = geo_data[uni_ixs] # unique, originally ordered and shaped\n",
    "    return data_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points= cruce_check.geometry\n",
    "geoms = [shape(feat[\"geometry\"]) for feat in points ]\n",
    "list_arrays = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms ]\n",
    "result = deduplicate(list_arrays)\n",
    "final_result = [list(map(tuple, pair)) for pair in result.tolist()]\n",
    "pnts = [Point(pair) for pair in final_result]\n",
    "# cruce_check['geometry'] = pnts\n",
    "geometria=gpd.GeoSeries(pnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cruce_predial_adicionales():\n",
    "    filenames= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\*.csv\")\n",
    "\n",
    "    for path in tqdm.tqdm(filenames):\n",
    "        # filename= glob.glob(path)\n",
    "        puntos=pd.read_csv(path)\n",
    "        puntos= prep.transform_df_to_gpd(puntos, 'LONGITUD','LATITUD', 4326)\n",
    "        rev_pred=gpd.read_file(path[:path.find('_puntos.csv')] + '.shp')\n",
    "        rev_pred=rev_pred.to_crs(3857)\n",
    "        UNICOS=rev_pred.loc[rev_pred['CURT_1']==1]\n",
    "        nounicos=rev_pred.loc[rev_pred['CURT_1'].fillna(0)!=1]\n",
    "        \n",
    "        puntos=puntos.set_geometry('geometry')\n",
    "        rev_pred=rev_pred.set_geometry('geometry')\n",
    "        rev_pred.drop_duplicates('CLAVECATAS', keep='first', inplace=True)\n",
    "        j_puntos=prep.ckdnearest(puntos.to_crs(3857), puntos[['geometry']].to_crs(3857), k=2)\n",
    "        # print(nounicos, 'no unicos')\n",
    "        # print(nounicos.crs, 'no unicos crs')\n",
    "        # print(j_puntos, 'puntos')\n",
    "        # print(j_puntos.crs,'puntos crs')\n",
    "        # print(gpd.sjoin(nounicos,j_puntos.loc[j_puntos['min_dist_2']==0][['geometry', 'LONGITUD', 'LATITUD']]))\n",
    "        cruce_check= gpd.sjoin(nounicos,j_puntos.loc[j_puntos['min_dist_2']==0][['geometry', 'LONGITUD', 'LATITUD']])\n",
    "        # cruce_check=cruce_check.loc[cruce_check['CLAVECATASTRAL'].notna()]\n",
    "        cruce_check=cruce_check.groupby('geometry', as_index=False,sort=False).first().reset_index(drop=True)\n",
    "    #   cruce_check.loc[cruce_check['CLAVECATAS']=='0240127004000000'].plot()\n",
    "        file_name='Salidas'\n",
    "        name=path[path.rfind('\\\\')+1:path.rfind('_puntos')]\n",
    "        path12= os.path.join(path[:path.rfind('MUNICIPIOS')],'MUNICIPIOS' ,file_name)\n",
    "        # cruce_check.to_file(path12 + '\\\\' +name+  '_predial_final_curts_reps.shp')\n",
    "        # UNICOS.to_file(path12 + '\\\\' +name+ '_predial_final_curts_unicos.shp')\n",
    "        # final_pred= pd.concat([cruce_check, UNICOS])\n",
    "        filename2= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\*.shp\")\n",
    "        for path2 in filename2:\n",
    "            \n",
    "            if name in path2:\n",
    "                \n",
    "                cruces_ads=gpd.read_file(path2)\n",
    "                print(cruces_ads.crs)\n",
    "                name2=path2[path2.rfind('\\\\'+name)+1:path2.rfind('_cruces_todos')]\n",
    "            else:\n",
    "                print('El archivo aun no se encuentra en la carpeta')\n",
    "                break\n",
    "            # if cruces_ads.crs== 4326:\n",
    "            #     cruces_ads=cruces_ads.to_crs(3857)\n",
    "            # elif cruces_ads.crs == 3857:\n",
    "            #     continue           \n",
    "            # print(cruces_ads.columns)\n",
    "            ### el primero es fácil porque es directo, resultado: poli    \n",
    "            primero=gpd.sjoin(UNICOS,cruces_ads)\n",
    "            \n",
    "            ## diferenciando\n",
    "            temp1=cruces_ads.loc[~cruces_ads['CURT_f'].isin(primero['CURT_f'])]\n",
    "            ##cruce\n",
    "            drop=temp1.columns[(temp1.columns.str.contains('left|right'))]\n",
    "            temp1.drop(columns=drop, inplace=True)\n",
    "            drop=cruce_check.columns[(cruce_check.columns.str.contains('left|right'))]\n",
    "            cruce_check.drop(columns=drop, inplace=True)\n",
    "            segundo= gpd.sjoin(cruce_check,temp1)\n",
    "       \n",
    "            sobra_pred=cruce_check[~cruce_check.geometry.isin(segundo.geometry)]\n",
    "            real_ads= temp1.loc[~temp1['CURT_f'].isin(segundo['CURT_f'])]\n",
    "            sobra_pred['CAT_1']='FUERA'\n",
    "            primero['CAT_1']='PREDIAL_UNICOS'\n",
    "            segundo['CAT_1']= 'PREDIAL_REPETIDOS'\n",
    "            pred_final= pd.concat([primero, segundo,sobra_pred])\n",
    "            pred_final.dropna(how='all', axis=1, inplace=True)\n",
    "            drop=pred_final.columns[(pred_final.columns.str.contains('0|TYPES|TYPE|ADDRESS|PLUS_CODE|_GEO_|Unnamed'))]\n",
    "            pred_final.drop(columns=drop, inplace=True)\n",
    "            \n",
    "            pred_final.to_file(path12 + '\\\\' +name2+ 'base_final_predial_corregida.shp')\n",
    "            real_ads['CAT_1']= 'ADICIONALES'\n",
    "            base_final=pd.concat([pred_final, real_ads])\n",
    "            base_final.to_file(path12 + '\\\\' +name2+ 'base_final_ads_pred.shp')\n",
    "            return(base_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:3857\n"
     ]
    }
   ],
   "source": [
    "base_final=cruce_predial_adicionales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1076901742.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    base_final.to_file('C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas\\Ixtapan_base_final_ads_pred.shp')\u001b[0m\n\u001b[1;37m                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "base_final.to_file(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas\\Ixtapan_terrenos_base_final_ads_pred.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\*.shp\")\n",
    "for path2 in filename2:\n",
    "    print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=path[path.rfind('\\\\')+1:path.rfind('_puntos')]\n",
    "path12= os.path.join(path[:path.rfind('MUNICIPIOS')],'MUNICIPIOS' ,file_name)\n",
    "path2[path2.rfind(path12 + '\\\\' +name):path2.rfind('_cruces_todos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 + '\\\\' +name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0=pd.concat([m1,ADS_F,PRED_F, fin_casas], axis=0)\n",
    "# .drop_duplicates('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predial.loc[~predial['CLAVECATASTRAL'].isin(PRED['CLAVECATASTRAL'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancias mínimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "from geoloc2.preparacion_datos.src.preparacion_inter_puntos import ckdnearest\n",
    "gdf=gpd.read_file(\"C:/Users/ASUS/Desktop/qgiszonas/points.shp\")\n",
    "gdf[\"LATLON\"]=gdf[\"geometry\"].x.astype(\"str\")+\",\"+gdf[\"geometry\"].y.astype(\"str\")\n",
    "gdf\n",
    "\n",
    "\n",
    "# usar primero sjoin_nearest y si hay mucho fallo usar la función ckdnearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\casas_t_especificios_1.shp\")\n",
    "casas=casas.to_crs(gdf.crs)\n",
    "casas[\"LATLON\"]=casas[\"geometry\"].centroid.x.astype(\"str\")+\",\"+casas[\"geometry\"].centroid.y.astype(\"str\")\n",
    "casas[\"geometry1\"]=casas[\"geometry\"]\n",
    "casas[\"geometry\"]=casas[\"geometry\"].representative_point()\n",
    "casas=casas.reset_index()\n",
    "casas.rename(columns={\"index\":\"FID\"},inplace=True)\n",
    "casas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terreno=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\terreno_t_especificios_1.shp\")\n",
    "terreno=terreno.to_crs(gdf.crs)\n",
    "terreno[\"LATLON\"]=terreno[\"geometry\"].centroid.x.astype(\"str\")+\",\"+terreno[\"geometry\"].centroid.y.astype(\"str\")\n",
    "terreno[\"geometry1\"]=terreno[\"geometry\"]\n",
    "terreno[\"geometry\"]=terreno[\"geometry\"].representative_point()\n",
    "terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# JFF_c = JFF_c.loc[JFF_c['min_dist'] < 10]\n",
    "JFF_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFF_terreno = ckdnearest(gdf.drop(columns='LATLON').to_crs(3857), terreno.to_crs(3857))\n",
    "# JFF_terreno = JFF_terreno.loc[JFF_terreno['min_dist'] < 10]\n",
    "JFF_terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFF_c[\"origen\"]=\"Casas\"\n",
    "JFF_terreno[\"origen\"]=\"Terreno\"\n",
    "concatenado=pd.concat([JFF_c,JFF_terreno],ignore_index=True)\n",
    "concatenado.sort_values(by=\"min_dist\",inplace=True)\n",
    "concatenado=concatenado.drop_duplicates(subset=[\"CLAVECATAS\"],keep=\"first\")\n",
    "concatenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenado[[\"FID\",\"origen\",\"CLAVECATAS\",\"geometry\"]].to_crs(\"3857\").to_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\Puntos_cercanos.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=concatenado[[\"FID\",\"origen\",\"CLAVECATAS\",\"geometry1\"]]\n",
    "a=gpd.GeoDataFrame(a[[\"FID\",\"origen\",\"CLAVECATAS\"]],geometry=a[\"geometry1\"])\n",
    "a.crs=6364\n",
    "a=a.to_crs(\"3857\")\n",
    "a.to_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\Poligonos_cercanos.shp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N= pd.read_csv('E:\\Downloads\\INTFIS_BASE_FINAL_NAUCALPAN_por_coma\\INTFIS_BASE_FINAL_NAUCALPAN_por_coma.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED=N.loc[N['CLAVECATASTRAL_RECAUDACION'].notna()].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred= PRED.loc[PRED['CLAVECATASTRAL'].astype(str).str.startswith('00')].groupby(['CLAVECATASTRAL','BDINTERNA_CONT_NOMBRE_COMPLETO']).first().dropna(axis=1,how='all').drop(columns='Unnamed: 0').reset_index()\n",
    "# correct_pred['CLAVECATASTRAL']=correct_pred['CLAVECATASTRAL'].str[-12:].str.replace('000','', regex=False).str.zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred['CLAVECATASTRAL'].str[-16:]\n",
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00000'), 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00000')]['CLAVECATASTRAL'].str[-11:].str.zfill(12).str.replace('000','', regex=False).str.zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('000'),'CLAVECATASTRAL']=correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('000')]['CLAVECATASTRAL'].str[-16:].str.replace('000','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00'),'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00')]['CLAVECATASTRAL'].str[:12].str.replace('00','').str.zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()<9, 'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()<9]['CLAVECATASTRAL'] + '00000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==9, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==9]['CLAVECATASTRAL'] + '0000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==10, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==10]['CLAVECATASTRAL'].str.zfill(10) + '000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==12, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==12]['CLAVECATASTRAL'] + '0000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==13, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==13]['CLAVECATASTRAL'] + '000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==14, 'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==14]['CLAVECATASTRAL'] + '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==16, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==16]['CLAVECATASTRAL'].str[:-6].str.replace('098','98').str.ljust(15,fillchar='0').str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED=PRED.loc[~PRED['CLAVECATASTRAL'].astype(str).str.startswith('00')]\n",
    "PRED['CLAVECATASTRAL']=PRED['CLAVECATASTRAL'].str.replace('.0','', regex=False).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED=PRED.dropna(axis=1,how='all').drop(columns='Unnamed: 0')\n",
    "ZPRED=pd.concat([PRED,correct_pred ], axis=0)\n",
    "# ZPRED.CLAVECATASTRAL.value_counts()\n",
    "ZPRED.loc[ZPRED['CLAVECATASTRAL'].isna(), 'CLAVECATASTRAL'] =ZPRED.loc[ZPRED['CLAVECATASTRAL'].isna()]['CLAVECATASTRAL_RECAUDACION'].str.replace('CAT-','').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados=ZPRED.loc[ZPRED['CLAVECATASTRAL'].isin(ZPRED['CLAVECATASTRAL'][ZPRED['CLAVECATASTRAL'].duplicated()])].sort_values(by='CLAVECATASTRAL').groupby(['CLAVECATASTRAL','BDINTERNA_CONT_NOMBRE_COMPLETO']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZPRED=ZPRED.loc[~ZPRED['CLAVECATASTRAL'].isin(ZPRED['CLAVECATASTRAL'][ZPRED['CLAVECATASTRAL'].duplicated()])]\n",
    "ZZPRED= pd.concat([ZPRED,duplicados], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED['CLAVECATASTRAL_RECAUDACION'] = 'CAT-' + ZZPRED['CLAVECATASTRAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NF=pd.read_csv(r'C:\\Users\\dlara\\Downloads\\drive-download-20230607T215848Z-001\\BASE_MEJORADA_NAUCALPAN_URLS_v2.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFS=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\drive-download-20230607T215848Z-001\\BASE_MEJORADA_NAUCALPAN_URLS_v2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2=NF.loc[NF['CLAVECATASTRAL'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED.loc[ZZPRED['CLAVECATASTRAL']=='09807751100E0904']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2['CLAVECATASTRAL']=PRED2['CLAVECATASTRAL'].astype(str).str.replace('.0','', regex=False).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2['CLAVECATASTRAL_RECAUDACION'] = 'CAT-' + PRED2['CLAVECATASTRAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# denue=PRED2.columns[PRED2.columns.str.contains('DENUE')]\n",
    "# PRED2.drop(columns=denue,inplace=True)\n",
    "# drop1=PRED2.columns[(~PRED2.columns.isin(ZZPRED.columns)) & (PRED2.columns.str.contains('SAT|ESTATUS|NOMINA'))]\n",
    "# PRED2.drop(columns=drop1,inplace=True)\n",
    "\n",
    "drop2=PRED2.columns[(~PRED2.columns.isin(ZZPRED.columns)) & (PRED2.columns.str.contains('N_EXT|KEY|GRUPO_CONTROL|BDINTERNA|IMSS|CALLE|COLONIA|ADDRESS|PLUS_CODE|_GEO_|Unnamed'))]\n",
    "PRED2.drop(columns=drop2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2[['CLAVECATASTRAL','LATLON',  'CVEGEO',\n",
    "       'Tipo Polígono', 'ORIGEN', 'TIPO DE COORDENADA', 'CURT_NOTAS', 'IMPORTE_FEB',\n",
    "       'IMPORTE_MAR', 'ACTIVO', 'ACTIVIDAD_ECONOMICA', 'NUM_TRABAJADORES',\n",
    "       'RANGO_TRABAJADORES', 'CLASIFICACION_TRABAJADORES', 'ACTIVO2',\n",
    "       'CANTIDAD_ANIOS_ADEUDOS', 'ZONA_CATASTRAL', 'IMPORTE_FEB_X_ANIO',\n",
    "       'CLASIFICACION_VALORCATASTRAL', 'USO', 'INTFIS_RS_FD_COOR_RECAUDACION',\n",
    "       'INTFIS_RS_FD_ESTADO', 'INTFIS_RS_FD_PAIS', 'INTFIS_RS_FD_URLS',\n",
    "       'CONSECUTIVO', 'RFC', 'RFC_CONTEOS', 'INTFIS_RS_FD_FULL_DOM', 'ID_CAT',\n",
    "       'curt', 'DOMICILIO', 'NUM_EXT', 'NUM_INT', 'CP', 'CONST_DOM',\n",
    "       'DOM_UNICOS', 'PERSONA', 'VALORCATASTRAL_2008', 'VALORCATASTRAL_2009',\n",
    "       'VALORCATASTRAL_2010', 'VALORCATASTRAL_2011', 'VALORCATASTRAL_2012',\n",
    "       'VALORCATASTRAL_2013', 'VALORCATASTRAL_2014', 'VALORCATASTRAL_2015',\n",
    "       'PREDIAL_PROPIETARIO_EMAIL', 'PREDIAL_PROPIETARIO_CURP',\n",
    "       'PREDIAL_PROPIETARIO_RFC', 'IMPORTETOTAL_ACUMULATIVO_AGUA',\n",
    "       'CANTIDAD_NIS', 'NIS', 'CANTIDAD_CLAVES_CATASTRALES',\n",
    "       'CLAVES_CATASTRALES', 'INTFIS_RS_FD_LATLON','curt','CURT','INTFIS_RS_FD_LON', 'INTFIS_RS_FD_LAT','INTFIS_RS_FD_LON_1', 'INTFIS_RS_FD_LAT_1','INTFIS_RS_FD_LAT_2', 'INTFIS_RS_FD_LON_2', '0', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED.loc[~ZZPRED['CLAVECATASTRAL'].isin(PRED2['CLAVECATASTRAL'])]\n",
    "# PRED2.loc[~PRED2['CLAVECATASTRAL'].isin(ZZPRED['CLAVECATASTRAL'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
