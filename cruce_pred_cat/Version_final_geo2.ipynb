{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "from preparacion_datos.src.preparacion_inter_puntos import prep\n",
    "import glob\n",
    "import tqdm as tqdm\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "import warnings\n",
    "from shapely.geometry import shape\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from puntos_sobre_poligono.simulacion_interpolacion import task_chunks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=gpd.read_file(r'C:\\Users\\dlara\\Naucalpan_new_casas.shp')\n",
    "# terrenos=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\naucalpancompleto\\new_terreno1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predial=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PREDIAL (16022022).xlsx')\n",
    "adeudo=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PREDIALADEUDO (16022022).xlsx')\n",
    "propietario=pd.read_excel(r'C:\\Users\\dlara\\Downloads\\Recepcion de informacion-20230302T185018Z-001\\Recepcion de informacion\\Naucalpan de Juárez_PROPIETARIO (16022022).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred= pd.read_csv(r'C:\\Users\\dlara\\Downloads\\Predial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoloc2.Valor_Catastral.calculo_predial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curts= gpd.read_file(r'C:\\Users\\dlara\\Downloads\\098 Naucalpan\\NAUCALPAN_PREDIOS.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=pd.read_csv(r'C:\\Users\\dlara\\BASE_MEJORADA_NAUCALPAN_URLS_v2.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df_to_gpd(df: pd.DataFrame,\n",
    "                    lon_col: str = 'INTFIS_RS_FD_LON_1',\n",
    "                    lat_col: str = 'INTFIS_RS_FD_LAT_1', crs= 'EPSG:4326'):\n",
    "        '''Transforma base a partir de dos columnas de latitud y longitud'''\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df,\n",
    "            geometry=gpd.points_from_xy(\n",
    "                df[lon_col], df[lat_col]\n",
    "            ),\n",
    "            crs=crs,\n",
    "        )\n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC['INTFIS_RS_FD_LAT']= NAUC['INTFIS_RS_FD_LAT_1'].combine_first(NAUC['INTFIS_RS_FD_LAT'])\n",
    "NAUC['INTFIS_RS_FD_LON']= NAUC['INTFIS_RS_FD_LON_1'].combine_first(NAUC['INTFIS_RS_FD_LON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=transform_df_to_gpd(NAUC, lon_col= 'INTFIS_RS_FD_LON',lat_col = 'INTFIS_RS_FD_LAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED= NAUC.loc[NAUC['CLAVECATASTRAL'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manzanas=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\Full manzanas\\Full manzanas\\Manzana_Naucalpan.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manzanas['geometry']=Manzanas.buffer(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manz=Manzanas.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAUC=NAUC.to_crs(Manz.crs)\n",
    "def new_func(NAUC):\n",
    "    return gpd.sjoin(NAUC,Manz).drop(columns=['index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])\n",
    "\n",
    "rectificado_nauc=new_func(NAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curts=curts.to_crs(Manz.crs)\n",
    "curts_rectificado=gpd.sjoin(curts,Manz).drop(columns=['index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=casas.to_crs(Manz.crs)\n",
    "casas['ID']=casas.reset_index()['index']\n",
    "casas_rectificado=gpd.sjoin(casas,Manz).drop(columns=[\t'index_right',\t'mun',\t'zona',\t'manz',\t'cve_cat'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ARR=linestring.geometry.astype(str)\n",
    "    # print(ARR)\n",
    "    if len(ARR)>0:\n",
    "        # print(ARR)\n",
    "        \n",
    "        # print(l1)\n",
    "            try:\n",
    "                # print(ARR)\n",
    "                l1=ARR.str.rfind('POLYGON')\n",
    "                l1=int(l1)\n",
    "                # print(ARR)\n",
    "                list_wkt = ARR.str.replace(\"GEOMETRYCOLLECTION (\",'', regex=False).str.replace(\"LINESTRING \",'POLYGON ', regex=False)#.str.replace(\"POLYGON \",'', regex=False).str.replace(\"LINESTRING \",'', regex=False).str.replace('((','[', regex=False).str.replace('))',']', regex=False)\n",
    "                list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "                multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "                # print(multi)\n",
    "                # print('multi', multi)\n",
    "                linestring['geometry'] = multi\n",
    "\n",
    "\n",
    "            except:\n",
    "                # print(ARR)\n",
    "                l1=ARR.str.find('LINESTRING')\n",
    "                print(ARR.str[:l1])\n",
    "                list_wkt = ARR.str.replace(ARR.str[:l1],'').str.replace(\"GEOMETRYCOLLECTION (\",'').str.replace(\"LINESTRING \",'POLYGON ', regex=False)\n",
    "                list_wkt= [list_wkt+str('))')]\n",
    "                # print(list_wkt)\n",
    "                list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "                multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "                # print('multi', multi)\n",
    "                linestring['geometry'] = multi\n",
    "                \n",
    "            for col in dictt['cata']:\n",
    "                try:\n",
    "                    \n",
    "                    BASE=BASE[~BASE[col].isin(linestring[col])]\n",
    "                except:\n",
    "                    pass\n",
    "    return(BASE)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(linestring.columns) == dictt['cata'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2poli(BASE):    \n",
    "    linestring=BASE.loc[(BASE[\"geometry\"].map(lambda y: isinstance(y,MultiPolygon))==False)&(BASE[\"geometry\"].map(lambda y: isinstance(y,Polygon))==False)]\n",
    "    # print(BASE.plot(), '1')\n",
    "    linestring=linestring.explode()\n",
    "    \n",
    "    newpols=linestring.loc[(linestring[\"geometry\"].map(lambda y: isinstance(y,MultiPolygon))==True)|(linestring[\"geometry\"].map(lambda y: isinstance(y,Polygon))==True)]\n",
    "    # print(newpols.shape)\n",
    "    BASES=gpd.GeoDataFrame()\n",
    "    for col in dictt['cata']:\n",
    "        try:\n",
    "            BASE=BASE[~BASE[col].isin(linestring[col])]\n",
    "            # print(BASE.shape)\n",
    "            BASES=pd.concat([BASES, BASE])\n",
    "            # print(BASE.shape)\n",
    "            # print(BASE.plot(), '2')\n",
    "            # print(BASE)\n",
    "        except:\n",
    "            continue\n",
    "       \n",
    "        # print(final.shape)\n",
    "    print(BASES.plot())\n",
    "    return(pd.concat([BASES,newpols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring=shps_merged.loc[(shps_merged[\"geometry\"].map(lambda y: isinstance(y,MultiPolygon))==False)&(shps_merged[\"geometry\"].map(lambda y: isinstance(y,Polygon))==False)].dissolve()\n",
    "\n",
    "ARR=linestring.geometry.astype(str)\n",
    "print(ARR)\n",
    "\n",
    "if len(ARR)>0:\n",
    "    # print(ARR)\n",
    "    \n",
    "    # print(l1)\n",
    "    for i in range(len(ARR)):\n",
    "        try:\n",
    "            # print(ARR)\n",
    "            l1=ARR.str.find('POLYGON')\n",
    "            # print(ARR.str.replace(\"GEOMETRYCOLLECTION (POLYGON \",''))\n",
    "            list_wkt = ARR.str.replace(\"GEOMETRYCOLLECTION (POLYGON \",'')\n",
    "            # print(ARR,list_wkt)\n",
    "            list_wkt= [list_wkt+str('))')]\n",
    "            # print(list_wkt)\n",
    "            list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "            multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "            # print(multi)\n",
    "            # print('multi', multi)\n",
    "            linestring['geometry'] = multi\n",
    "\n",
    "        except:\n",
    "            # print(ARR)\n",
    "            l1=ARR.str.find('LINESTRING')\n",
    "            # print(ARR.str[:l1])\n",
    "            list_wkt = ARR.str.replace(ARR.str[:l1],'').str.replace(\"GEOMETRYCOLLECTION (LINESTRING \",'')\n",
    "            list_wkt= [list_wkt+str('))')]\n",
    "            # print(list_wkt)\n",
    "            list_polygons =  [shapely.wkt.loads(poly) for poly in list_wkt]\n",
    "            multi=shapely.geometry.MultiPolygon(list_polygons)\n",
    "            # print('multi', multi)\n",
    "            linestring['geometry'] = multi\n",
    "            \n",
    "        for col in dictt['cata']:\n",
    "            try:\n",
    "                \n",
    "                shps_merged=shps_merged[~shps_merged[col].isin(linestring[col])]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        shps_merged = pd.concat([shps_merged,linestring])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt= {'cata':['id_cat','cve_cat','CLAVECATAS','CLAVECATASTRAL_1','CLAVECATASTRAL_2']}\\n\",\n",
    "dictt['cata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Insumos_municipios_en_proceso\\*\"\n",
    "filenames= glob.glob(path)\n",
    "for files in tqdm.tqdm(filenames):\n",
    "\n",
    "    shapes={}\n",
    "       \n",
    "    i=0\n",
    "    files=files.replace('\\\\',\"/\")\n",
    "    path2=files.replace('\\\\',\"/\").replace('/*',\"/\")\n",
    "    \n",
    "    for file in glob.glob(path2 + '/*.shp'):\n",
    "        file= file.replace('/',\"\\\\\")\n",
    "        name=file.replace(path2.replace('/',\"\\\\\"),'').replace('.shp',\"\").replace('\\\\',\"\") \n",
    "        i=i+1\n",
    "        Nname= name + str(i)\n",
    "    #   \n",
    "        shapes[Nname]=gpd.read_file(file)\n",
    "        \n",
    "        # print(Nname)\n",
    "        # reemplazar id cat por clave catastral\n",
    "        \n",
    "        for col in dictt['cata']:\n",
    "            shapes[Nname].rename(columns={col:'CLAVECATASTRAL'}, inplace=True)\n",
    "        #Disolución de las geometrías a partir de clavecatastral \n",
    "        shapes[Nname]=shapes[Nname].dissolve(by='CLAVECATASTRAL').reset_index()\n",
    "        \n",
    "        if shapes[Nname].crs == 4326:\n",
    "            pass\n",
    "        else:\n",
    "            shapes[Nname]=shapes[Nname].to_crs(4326)\n",
    "\n",
    "        lista= list(shapes.keys())  \n",
    "        i=0     \n",
    "        shps_merged= shapes[lista[i]]\n",
    "        shps_merged.crs= 4326\n",
    "        if len(shapes)>1:\n",
    "            i=1\n",
    "            shps_merged=shapes[lista[i]].overlay(shps_merged, how='union',keep_geom_type=False)\n",
    "                # print(shps_merged)\n",
    "            # try:\n",
    "                # print(shps_merged.plot(),'1')\n",
    "                \n",
    "            shps_merged= line2poli(shps_merged)\n",
    "            # print(shps_merged.plot(),'2')\n",
    "            for i in shps_merged.columns:\n",
    "                if i != 'geometry':\n",
    "                    shps_merged[i]=shps_merged[i].astype(str)\n",
    "            shps_merged.reset_index(drop=True, inplace=True)\n",
    "            shps_merged.set_geometry('geometry').to_file(r'C:/Users/dlara/Desktop/MUNICIPIOS/IGECEM/' + Nname + \"_cruce_shapes.shp\")\n",
    "\n",
    "            # except:\n",
    "            #     print('except')\n",
    "            \n",
    "                # shps_merged= shapes[lista[0]]\n",
    "                # shps_merged=shps_merged.overlay(shapes[lista[i]], how='union',keep_geom_type=False)\n",
    "                \n",
    "                # shps_merged= line2poli(shps_merged)\n",
    "                # print(name)\n",
    "                # print(shps_merged)\n",
    "        else:\n",
    "            print('else')\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # shps_merged.reset_index(drop=True, inplace=True)\n",
    "        # print(r'C:/Users/dlara/Desktop/MUNICIPIOS/IGECEM/' + Nname +  str(i) + \"_cruce_shapes.shp\")\n",
    "        \n",
    "        # shps_merged.to_file(r'C:/Users/dlara/Desktop/MUNICIPIOS/IGECEM/' + Nname +  str(i) + \"_cruce_shapes.shp\")\n",
    "                # else: \n",
    "                # print('error')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_igecem=gpd.read_file(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\IGECEM\\predios_Ixtapan_Sal.1_cruce_shapes.shp')\n",
    "full_igecem.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED=pd.read_csv(r'C:\\Users\\dlara\\Atlacomulco_puntos.csv', encoding='utf-8-sig')\n",
    "PRED['CLAVECATASTRAL']=PRED['CLAVECATASTRAL'].astype(str).str.replace('.0','', regex=False).str.zfill(16)\n",
    "# \n",
    "PRED[['CLAVECATASTRAL', 'LONGITUD','LATITUD','CURT_1', 'curt','geometry','min_dist']].dropna()\n",
    "\n",
    "# prep.transform_df_to_gpd(PRED, 'LONGITUD_1', 'LATITUD_1', 3857).to_crs(4326)\n",
    "\n",
    "PRED.drop_duplicates('geometry', inplace=True)\n",
    "PRED.dropna(axis=1, inplace=True)\n",
    "puntos=prep.transform_df_to_gpd(PRED, 'LONGITUD_1', 'LATITUD_1', 3857)\n",
    "puntos.dropna(axis=1, inplace=True)\n",
    "rev_pred=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\final\\final\\test_igecem_final.shp')\n",
    "\n",
    "UNICOS=rev_pred.loc[rev_pred['CURT_1']==1]\n",
    "nounicos=rev_pred.loc[rev_pred['CURT_1'].fillna(0)!=1]\n",
    "nounicos=nounicos.to_crs(3857)\n",
    "puntos=puntos.set_geometry('geometry')\n",
    "rev_pred=rev_pred.set_geometry('geometry')\n",
    "rev_pred.drop_duplicates('CLAVECATAS', keep='first', inplace=True)\n",
    "# from preparacion_datos.src.preparacion_inter_puntos import ckdnearest\n",
    "\n",
    "j_puntos=prep.ckdnearest(puntos, puntos[['geometry']])\n",
    "cruce_check= gpd.sjoin(nounicos.to_crs(3857),j_puntos.loc[j_puntos['min_dist_2']>30][['geometry', 'LONGITUD_1', 'LATITUD_1','min_dist']], how='right')\n",
    "\n",
    "cruce_check.to_file('C:/Users/dlara/Atlacomulco_predial_final_curts_reps.shp')\n",
    "UNICOS.to_file('C:/Users/dlara/Atlacomulco_predial_final_curts_unicos.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruce_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate(geo_data: np.ndarray # shape == (N, 4)\n",
    "        ) -> np.ndarray:             # deduplicated data with origin order\n",
    "    data = geo_data.reshape(-1, 2, 2)\n",
    "    dt = f'f{data.itemsize}' # f4 or f8\n",
    "    data = data.view([('x', dt), ('y', dt)]) \n",
    "    # eliminate differences\n",
    "    ixs = np.argsort(data, -2, order=('x', 'y'))\n",
    "    data_no_df = np.take_along_axis(data, ixs, axis=-2) # sorted by 'x' then by 'y'\n",
    "    # get unique\n",
    "    unique_sorted_data, uni_ixs = np.unique(data_no_df, True, axis=0)\n",
    "    uni_ixs.sort() # inplace sort 1d-array\n",
    "    data_deduplicated = geo_data[uni_ixs] # unique, originally ordered and shaped\n",
    "    return data_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points= cruce_check.geometry\n",
    "geoms = [shape(feat[\"geometry\"]) for feat in points ]\n",
    "list_arrays = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms ]\n",
    "result = deduplicate(list_arrays)\n",
    "final_result = [list(map(tuple, pair)) for pair in result.tolist()]\n",
    "pnts = [Point(pair) for pair in final_result]\n",
    "# cruce_check['geometry'] = pnts\n",
    "geometria=gpd.GeoSeries(pnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1= pd.read_csv(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas\\Ixtapan_Base_predial_PREGEO.csv', encoding='utf-8-sig')\n",
    "rev_pred= gpd.read_file(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Ixtapan.shp').to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1= prep.transform_df_to_gpd(m1, 'LONGITUD','LATITUD', 4326)\n",
    "N1=m1.loc[(m1['LATITUD']==18)| (m1['LATITUD'].isna())]\n",
    "N2=m1.loc[(m1['LATITUD']!=18)| (m1['LATITUD'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pred['CLAVE_CATASTRAL']=rev_pred['cve_cat'].str[:-8]\n",
    "N1['CLAVE_CATASTRAL']=N1['CLAVE_CATASTRAL'].astype(str).str.zfill(10).str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.drop(columns='geometry', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm2=gpd.sjoin(rev_pred[['cve_cat','geometry']],N2.to_crs(3857).drop(columns='cve_cat'))\n",
    "nm1=pd.merge(N1.drop(columns='cve_cat'),rev_pred[['cve_cat','geometry','CLAVE_CATASTRAL']], on='CLAVE_CATASTRAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to create file C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas/C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\Ixtapan_casasbase_final_predial_corregida.shp: No error\n",
      "  0%|          | 0/2 [01:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"fiona\\ogrext.pyx\", line 1133, in fiona.ogrext.WritingSession.start\n",
      "  File \"fiona\\_err.pyx\", line 291, in fiona._err.exc_wrap_pointer\n",
      "fiona._err.CPLE_AppDefinedError: Failed to create file C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas/C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\Ixtapan_casasbase_final_predial_corregida.shp: No error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\dlara\\AppData\\Local\\Temp\\ipykernel_16724\\365799180.py\", line 94, in <module>\n",
      "    gpd.GeoDataFrame(pred_final, geometry='geometry', crs=3857).to_file(path12 + '/' +name2+ 'base_final_predial_corregida.shp')\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py\", line 1114, in to_file\n",
      "    _to_file(self, filename, driver, schema, index, **kwargs)\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py\", line 393, in _to_file\n",
      "    with fiona.open(\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\site-packages\\fiona\\env.py\", line 408, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\site-packages\\fiona\\__init__.py\", line 280, in open\n",
      "    c = Collection(path, mode, crs=crs, driver=driver, schema=this_schema,\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\site-packages\\fiona\\collection.py\", line 165, in __init__\n",
      "    self.session.start(self, **kwargs)\n",
      "  File \"fiona\\ogrext.pyx\", line 1141, in fiona.ogrext.WritingSession.start\n",
      "fiona.errors.DriverIOError: Failed to create file C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas/C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\Ixtapan_casasbase_final_predial_corregida.shp: No error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\dlara\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\inspect.py\", line 1006, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"c:\\Users\\dlara\\anaconda3\\lib\\inspect.py\", line 835, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "filenames= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\*.csv\")\n",
    "\n",
    "for path in tqdm.tqdm(filenames):\n",
    "    # filename= glob.glob(path)\n",
    "    puntos=pd.read_csv(path)\n",
    "    try:\n",
    "        puntos= prep.transform_df_to_gpd(puntos, 'LONGITUD_1','LATITUD_1', 3857)\n",
    "    except:\n",
    "        puntos= prep.transform_df_to_gpd(puntos, 'LONGITUD','LATITUD', 4326).to_crs(3857)\n",
    "    rev_pred=gpd.read_file(path[:path.find('_puntos.csv')] + '.shp')\n",
    "    rev_pred=rev_pred.to_crs(3857)\n",
    "    puntos=puntos.set_geometry('geometry')\n",
    "    rev_pred=rev_pred.set_geometry('geometry')\n",
    "    # puntos.drop_duplicates('CLAVECATASTRAL', keep='first', inplace=True)\n",
    "    puntos=puntos.groupby('geometry', sort=False, dropna=True).first().reset_index()\n",
    "    try:\n",
    "        UNICOS=puntos.loc[puntos['CURT_1']<=1]\n",
    "        \n",
    "        # UNICOS['geometry']=UNICOS.geometry.centroid\n",
    "        nounicos=puntos.loc[puntos['CURT_1']>1]\n",
    "    except:\n",
    "        UNICOS=puntos.loc[puntos['CURT']<=1]\n",
    "        nounicos=puntos.loc[puntos['CURT']>1]\n",
    "    j_puntos=prep.ckdnearest(nounicos, nounicos[['geometry']], k=2)\n",
    "    # print(nounicos, 'no unicos')\n",
    "    # print(nounicos.crs, 'no unicos crs')\n",
    "    # print(j_puntos, 'puntos')\n",
    "    # print(j_puntos.crs,'puntos crs')\n",
    "    # print(gpd.sjoin(nounicos,j_puntos.loc[j_puntos['min_dist_2']==0][['geometry', 'LONGITUD', 'LATITUD']]))\n",
    "    try:\n",
    "        cruce_check= gpd.sjoin(j_puntos.loc[j_puntos['min_dist_2']==0][['geometry', 'LONGITUD_1', 'LATITUD_1']],rev_pred, how='left')\n",
    "    except:\n",
    "       cruce_check= gpd.sjoin(j_puntos.loc[j_puntos['min_dist_2']==0][['geometry', 'LONGITUD', 'LATITUD']],rev_pred,how='left') \n",
    "    # cruce_check=cruce_check.loc[cruce_check['CLAVECATASTRAL'].notna()]\n",
    "    cruce_check=cruce_check.groupby('geometry', as_index=False,sort=False).first().reset_index(drop=True)\n",
    "#   cruce_check.loc[cruce_check['CLAVECATAS']=='0240127004000000'].plot()\n",
    "    file_name='Salidas'\n",
    "    name=path[path.rfind('\\\\')+1:path.rfind('_puntos')]\n",
    "    path12= os.path.join(path[:path.rfind('MUNICIPIOS')],'MUNICIPIOS' ,file_name)\n",
    "    # cruce_check.to_file(path12 + '\\\\' +name+  '_predial_final_curts_reps.shp')\n",
    "    # UNICOS.to_file(path12 + '\\\\' +name+ '_predial_final_curts_unicos.shp')\n",
    "    # final_pred= pd.concat([cruce_check, UNICOS])\n",
    "   \n",
    "    filename2= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\*.shp\")\n",
    "    for path2 in filename2:\n",
    "        \n",
    "        if 'Ixtapan' in path2:\n",
    "            \n",
    "            cruces_ads=gpd.read_file(path2)\n",
    "            print(cruces_ads.crs)\n",
    "            name2=path2[path2.rfind('\\\\'+name)+1:path2.rfind('_cruces_todos')]\n",
    "        else:\n",
    "            print('El archivo aun no se encuentra en la carpeta')\n",
    "            break\n",
    "        # if cruces_ads.crs== 4326:\n",
    "        #     cruces_ads=cruces_ads.to_crs(3857)\n",
    "        # elif cruces_ads.crs == 3857:\n",
    "        #     continue           \n",
    "        # print(cruces_ads.columns)\n",
    "        ### el primero es fácil porque es directo, resultado: poli \n",
    "        # gato   \n",
    "        drop=UNICOS.columns[(UNICOS.columns.str.contains('left|right'))]\n",
    "        UNICOS.drop(columns=drop, inplace=True)\n",
    "        drop=cruces_ads.columns[(cruces_ads.columns.str.contains('left|right'))]\n",
    "        cruces_ads.drop(columns=drop, inplace=True)\n",
    "        primero=gpd.sjoin(cruces_ads,UNICOS, how='left' )\n",
    "        \n",
    "        ## diferenciando\n",
    "        temp1=cruces_ads.loc[~cruces_ads['CURT_f'].isin(primero['CURT_f'])]\n",
    "        ##cruce\n",
    "        drop=temp1.columns[(temp1.columns.str.contains('left|right'))]\n",
    "        temp1.drop(columns=drop, inplace=True)\n",
    "        drop=cruce_check.columns[(cruce_check.columns.str.contains('left|right'))]\n",
    "        cruce_check.drop(columns=drop, inplace=True)\n",
    "        segundo= gpd.sjoin(temp1,cruce_check,how='left')\n",
    "    \n",
    "        sobra_pred=cruce_check[~cruce_check.geometry.isin(segundo.geometry)]\n",
    "        sobra_pred.geometry=sobra_pred.geometry.buffer(2)\n",
    "        real_ads= temp1.loc[~temp1['CURT_f'].isin(segundo['CURT_f'])]\n",
    "        sobra_pred['CAT_1']='FUERA'\n",
    "        primero['CAT_1']='PREDIAL_UNICOS'\n",
    "        segundo['CAT_1']= 'PREDIAL_REPETIDOS'\n",
    "        pred_final= pd.concat([primero, segundo,sobra_pred])\n",
    "        pred_final.dropna(how='all', axis=1, inplace=True)\n",
    "        drop=pred_final.columns[(pred_final.columns.str.contains('0|TYPES|TYPE|ADDRESS|PLUS_CODE|_GEO_|Unnamed'))]\n",
    "        pred_final.drop(columns=drop, inplace=True)\n",
    "        drop2=pred_final.columns[(pred_final.columns.str.contains(r'[()\\\"#/@;:<>{}`+=~|.!?,]'))]\n",
    "        pred_final.drop(columns=drop2, inplace=True)\n",
    "        # pred_final.columns=pred_final.columns.str.replace(r\"[()\\\"#/@;:<>{}`+=~|.!?,]\", '')\n",
    "        pred_final.rename(columns={'USO DE ÁREA HOMOGÉNEA':'USO DE AREA HOMOGENEA'}, inplace=True)\n",
    "        for i in pred_final.columns:\n",
    "            if i != 'geometry':\n",
    "                pred_final.loc[pred_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+'),i]=pred_final.loc[pred_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+')][i].astype(str).str.replace(r'[^A-Za-z0-9]+','')\n",
    "        gpd.GeoDataFrame(pred_final, geometry='geometry', crs=3857).to_file(path12 + '/' +name2+ 'base_final_predial_corregida.shp')\n",
    "        real_ads['CAT_1']= 'ADICIONALES'\n",
    "        base_final=pd.concat([pred_final, real_ads])\n",
    "        base_final.columns=base_final.columns.str.replace(r\"[()\\\"#/@;:<>{}`+=~|.!?,]\", '')\n",
    "        drop2=base_final.columns[(base_final.columns.str.contains(r'[()\\\"#/@;:<>{}`+=~|.!?,]'))]\n",
    "        base_final.drop(columns=drop2, inplace=True)\n",
    "        base_final.rename(columns={'USO DE ÁREA HOMOGÉNEA':'USO DE AREA HOMOGENEA'}, inplace=True)\n",
    "        for i in base_final.columns:\n",
    "            if i != 'geometry':\n",
    "                base_final.loc[base_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+')][i]=base_final.loc[base_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+')][i].astype(str).str.replace(r'[^A-Za-z0-9]+','')\n",
    "        \n",
    "        gpd.GeoDataFrame(base_final, geometry='geometry', crs=3857).to_file(path12 + '/' +name2+ 'base_final_ads_pred.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_points_catastro(path_base, path_shp, funcion):\n",
    "    \"\"\"\n",
    "        De la informacion que se obtiene, separa la lat y la lon, lo limpia y concatena, quita distancia menor entre ambos parametros.\n",
    "        Se genera una base total, se hace un proceso de diatancia minima para quitar los puntos que cruzan entre si.\n",
    "\n",
    "        Los chunks se obtienen a partir de los cores de la pc en que se ejecute este script\n",
    "    \"\"\"\n",
    "    if path_base == float('Nan'):\n",
    "        test_igecem = prep.data_prep_catastro(path_base, path_shp)\n",
    "        # print('test igecem es: ',test_igecem)\n",
    "    else:\n",
    "        m_igecem = gpd.read_file(path_shp) ##Lee desde shp\n",
    "        m_igecem.crs= 4326 #m_igecem.to_crs(4326)\n",
    "    try:\n",
    "        m_igecem = m_igecem.loc[~m_igecem['manz'].astype(str).str.endswith('000')]\n",
    "    except: \n",
    "        pass\n",
    "    test_igecem = m_igecem\n",
    "    prep.replace_columns(test_igecem)\n",
    "    test_igecem.drop(columns= test_igecem.columns[(test_igecem.columns.str.contains('index'))|(test_igecem.columns.duplicated())], inplace=True)\n",
    "    # print('test_igecem:  ',test_igecem.columns[test_igecem.columns.duplicated()])\n",
    "    # test_igecem_chunks =  np.array_split(test_igecem, 1) ##Aqui se especifica si se requiere un loc y los chunks\n",
    "    \n",
    "    # df_concat = pd.DataFrame()\n",
    "    \n",
    "    # with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    #     for df_chunk in tqdm(zip(executor.map(funcion, test_igecem_chunks)),total = len(test_igecem_chunks)):\n",
    "    #         df_concat = pd.concat([df_chunk[0],df_concat], axis=0)\n",
    "\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_final= gpd.read_file(r'C:\\Users\\dlara\\Downloads\\Atlacomulco_predial_Z\\Atlacomulco_predial_Z.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predial con simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DIRECCION', 'VALORTERRENO', 'VALORTERRENOCOMUN', 'VALORCONSTPROP',\n",
       "       'VALORCONSTCOMUN', 'SUPERFICIE', 'SUPERFICIETERRCOMUN',\n",
       "       'SUPERFICIECONST', 'SUPERFICIECONSTCOMUN', 'CLAVEANTERIOR', 'FECHAALTA',\n",
       "       'NOMBRE', 'APATERNO', 'AMATERNO', 'CLAVECP', 'CLAVEMUNICIPIO',\n",
       "       'CLAVEENTIDAD', 'CALLE', 'CLAVESTATUS', 'CLAVEASENTAMIENTO', 'EMAIL',\n",
       "       'CURP', 'ASENTAMIENTO_NR', 'CLAVECP_NR', 'EJERCICIO', 'CLAVEPERIODOINI',\n",
       "       'CLAVEPERIODOFIN', 'VALORCATASTRAL', 'STATUS', 'No. CONSECUTIVO',\n",
       "       'DOMICILIO', 'NOMBRE DEL PROPIETARIO', 'RFC', 'ESTATUS DE LA CLAVE',\n",
       "       'VALOR CATASTRAL', 'SUPERFICIE DE TERRENO', 'SUPERFICIE CONSTRUCCION',\n",
       "       'USO DE ÁREA HOMOGÉNEA', 'PERIODO DE RECAUDACION CORRIENTE REZAGO',\n",
       "       'PERIODO DE RECAUDACION CORRIENTE', 'EJERCICIO FISCAL',\n",
       "       'CLAVECATASTRAL', 'CLAVE_PREDIO', 'CLAVE_MZA', 'CLAVE_LOC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "FILEBROWSER_PATH = os.path.join(os.getenv('WINDIR'), 'explorer.exe')\n",
    "\n",
    "def explore(path):\n",
    "    # explorer would choke on forward slashes\n",
    "    path = os.path.normpath(path)\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        subprocess.run([FILEBROWSER_PATH, path])\n",
    "    elif os.path.isfile(path):\n",
    "        subprocess.run([FILEBROWSER_PATH, '/select,', path]).__dir__\n",
    "explore(\"C:/Users/dlara/Desktop/MUNICIPIOS/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *                   # importing all the widgets and modules from tkinter  \n",
    "from tkinter import messagebox as mb    # importing the messagebox module from tkinter  \n",
    "from tkinter import filedialog as fd    # importing the filedialog module from tkinter  \n",
    "import os                               # importing the os module  \n",
    "import shutil   \n",
    "# function to copy a file  \n",
    "def copyFile():  \n",
    "   # using the filedialog's askopenfilename() method to select the file  \n",
    "   fileToCopy = fd.askopenfilename(  \n",
    "      title = \"Select a file to copy\",  \n",
    "      filetypes=[(\"All files\", \"*.*\")]  \n",
    "      )  \n",
    "   # using the filedialog's askdirectory() method to select the directory  \n",
    "#    directoryToPaste = fd.askdirectory(title = \"Select the folder to paste the file\")  \n",
    "   return(fileToCopy)\n",
    "#    # using the try-except method  \n",
    "#    try:  \n",
    "#       # using the copy() method of the shutil module to  \n",
    "#       # paste the selected file to the desired directory  \n",
    "#       shutil.copy(fileToCopy, directoryToPaste)  \n",
    "#       # showing success message using the messagebox's showinfo() method  \n",
    "#       mb.showinfo(  \n",
    "#          title = \"File copied!\",  \n",
    "#          message = \"The selected file has been copied to the selected location.\"  \n",
    "#          )  \n",
    "#    except:  \n",
    "#       # using the showerror() method to display error  \n",
    "#       mb.showerror(  \n",
    "#          title = \"Error!\",  \n",
    "#          message = \"Selected file is unable to copy to the selected location. Please try again!\"  \n",
    "#          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/dlara/Desktop/MUNICIPIOS/Entradas/Ixtapan_casas_cruces_todos.shp'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copyFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puntos= pd.read_csv(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Ixtapan_puntos.csv')\n",
    "pred= pd.read_csv(r'C:\\Users\\dlara\\Downloads\\Ixtapan_crucexcurtxpredial\\Ixtapan_crucexcurtxpredial.csv', encoding='utf-8-sig')\n",
    "pred.dropna(subset=['CLAVECATASTRAL'],inplace=True)\n",
    "\n",
    "pred.loc[~(pred['CLAVECATASTRAL'].astype(str).str.startswith('0')),'CLAVECATASTRAL']=pred.loc[~(pred['CLAVECATASTRAL'].astype(str).str.startswith('0'))]['CLAVECATASTRAL'].astype(str).str[0:15].str.zfill(16)\n",
    "pred.loc[(pred['CLAVECATASTRAL'].str.len()<16)| (pred['CLAVECATASTRAL'].str.startswith('00')),'CLAVECATASTRAL']=pred.loc[pred['CLAVECATASTRAL'].str.len()<16]['CLAVECATASTRAL'].str.ljust(16,fillchar='0')\n",
    "curts=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\060 Ixtapan de la Sal-20230524T163957Z-001\\060 Ixtapan de la Sal\\predios_060.shp')\n",
    "manz=gpd.read_file(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Insumos_municipios_en_proceso\\Ixtapan_Sal\\2023 060 MZ.shp')\n",
    "manz=manz.to_crs(curts.crs)\n",
    "pred=pred[['DIRECCION',\n",
    "       'VALORTERRENO', 'VALORTERRENOCOMUN', 'VALORCONSTPROP',\n",
    "       'VALORCONSTCOMUN', 'SUPERFICIE', 'SUPERFICIETERRCOMUN',\n",
    "       'SUPERFICIECONST', 'SUPERFICIECONSTCOMUN', 'CLAVEANTERIOR', 'FECHAALTA',\n",
    "       'NOMBRE', 'APATERNO', 'AMATERNO', 'CLAVECP', 'CLAVEMUNICIPIO',\n",
    "       'CLAVEENTIDAD', 'CALLE', 'CLAVESTATUS', 'CLAVEASENTAMIENTO', 'EMAIL',\n",
    "       'CURP', 'ASENTAMIENTO_NR', 'CLAVECP_NR', 'EJERCICIO', 'CLAVEPERIODOINI',\n",
    "       'CLAVEPERIODOFIN', 'VALORCATASTRAL', 'STATUS', 'No. CONSECUTIVO',\n",
    "       'DOMICILIO', 'NOMBRE DEL PROPIETARIO', 'RFC', 'ESTATUS DE LA CLAVE',\n",
    "       'VALOR CATASTRAL', 'SUPERFICIE DE TERRENO', 'SUPERFICIE CONSTRUCCION',\n",
    "       'USO DE ÁREA HOMOGÉNEA', 'PERIODO DE RECAUDACION CORRIENTE REZAGO',\n",
    "       'PERIODO DE RECAUDACION CORRIENTE', 'EJERCICIO FISCAL', 'CLAVECATASTRAL']]\n",
    "pred=pred.sort_values('PERIODO DE RECAUDACION CORRIENTE', ascending=False).drop_duplicates(['CLAVECATASTRAL'])\n",
    "pred['CLAVECATASTRAL']=pred['CLAVECATASTRAL'].astype(str).str.zfill(16)\n",
    "pred['CLAVE_PREDIO']=pred['CLAVECATASTRAL'].str[0:10]+'000000'\n",
    "pred['CLAVE_MZA']=pred['CLAVECATASTRAL'].str[0:8]+'00000000'\n",
    "pred['CLAVE_LOC']=pred['CLAVECATASTRAL'].str[0:6]+'0000000000'\n",
    "pred['CLAVE_LOC']=pred['CLAVE_LOC'].str.zfill(16)\n",
    "pred['CLAVE_MZA']=pred['CLAVE_MZA'].str.zfill(16)\n",
    "m1=pd.merge(pred, curts,  left_on='CLAVECATASTRAL', right_on='id_cat')\n",
    "temp1= pred.loc[~pred['CLAVECATASTRAL'].isin(m1['CLAVECATASTRAL'])]\n",
    "m2=pd.merge(temp1, curts,  left_on='CLAVE_PREDIO', right_on='id_cat')\n",
    "temp2= pred.loc[(~pred['CLAVECATASTRAL'].isin(m1['CLAVECATASTRAL']))& (~pred['CLAVECATASTRAL'].isin(m2['CLAVECATASTRAL']))]\n",
    "m3=pd.merge(temp2,manz,  left_on='CLAVE_MZA', right_on='cve_cat')\n",
    "temp4= pred.loc[(~pred['CLAVECATASTRAL'].isin(m1['CLAVECATASTRAL']))& (~pred['CLAVECATASTRAL'].isin(m2['CLAVECATASTRAL']))& (~pred['CLAVECATASTRAL'].isin(m3['CLAVECATASTRAL']))]\n",
    "m4=pd.merge(temp4,manz,  left_on='CLAVE_LOC', right_on='cve_cat')\n",
    "pred_diff=pd.concat([m1,m2,m3])\n",
    "pred_diff=pred_diff.sort_values('CLAVECATASTRAL')[['CLAVECATASTRAL', 'CLAVE_PREDIO', 'CLAVE_MZA', 'CLAVE_LOC', 'cve_ent',\n",
    "       'cve_mun', 'cve_loc', 'id_cat', 'proceso', 'curt', 'notas', 'geometry',\n",
    "       'mun', 'zona', 'manz', 'cve_cat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_diff=gpd.GeoDataFrame(pred_diff, geometry='geometry', crs=4326)\n",
    "igecem=pred_diff.copy()\n",
    "\n",
    "pred_final=pd.concat([pred_diff,m4])\n",
    "pred_final=pred_final.sort_values('CLAVECATASTRAL')\n",
    "pred_final['LATITUD'].interpolate(method='nearest',limit_direction='backward', limit=2,inplace=True)\n",
    "pred_final['LONGITUD'].interpolate(method='nearest',limit_direction='backward', limit=2,inplace=True)\n",
    "pred_final=prep.transform_df_to_gpd(pred_final, 'LONGITUD','LATITUD')\n",
    "pred_final=pred_final[pred_final.columns[~pred_final.columns.str.contains('cve|id|mun|zona|manz')]]\n",
    "pred_final.columns=pred_final.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_igecem=igecem[['CLAVE_PREDIO', 'CLAVE_MZA', 'CLAVE_LOC',  'curt','geometry']].groupby(['geometry','CLAVE_MZA'], sort=False).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_igecem=test_igecem.merge(pred_final.groupby('CLAVE_PREDIO').count().reset_index().sort_values(by='CLAVECATASTRAL', ascending=False)[['CLAVECATASTRAL', 'CURT', 'CLAVE_PREDIO']].rename(columns={'CLAVECATASTRAL':'ESTIMADO'}), on ='CLAVE_PREDIO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_igecem=test_igecem.sort_values(by='ESTIMADO', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'puntos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     puntos\u001b[39m=\u001b[39m prep\u001b[39m.\u001b[39mtransform_df_to_gpd(puntos, \u001b[39m'\u001b[39m\u001b[39mLONGITUD_1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLATITUD_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3857\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'puntos' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     puntos\u001b[39m=\u001b[39m prep\u001b[39m.\u001b[39mtransform_df_to_gpd(puntos, \u001b[39m'\u001b[39m\u001b[39mLONGITUD_1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLATITUD_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3857\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     puntos\u001b[39m=\u001b[39m prep\u001b[39m.\u001b[39mtransform_df_to_gpd(puntos, \u001b[39m'\u001b[39m\u001b[39mLONGITUD\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLATITUD\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m4326\u001b[39m)\u001b[39m.\u001b[39mto_crs(\u001b[39m3857\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[39m# pred=gpd.read_file(path[:path.find('_puntos.csv')] + '.shp')\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# pred=pred.to_crs(3857)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m puntos\u001b[39m=\u001b[39mpuntos\u001b[39m.\u001b[39mset_geometry(\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'puntos' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    puntos= prep.transform_df_to_gpd(puntos, 'LONGITUD_1','LATITUD_1', 3857)\n",
    "except:\n",
    "    puntos= prep.transform_df_to_gpd(puntos, 'LONGITUD','LATITUD', 4326).to_crs(3857)\n",
    "    # pred=gpd.read_file(path[:path.find('_puntos.csv')] + '.shp')\n",
    "# pred=pred.to_crs(3857)\n",
    "puntos=puntos.set_geometry('geometry')\n",
    "# pred=pred.set_geometry('geometry')\n",
    "# # puntos.drop_duplicates('CLAVECATASTRAL', keep='first', inplace=True)\n",
    "# puntos=puntos.groupby('geometry', sort=False, dropna=True).first().reset_index()\n",
    "# try:\n",
    "#     UNICOS=puntos.loc[puntos['CURT_1']<=1]\n",
    "    \n",
    "#     # UNICOS['geometry']=UNICOS.geometry.centroid\n",
    "#     nounicos=puntos.loc[puntos['CURT_1']>1]\n",
    "# except:\n",
    "#     UNICOS=puntos.loc[(puntos['CURT']<=1)| (puntos['CURT'].isna())]\n",
    "#     nounicos=puntos.loc[puntos['CURT']>1]\n",
    "# j_puntos=prep.ckdnearest(nounicos, nounicos[['geometry']], k=2)\n",
    "# try:\n",
    "#     cruce_check= gpd.sjoin(j_puntos.loc[j_puntos['min_dist_2']>10][['geometry', 'LONGITUD_1', 'LATITUD_1']],pred, how='left')\n",
    "# except:\n",
    "#     cruce_check= gpd.sjoin(j_puntos.loc[j_puntos['min_dist_2']>10][['geometry', 'LONGITUD', 'LATITUD']],pred,how='left') \n",
    "# # cruce_check=cruce_check.loc[cruce_check['CLAVECATASTRAL'].notna()]\n",
    "# cruce_check=cruce_check.groupby('geometry', as_index=False,sort=False).first().reset_index(drop=True)\n",
    "# #   cruce_check.loc[cruce_check['CLAVECATAS']=='0240127004000000'].plot()\n",
    "# file_name='Salidas'\n",
    "# name=path[path.rfind('\\\\')+1:path.rfind('_puntos')]\n",
    "# path12= os.path.join(path[:path.rfind('MUNICIPIOS')],'MUNICIPIOS' ,file_name)\n",
    "# # cruce_check.to_file(path12 + '\\\\' +name+  '_predial_final_curts_reps.shp')\n",
    "# # UNICOS.to_file(path12 + '\\\\' +name+ '_predial_final_curts_unicos.shp')\n",
    "# # final_pred= pd.concat([cruce_check, UNICOS])\n",
    "\n",
    "# filename2= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\*.shp\")\n",
    "\n",
    "    \n",
    "# cruces_ads=ads_final\n",
    "# print(cruces_ads.crs)\n",
    "# name2=path2[path2.rfind('\\\\'+name)+1:path2.rfind('_cruces_todos')]\n",
    "\n",
    "# # if cruces_ads.crs== 4326:\n",
    "# #     cruces_ads=cruces_ads.to_crs(3857)\n",
    "# # elif cruces_ads.crs == 3857:\n",
    "# #     continue           \n",
    "# # print(cruces_ads.columns)\n",
    "# ### el primero es fácil porque es directo, resultado: poli \n",
    "# # gato   \n",
    "# drop=UNICOS.columns[(UNICOS.columns.str.contains('left|right'))]\n",
    "# UNICOS.drop(columns=drop, inplace=True)\n",
    "# drop=cruces_ads.columns[(cruces_ads.columns.str.contains('left|right'))]\n",
    "# cruces_ads.drop(columns=drop, inplace=True)\n",
    "# primero=gpd.sjoin(cruces_ads,UNICOS, how='left' )\n",
    "\n",
    "# ## diferenciando\n",
    "# temp1=cruces_ads.loc[~cruces_ads['CURT_f'].isin(primero['CURT_f'])]\n",
    "# ##cruce\n",
    "# drop=temp1.columns[(temp1.columns.str.contains('left|right'))]\n",
    "# temp1.drop(columns=drop, inplace=True)\n",
    "# drop=cruce_check.columns[(cruce_check.columns.str.contains('left|right'))]\n",
    "# cruce_check.drop(columns=drop, inplace=True)\n",
    "# segundo= gpd.sjoin(temp1,cruce_check,how='left')\n",
    "\n",
    "# sobra_pred=cruce_check[~cruce_check.geometry.isin(segundo.geometry)]\n",
    "# sobra_pred.geometry=sobra_pred.geometry.buffer(2)\n",
    "# real_ads= temp1.loc[~temp1['CURT_f'].isin(segundo['CURT_f'])]\n",
    "# sobra_pred['CAT_1']='FUERA'\n",
    "# primero['CAT_1']='PREDIAL_UNICOS'\n",
    "# segundo['CAT_1']= 'PREDIAL_REPETIDOS'\n",
    "# pred_final= pd.concat([primero, segundo,sobra_pred])\n",
    "# pred_final.dropna(how='all', axis=1, inplace=True)\n",
    "# drop=pred_final.columns[(pred_final.columns.str.contains('0|TYPES|TYPE|ADDRESS|PLUS_CODE|_GEO_|Unnamed'))]\n",
    "# pred_final.drop(columns=drop, inplace=True)\n",
    "# # drop2=pred_final.columns[(pred_final.columns.str.contains(r'[()\\\"#/@;:<>{}`+=~|.!?,]'))]\n",
    "# pred_final.drop(columns=drop2, inplace=True)\n",
    "# # pred_final.columns=pred_final.columns.str.replace(r\"[()\\\"#/@;:<>{}`+=~|.!?,]\", '')\n",
    "# pred_final.rename(columns={'USO DE ÁREA HOMOGÉNEA':'USO DE AREA HOMOGENEA'}, inplace=True)\n",
    "# # for i in pred_final.columns:\n",
    "# #     if i != 'geometry':\n",
    "#         # pred_final.loc[pred_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+'),i]=pred_final.loc[pred_final[i].astype(str).str.contains(r'[^A-Za-z0-9]+')][i].astype(str).str.replace(r'[^A-Za-z0-9]+','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteos=pred_final.groupby('CLAVE_PREDIO').count().reset_index().sort_values(by='CLAVECATASTRAL', ascending=False)[['CLAVECATASTRAL', 'CURT', 'CLAVE_PREDIO']].rename(columns={'CLAVECATASTRAL':'ESTIMADO'})\n",
    "unicos=conteos.loc[conteos['ESTIMADO']==1]\n",
    "pred_f_unicos=pred_final.loc[pred_final['CLAVE_PREDIO'].isin(unicos['CLAVE_PREDIO'])]\n",
    "pred_final.loc[~pred_final['CLAVECATASTRAL'].str.endswith('000000')]\n",
    "pred_final.rename(columns={'GEOMETRY':'geometry'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predial final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7116/7116 [13:39<00:00,  8.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df_concat=task_chunks(test_igecem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.loc[df_concat['ESTIMADO']!=1]\n",
    "pred_cruce=pred_final.loc[~pred_final['CLAVE_PREDIO'].isin(unicos['CLAVE_PREDIO'])]\n",
    "pred_cruce.rename(columns={'GEOMETRY':'geometry'}, inplace=True)\n",
    "pred_cruce=gpd.GeoDataFrame(pred_cruce, geometry='geometry',crs=4326)\n",
    "df_concat=df_concat[df_concat.columns[(~df_concat.columns.isin(pred_cruce.columns)) | (df_concat.columns.astype(str).str.contains('CLAVE_PREDIO|geometry'))]]\n",
    "\n",
    "mn1=pd.merge(pred_cruce.drop(columns=['geometry','CLAVE_PREDIO']),df_concat, left_on='CLAVECATASTRAL',right_on='CLAVE_PREDIO')\n",
    "tempn1= df_concat.loc[~df_concat['CLAVE_PREDIO'].isin(mn1['CLAVECATASTRAL'])]\n",
    "mn2=pd.merge(pred_cruce.drop(columns=['geometry']),tempn1, left_on='CLAVE_PREDIO',right_on='CLAVE_PREDIO')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dbfs: \n",
    "manzs= (las bases a nivel manzana) \n",
    "dbfs_final=(manzs con dbfs (nivel predio) como llave clave a nivel Manzana)\n",
    "\n",
    "\n",
    "CC= debe de tener 0 al inicio y no tener \".0\" al final, no debe tener más de un 0's al inicio\n",
    "m1: curts con dbfs_final como llave a nivel predio ** CLAVE_PREDIO: CC.str[0:10]+'000000'\n",
    "diferenciar las que no cruzan y cruzarlas a nivel manzana: CC.str[0:8]+'00000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn1=mn1.sort_values(by=['CLAVECATASTRAL','LONGITUD_1','LATITUD_1']).drop_duplicates(subset='CLAVECATASTRAL',keep='first')\n",
    "mn2=mn2.sort_values(by=['CLAVECATASTRAL','LONGITUD_1','LATITUD_1']).drop_duplicates(subset='CLAVECATASTRAL',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cruzado=pd.concat([mn1,mn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnm1=prep.ckdnearest(pred_cruce.loc[~pred_cruce['geometry'].is_empty].to_crs(3857),df_concat[['geometry','LATITUD_1','LONGITUD_1']])\n",
    "# nnm1.loc[nnm1['min_dist_2']<10]\n",
    "nnm1=nnm1.sort_values(by=['CLAVECATASTRAL','min_dist_2']).drop_duplicates(subset=['CLAVECATASTRAL'],keep='first')\n",
    "nnm1=nnm1.loc[~nnm1['CLAVECATASTRAL'].isin(pred_cruzado['CLAVECATASTRAL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final=pred_final.to_crs(3857)\n",
    "pred_cruzado_min=pd.concat([nnm1,pred_cruzado,pred_final.loc[pred_final['CLAVE_PREDIO'].isin(unicos['CLAVE_PREDIO'])]])\n",
    "pred_cruzado_min.columns[pred_cruzado_min.columns.astype(str).str.contains('CURT|curt')]\n",
    "\n",
    "pred_cruzado['CURT']=pred_cruzado['CURT'].fillna(float('Nan'))\n",
    "pred_cruzado['curt']=pred_cruzado['curt'].fillna(float('Nan'))\n",
    "if all(pred_cruzado['CURT'])==all(pred_cruzado['curt']):\n",
    "    pred_cruzado.drop(columns=['CURT'], inplace=True)\n",
    "    \n",
    "pred_cruzado_min.drop(columns=['index_left','dist',0,'NOTAS','PROCESO'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_cruzado_minx ads \n",
    "geometry: poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLAVECATASTRAL</th>\n",
       "      <th>CLAVE_PREDIO</th>\n",
       "      <th>CLAVE_MZA</th>\n",
       "      <th>CLAVE_LOC</th>\n",
       "      <th>PROCESO</th>\n",
       "      <th>CURT</th>\n",
       "      <th>NOTAS</th>\n",
       "      <th>geometry</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>...</th>\n",
       "      <th>USO DE ÁREA HOMOGÉNEA</th>\n",
       "      <th>PERIODO DE RECAUDACION CORRIENTE REZAGO</th>\n",
       "      <th>PERIODO DE RECAUDACION CORRIENTE</th>\n",
       "      <th>EJERCICIO FISCAL</th>\n",
       "      <th>LATITUD_1</th>\n",
       "      <th>LONGITUD_1</th>\n",
       "      <th>min_dist_2</th>\n",
       "      <th>ORDEN</th>\n",
       "      <th>curt</th>\n",
       "      <th>ESTIMADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0600101502010001</td>\n",
       "      <td>0600101502000000</td>\n",
       "      <td>0600101500000000</td>\n",
       "      <td>0600100000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11095699.208 2136816.123)</td>\n",
       "      <td>18.846024</td>\n",
       "      <td>-99.674362</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136820e+06</td>\n",
       "      <td>-1.109571e+07</td>\n",
       "      <td>8.494446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0600101502010002</td>\n",
       "      <td>0600101502000000</td>\n",
       "      <td>0600101500000000</td>\n",
       "      <td>0600100000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11095699.208 2136816.123)</td>\n",
       "      <td>18.846024</td>\n",
       "      <td>-99.674362</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136820e+06</td>\n",
       "      <td>-1.109571e+07</td>\n",
       "      <td>8.494446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0600101502010003</td>\n",
       "      <td>0600101502000000</td>\n",
       "      <td>0600101500000000</td>\n",
       "      <td>0600100000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11095699.208 2136816.123)</td>\n",
       "      <td>18.846024</td>\n",
       "      <td>-99.674362</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136820e+06</td>\n",
       "      <td>-1.109571e+07</td>\n",
       "      <td>8.494446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0600101502010004</td>\n",
       "      <td>0600101502000000</td>\n",
       "      <td>0600101500000000</td>\n",
       "      <td>0600100000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11095699.208 2136816.123)</td>\n",
       "      <td>18.846024</td>\n",
       "      <td>-99.674362</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136820e+06</td>\n",
       "      <td>-1.109571e+07</td>\n",
       "      <td>8.494446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0600101502010005</td>\n",
       "      <td>0600101502000000</td>\n",
       "      <td>0600101500000000</td>\n",
       "      <td>0600100000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11095699.208 2136816.123)</td>\n",
       "      <td>18.846024</td>\n",
       "      <td>-99.674362</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136820e+06</td>\n",
       "      <td>-1.109571e+07</td>\n",
       "      <td>8.494446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>0600913504000000</td>\n",
       "      <td>0600913504000000</td>\n",
       "      <td>0600913500000000</td>\n",
       "      <td>0600910000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11098909.976 2129730.240)</td>\n",
       "      <td>18.785772</td>\n",
       "      <td>-99.703205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>0600913506000000</td>\n",
       "      <td>0600913506000000</td>\n",
       "      <td>0600913500000000</td>\n",
       "      <td>0600910000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11098909.976 2129730.240)</td>\n",
       "      <td>18.785772</td>\n",
       "      <td>-99.703205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7058</th>\n",
       "      <td>0600913507000000</td>\n",
       "      <td>0600913507000000</td>\n",
       "      <td>0600913500000000</td>\n",
       "      <td>0600910000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11098909.976 2129730.240)</td>\n",
       "      <td>18.785772</td>\n",
       "      <td>-99.703205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>0600913508000000</td>\n",
       "      <td>0600913508000000</td>\n",
       "      <td>0600913500000000</td>\n",
       "      <td>0600910000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11098909.976 2129730.240)</td>\n",
       "      <td>18.785772</td>\n",
       "      <td>-99.703205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056</th>\n",
       "      <td>0600913509000000</td>\n",
       "      <td>0600913509000000</td>\n",
       "      <td>0600913500000000</td>\n",
       "      <td>0600910000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-11098909.976 2129730.240)</td>\n",
       "      <td>18.785772</td>\n",
       "      <td>-99.703205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22635 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CLAVECATASTRAL      CLAVE_PREDIO         CLAVE_MZA         CLAVE_LOC  \\\n",
       "0     0600101502010001  0600101502000000  0600101500000000  0600100000000000   \n",
       "1     0600101502010002  0600101502000000  0600101500000000  0600100000000000   \n",
       "2     0600101502010003  0600101502000000  0600101500000000  0600100000000000   \n",
       "3     0600101502010004  0600101502000000  0600101500000000  0600100000000000   \n",
       "4     0600101502010005  0600101502000000  0600101500000000  0600100000000000   \n",
       "...                ...               ...               ...               ...   \n",
       "7061  0600913504000000  0600913504000000  0600913500000000  0600910000000000   \n",
       "7060  0600913506000000  0600913506000000  0600913500000000  0600910000000000   \n",
       "7058  0600913507000000  0600913507000000  0600913500000000  0600910000000000   \n",
       "7057  0600913508000000  0600913508000000  0600913500000000  0600910000000000   \n",
       "7056  0600913509000000  0600913509000000  0600913500000000  0600910000000000   \n",
       "\n",
       "     PROCESO CURT NOTAS                           geometry    LATITUD  \\\n",
       "0        NaN  NaN   NaN  POINT (-11095699.208 2136816.123)  18.846024   \n",
       "1        NaN  NaN   NaN  POINT (-11095699.208 2136816.123)  18.846024   \n",
       "2        NaN  NaN   NaN  POINT (-11095699.208 2136816.123)  18.846024   \n",
       "3        NaN  NaN   NaN  POINT (-11095699.208 2136816.123)  18.846024   \n",
       "4        NaN  NaN   NaN  POINT (-11095699.208 2136816.123)  18.846024   \n",
       "...      ...  ...   ...                                ...        ...   \n",
       "7061     NaN  NaN   NaN  POINT (-11098909.976 2129730.240)  18.785772   \n",
       "7060     NaN  NaN   NaN  POINT (-11098909.976 2129730.240)  18.785772   \n",
       "7058     NaN  NaN   NaN  POINT (-11098909.976 2129730.240)  18.785772   \n",
       "7057     NaN  NaN   NaN  POINT (-11098909.976 2129730.240)  18.785772   \n",
       "7056     NaN  NaN   NaN  POINT (-11098909.976 2129730.240)  18.785772   \n",
       "\n",
       "       LONGITUD  ... USO DE ÁREA HOMOGÉNEA  \\\n",
       "0    -99.674362  ...                   NaN   \n",
       "1    -99.674362  ...                   NaN   \n",
       "2    -99.674362  ...                   NaN   \n",
       "3    -99.674362  ...                   NaN   \n",
       "4    -99.674362  ...                   NaN   \n",
       "...         ...  ...                   ...   \n",
       "7061 -99.703205  ...                   NaN   \n",
       "7060 -99.703205  ...                   NaN   \n",
       "7058 -99.703205  ...                   NaN   \n",
       "7057 -99.703205  ...                   NaN   \n",
       "7056 -99.703205  ...                   NaN   \n",
       "\n",
       "      PERIODO DE RECAUDACION CORRIENTE REZAGO  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "7061                                      NaN   \n",
       "7060                                      NaN   \n",
       "7058                                      NaN   \n",
       "7057                                      NaN   \n",
       "7056                                      NaN   \n",
       "\n",
       "      PERIODO DE RECAUDACION CORRIENTE  EJERCICIO FISCAL     LATITUD_1  \\\n",
       "0                                  NaN               NaN  2.136820e+06   \n",
       "1                                  NaN               NaN  2.136820e+06   \n",
       "2                                  NaN               NaN  2.136820e+06   \n",
       "3                                  NaN               NaN  2.136820e+06   \n",
       "4                                  NaN               NaN  2.136820e+06   \n",
       "...                                ...               ...           ...   \n",
       "7061                               NaN               NaN           NaN   \n",
       "7060                               NaN               NaN           NaN   \n",
       "7058                               NaN               NaN           NaN   \n",
       "7057                               NaN               NaN           NaN   \n",
       "7056                               NaN               NaN           NaN   \n",
       "\n",
       "        LONGITUD_1  min_dist_2  ORDEN  curt  ESTIMADO  \n",
       "0    -1.109571e+07    8.494446    NaN   NaN       NaN  \n",
       "1    -1.109571e+07    8.494446    NaN   NaN       NaN  \n",
       "2    -1.109571e+07    8.494446    NaN   NaN       NaN  \n",
       "3    -1.109571e+07    8.494446    NaN   NaN       NaN  \n",
       "4    -1.109571e+07    8.494446    NaN   NaN       NaN  \n",
       "...            ...         ...    ...   ...       ...  \n",
       "7061           NaN         NaN    NaN   NaN       NaN  \n",
       "7060           NaN         NaN    NaN   NaN       NaN  \n",
       "7058           NaN         NaN    NaN   NaN       NaN  \n",
       "7057           NaN         NaN    NaN   NaN       NaN  \n",
       "7056           NaN         NaN    NaN   NaN       NaN  \n",
       "\n",
       "[22635 rows x 57 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cruzado_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cruzado_min=gpd.GeoDataFrame(pred_cruzado_min, geometry='geometry')\n",
    "pred_cruzado_min.to_csv('C:/Users/dlara/Ixtapan_predial_final.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99690976.90385129"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_final.columns[pred_final.columns.str.contains('SUPER|VALOR|area|LS|LI')]\n",
    "pred_final[['LI_95%_vc_', 'LS_95%_vc_', 'LI_95%_v_1', 'LS_95%_v_1', 'LS_95%_cat',\n",
    "       'LI_95%_cat', 'PredialLI_', 'PredialLS_', 'VALORCATASTRAL',\n",
    "       'VALOR CATASTRAL',\n",
    "       'VALORCATAS']].dropna(how='all', axis=1).sort_values('VALORCATASTRAL')\n",
    "pred_final['diff']=pred_final['LI_95%_vc_']-pred_final['VALORCATASTRAL']\n",
    "pred_final['diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\Atlacomulco_predial_Z\\Atlacomulco_predial_Z.shp')\n",
    "ix['coordenada']=ix.geometry.to_crs(4326).centroid\n",
    "# ix.columns[~ix.columns.str.contains('factor|Estadist|ID|Predial|LI|LS|Media|Moda|STD|Len|Min|Max|media|min|max|Pmedia|Valor_ca')]\n",
    "# t=ix[['CURT_f','clase_dete',\n",
    "#        'Clase', 'Z', 'Area_Model', 'COD','COD_BV', 'COD_AH', 'Val m2_Ban',\n",
    "#        'Tipo_consA', 'Frente', 'Fondo', 'Area_AH', 'Val m2_Man',  'UsoSuelo', 'VU_Terr', 'Tipo','Min_constr','Min_terren','Predialmin','geometry','coordenada']]\n",
    "\n",
    "t=ix[['CURT_f', 'clase_dete', 'Clase', 'Area_Model', 'Induxcasa', 'tipoCenCom',\n",
    "       'tipo_asent', 'nombre_act', 'Area_use','COD_BV',\n",
    "       'COD_AH', 'Val m2_Ban', 'Tipo_consA', 'Frente', 'Fondo', 'Area_AH',\n",
    "       'Val m2_Man','Val_m2_AH_', 'COD_Manz', \n",
    "       'VU_Terr', 'Z', 'Tipo','Min_constr','Min_terren','geometry','Predialmin','coordenada']]\n",
    "# sum(ix['Min_constr']==0)\n",
    "# t.info()\n",
    "t['coordenada']=t['coordenada'].astype(str).str.replace('POINT', '')\n",
    "# t.columns[t.columns.duplicated()]\n",
    "t.to_file(r'C:\\Users\\dlara\\Base_Adicionales_Valor_Catastral_Atlaco.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28982511663.039375"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_final['VALORCATASTRAL'].sum()+pred_final['VALOR CATASTRAL'].sum()-pred_final['minVC'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67711647.51311669"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_final.loc[ads_final['curt']=='3']['PredialLI_'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pred_t=pd.read_csv(r'C:\\Users\\dlara\\Downloads\\Ixtapan_Base_predial_PREGEO.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final=cruce_predial_adicionales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.to_file(r'C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Salidas\\Ixtapan_terrenos_base_final_ads_pred.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2= glob.glob(r\"C:\\Users\\dlara\\Desktop\\MUNICIPIOS\\Entradas\\*.shp\")\n",
    "for path2 in filename2:\n",
    "    print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=path[path.rfind('\\\\')+1:path.rfind('_puntos')]\n",
    "path12= os.path.join(path[:path.rfind('MUNICIPIOS')],'MUNICIPIOS' ,file_name)\n",
    "path2[path2.rfind(path12 + '\\\\' +name):path2.rfind('_cruces_todos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0=pd.concat([m1,ADS_F,PRED_F, fin_casas], axis=0)\n",
    "# .drop_duplicates('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predial.loc[~predial['CLAVECATASTRAL'].isin(PRED['CLAVECATASTRAL'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancias mínimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "from geoloc2.preparacion_datos.src.preparacion_inter_puntos import ckdnearest\n",
    "gdf=gpd.read_file(\"C:/Users/ASUS/Desktop/qgiszonas/points.shp\")\n",
    "gdf[\"LATLON\"]=gdf[\"geometry\"].x.astype(\"str\")+\",\"+gdf[\"geometry\"].y.astype(\"str\")\n",
    "gdf\n",
    "\n",
    "\n",
    "# usar primero sjoin_nearest y si hay mucho fallo usar la función ckdnearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casas=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\casas_t_especificios_1.shp\")\n",
    "casas=casas.to_crs(gdf.crs)\n",
    "casas[\"LATLON\"]=casas[\"geometry\"].centroid.x.astype(\"str\")+\",\"+casas[\"geometry\"].centroid.y.astype(\"str\")\n",
    "casas[\"geometry1\"]=casas[\"geometry\"]\n",
    "casas[\"geometry\"]=casas[\"geometry\"].representative_point()\n",
    "casas=casas.reset_index()\n",
    "casas.rename(columns={\"index\":\"FID\"},inplace=True)\n",
    "casas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terreno=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\terreno_t_especificios_1.shp\")\n",
    "terreno=terreno.to_crs(gdf.crs)\n",
    "terreno[\"LATLON\"]=terreno[\"geometry\"].centroid.x.astype(\"str\")+\",\"+terreno[\"geometry\"].centroid.y.astype(\"str\")\n",
    "terreno[\"geometry1\"]=terreno[\"geometry\"]\n",
    "terreno[\"geometry\"]=terreno[\"geometry\"].representative_point()\n",
    "terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# JFF_c = JFF_c.loc[JFF_c['min_dist'] < 10]\n",
    "JFF_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFF_terreno = ckdnearest(gdf.drop(columns='LATLON').to_crs(3857), terreno.to_crs(3857))\n",
    "# JFF_terreno = JFF_terreno.loc[JFF_terreno['min_dist'] < 10]\n",
    "JFF_terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFF_c[\"origen\"]=\"Casas\"\n",
    "JFF_terreno[\"origen\"]=\"Terreno\"\n",
    "concatenado=pd.concat([JFF_c,JFF_terreno],ignore_index=True)\n",
    "concatenado.sort_values(by=\"min_dist\",inplace=True)\n",
    "concatenado=concatenado.drop_duplicates(subset=[\"CLAVECATAS\"],keep=\"first\")\n",
    "concatenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenado[[\"FID\",\"origen\",\"CLAVECATAS\",\"geometry\"]].to_crs(\"3857\").to_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\Puntos_cercanos.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=concatenado[[\"FID\",\"origen\",\"CLAVECATAS\",\"geometry1\"]]\n",
    "a=gpd.GeoDataFrame(a[[\"FID\",\"origen\",\"CLAVECATAS\"]],geometry=a[\"geometry1\"])\n",
    "a.crs=6364\n",
    "a=a.to_crs(\"3857\")\n",
    "a.to_file(r\"C:\\Users\\ASUS\\Desktop\\qgiszonas\\salida\\Poligonos_cercanos.shp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N= pd.read_csv('E:\\Downloads\\INTFIS_BASE_FINAL_NAUCALPAN_por_coma\\INTFIS_BASE_FINAL_NAUCALPAN_por_coma.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED=N.loc[N['CLAVECATASTRAL_RECAUDACION'].notna()].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred= PRED.loc[PRED['CLAVECATASTRAL'].astype(str).str.startswith('00')].groupby(['CLAVECATASTRAL','BDINTERNA_CONT_NOMBRE_COMPLETO']).first().dropna(axis=1,how='all').drop(columns='Unnamed: 0').reset_index()\n",
    "# correct_pred['CLAVECATASTRAL']=correct_pred['CLAVECATASTRAL'].str[-12:].str.replace('000','', regex=False).str.zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred['CLAVECATASTRAL'].str[-16:]\n",
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00000'), 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00000')]['CLAVECATASTRAL'].str[-11:].str.zfill(12).str.replace('000','', regex=False).str.zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('000'),'CLAVECATASTRAL']=correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('000')]['CLAVECATASTRAL'].str[-16:].str.replace('000','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00'),'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].astype(str).str.startswith('00')]['CLAVECATASTRAL'].str[:12].str.replace('00','').str.zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()<9, 'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()<9]['CLAVECATASTRAL'] + '00000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==9, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==9]['CLAVECATASTRAL'] + '0000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==10, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==10]['CLAVECATASTRAL'].str.zfill(10) + '000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==12, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==12]['CLAVECATASTRAL'] + '0000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==13, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==13]['CLAVECATASTRAL'] + '000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==14, 'CLAVECATASTRAL'] = correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==14]['CLAVECATASTRAL'] + '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==16, 'CLAVECATASTRAL']= correct_pred.loc[correct_pred['CLAVECATASTRAL'].str.len()==16]['CLAVECATASTRAL'].str[:-6].str.replace('098','98').str.ljust(15,fillchar='0').str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED=PRED.loc[~PRED['CLAVECATASTRAL'].astype(str).str.startswith('00')]\n",
    "PRED['CLAVECATASTRAL']=PRED['CLAVECATASTRAL'].str.replace('.0','', regex=False).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED=PRED.dropna(axis=1,how='all').drop(columns='Unnamed: 0')\n",
    "ZPRED=pd.concat([PRED,correct_pred ], axis=0)\n",
    "# ZPRED.CLAVECATASTRAL.value_counts()\n",
    "ZPRED.loc[ZPRED['CLAVECATASTRAL'].isna(), 'CLAVECATASTRAL'] =ZPRED.loc[ZPRED['CLAVECATASTRAL'].isna()]['CLAVECATASTRAL_RECAUDACION'].str.replace('CAT-','').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados=ZPRED.loc[ZPRED['CLAVECATASTRAL'].isin(ZPRED['CLAVECATASTRAL'][ZPRED['CLAVECATASTRAL'].duplicated()])].sort_values(by='CLAVECATASTRAL').groupby(['CLAVECATASTRAL','BDINTERNA_CONT_NOMBRE_COMPLETO']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZPRED=ZPRED.loc[~ZPRED['CLAVECATASTRAL'].isin(ZPRED['CLAVECATASTRAL'][ZPRED['CLAVECATASTRAL'].duplicated()])]\n",
    "ZZPRED= pd.concat([ZPRED,duplicados], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED['CLAVECATASTRAL_RECAUDACION'] = 'CAT-' + ZZPRED['CLAVECATASTRAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NF=pd.read_csv(r'C:\\Users\\dlara\\Downloads\\drive-download-20230607T215848Z-001\\BASE_MEJORADA_NAUCALPAN_URLS_v2.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFS=gpd.read_file(r'C:\\Users\\dlara\\Downloads\\drive-download-20230607T215848Z-001\\BASE_MEJORADA_NAUCALPAN_URLS_v2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2=NF.loc[NF['CLAVECATASTRAL'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED.loc[ZZPRED['CLAVECATASTRAL']=='09807751100E0904']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2['CLAVECATASTRAL']=PRED2['CLAVECATASTRAL'].astype(str).str.replace('.0','', regex=False).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2['CLAVECATASTRAL_RECAUDACION'] = 'CAT-' + PRED2['CLAVECATASTRAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# denue=PRED2.columns[PRED2.columns.str.contains('DENUE')]\n",
    "# PRED2.drop(columns=denue,inplace=True)\n",
    "# drop1=PRED2.columns[(~PRED2.columns.isin(ZZPRED.columns)) & (PRED2.columns.str.contains('SAT|ESTATUS|NOMINA'))]\n",
    "# PRED2.drop(columns=drop1,inplace=True)\n",
    "\n",
    "drop2=PRED2.columns[(~PRED2.columns.isin(ZZPRED.columns)) & (PRED2.columns.str.contains('N_EXT|KEY|GRUPO_CONTROL|BDINTERNA|IMSS|CALLE|COLONIA|ADDRESS|PLUS_CODE|_GEO_|Unnamed'))]\n",
    "PRED2.drop(columns=drop2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED2[['CLAVECATASTRAL','LATLON',  'CVEGEO',\n",
    "       'Tipo Polígono', 'ORIGEN', 'TIPO DE COORDENADA', 'CURT_NOTAS', 'IMPORTE_FEB',\n",
    "       'IMPORTE_MAR', 'ACTIVO', 'ACTIVIDAD_ECONOMICA', 'NUM_TRABAJADORES',\n",
    "       'RANGO_TRABAJADORES', 'CLASIFICACION_TRABAJADORES', 'ACTIVO2',\n",
    "       'CANTIDAD_ANIOS_ADEUDOS', 'ZONA_CATASTRAL', 'IMPORTE_FEB_X_ANIO',\n",
    "       'CLASIFICACION_VALORCATASTRAL', 'USO', 'INTFIS_RS_FD_COOR_RECAUDACION',\n",
    "       'INTFIS_RS_FD_ESTADO', 'INTFIS_RS_FD_PAIS', 'INTFIS_RS_FD_URLS',\n",
    "       'CONSECUTIVO', 'RFC', 'RFC_CONTEOS', 'INTFIS_RS_FD_FULL_DOM', 'ID_CAT',\n",
    "       'curt', 'DOMICILIO', 'NUM_EXT', 'NUM_INT', 'CP', 'CONST_DOM',\n",
    "       'DOM_UNICOS', 'PERSONA', 'VALORCATASTRAL_2008', 'VALORCATASTRAL_2009',\n",
    "       'VALORCATASTRAL_2010', 'VALORCATASTRAL_2011', 'VALORCATASTRAL_2012',\n",
    "       'VALORCATASTRAL_2013', 'VALORCATASTRAL_2014', 'VALORCATASTRAL_2015',\n",
    "       'PREDIAL_PROPIETARIO_EMAIL', 'PREDIAL_PROPIETARIO_CURP',\n",
    "       'PREDIAL_PROPIETARIO_RFC', 'IMPORTETOTAL_ACUMULATIVO_AGUA',\n",
    "       'CANTIDAD_NIS', 'NIS', 'CANTIDAD_CLAVES_CATASTRALES',\n",
    "       'CLAVES_CATASTRALES', 'INTFIS_RS_FD_LATLON','curt','CURT','INTFIS_RS_FD_LON', 'INTFIS_RS_FD_LAT','INTFIS_RS_FD_LON_1', 'INTFIS_RS_FD_LAT_1','INTFIS_RS_FD_LAT_2', 'INTFIS_RS_FD_LON_2', '0', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZPRED.loc[~ZZPRED['CLAVECATASTRAL'].isin(PRED2['CLAVECATASTRAL'])]\n",
    "# PRED2.loc[~PRED2['CLAVECATASTRAL'].isin(ZZPRED['CLAVECATASTRAL'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
