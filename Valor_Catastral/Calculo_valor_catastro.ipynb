{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon,mapping,LineString, Point\n",
    "import math\n",
    "import tqdm\n",
    "import sqlite3\n",
    "from calculo_predial import *\n",
    "from Valor_catastral_construccion import *\n",
    "from Valor_catastral_terreno import *\n",
    "from Herramientas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "# Modelo IA\n",
    "path_modelo_casas = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Ixtapan_Sal_casas.shp'\n",
    "# Manzanas del municipio\n",
    "path_manzanas     = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Manzana_Ixtapan_Sal.shp'\n",
    "# Cruce de valores unitarios vs Manzana\n",
    "#path_vu_and_mz    = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Valores_Unitarios_con_Manzanas_Naucalpan.shp'\n",
    "# Valores unitarios\n",
    "path_sql          ='Data/Valores_Unitarios_2022_v2'\n",
    "# shape 15m \n",
    "path_info = '/home/hector/Documentos/Infis/Geo/Data/Shapes/15m/15m.shp'\n",
    "# path de chinchetas\n",
    "path_chinchetas = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/chinchetas_limpieza1/Centro_chinchetas_limpieza1.shp'\n",
    "# ruta a dnue\n",
    "path_dnue = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Dnue/DENUE_EDOMEX_2022.shp'\n",
    "# Lista de afirmaciones en minisculas\n",
    "afirmativo = np.array(['si','1',1,'yes','claro','obvio','of course','sip','sipi','neta','ok'])\n",
    "# Municipio a procesar\n",
    "municipio = 'Ixtapan_de_la_sal'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar valores de SQL\n",
    "\n",
    "conexion = sqlite3.connect(path_sql)\n",
    "df_area = pd.read_sql(f'''\n",
    "SELECT Zona,Manzanas,COD,Tipo,Frente,Fondo,Area as Area_AH,[Val m2],\n",
    "        Pseudo_clave_cat, Municipio\n",
    "FROM area_homogenea\t\n",
    "WHERE Municipio = '{municipio}'\n",
    "    ''', conexion)\n",
    "df_banda = pd.read_sql(f'''\n",
    "SELECT [Tipo calle], [Nombre Calle], [Zona], [Manzanas], COD,\n",
    "       [Val m2], Pseudo_clave_cat, Municipio\n",
    "FROM banda_valores\n",
    "WHERE Municipio = '{municipio}'\n",
    "''', conexion)\n",
    "\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir formato del val m2 en ambas\n",
    "df_area['Val m2'] = df_area['Val m2'].map(lambda x: corregir_formato(str(x)))\n",
    "df_banda['Val m2'] = df_banda['Val m2'].map(lambda x: corregir_formato(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar que tenemos el municipio adecuado\n",
    "df_area['Municipio'].value_counts(), df_banda['Municipio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos duplicados\n",
    "print('Shape inicial de Area_H ', df_area.shape)\n",
    "print('Shape inicial de bandaV ', df_banda.shape)\n",
    "df_area.drop_duplicates(subset=['Zona', 'Manzanas', 'COD', 'Tipo', 'Frente', 'Fondo', 'Area_AH',\n",
    "       'Val m2', 'Pseudo_clave_cat'],\n",
    "       inplace=True)\n",
    "df_banda.drop_duplicates(subset=['Tipo calle', 'Nombre Calle', 'Zona', 'Manzanas', 'COD', 'Val m2',\n",
    "       'Pseudo_clave_cat'], inplace=True)\n",
    "print('Shape Final de Area_H ', df_area.shape)\n",
    "print('Shape Final de bandaV ', df_banda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el shape de manzanas para analisis\n",
    "shape = gpd.read_file(path_manzanas)\n",
    "shape=shape.to_crs(\"3857\")\n",
    "shape['key'] = shape['cve_cat'].map(lambda x: str(x)[:8])\n",
    "shape['Lon'] = shape['geometry'].centroid.x\n",
    "shape['Lat'] = shape['geometry'].centroid.y\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape de Area Homo= {df_area.shape}')\n",
    "print(f'Shape de Banda    = {df_banda.shape}')\n",
    "print(f'Shape de Manzanas = {shape.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_banda[~df_banda[\"Manzanas\"].isin(df_area[\"Manzanas\"])][\"Manzanas\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce area_h vs Mzs\n",
    "cruce1 = df_area.merge(shape, \n",
    "                       left_on='Pseudo_clave_cat', right_on='key', \n",
    "                       how='outer', indicator=True, \n",
    "                       suffixes=('_AreaH', '_Manz'))\n",
    "cruce1['Tipo_cruce1'] = cruce1['_merge'].map({'both':'AreaH_&_Manzana', 'left_only':'AreaH', 'right_only':'Manzanas' })\n",
    "cruce1.drop(columns=['_merge'], inplace=True)\n",
    "cruce1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce anterior vs BandaV\n",
    "cruce1 = df_banda.merge(cruce1, \n",
    "                        left_on='Pseudo_clave_cat', right_on='key', \n",
    "                        how='outer', indicator=True, \n",
    "                        suffixes=('_BandaV', '_Manz'))\n",
    "cruce1['Tipo_cruce2'] = cruce1['_merge'].map({'both':'BandaV_&_Manzana_&_AreaH', 'left_only':'BandaV', 'right_only':'Manzanas_&_AreaH' })\n",
    "cruce1.drop(columns=['_merge'], inplace=True)\n",
    "# Revisamos el tipo de variable\n",
    "for col in ['Val m2_BandaV','Val m2_Manz']:\n",
    "    cruce1[col] = cruce1[col].astype('float')\n",
    "cruce1[['Val m2_BandaV','Val m2_Manz']].fillna(0, inplace=True)\n",
    "# cruce1.sort_values('Val m2_Manz',inplace=True)\n",
    "cruce1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos duplicados por clave catastral y geomety\n",
    "print('Shape original --> ', cruce1.shape)\n",
    "cruce1.drop_duplicates(subset=['cve_cat','geometry'],inplace=True)\n",
    "print('Shape final    --> ', cruce1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AreaH solo tiene  {len(df_area[\"Manzanas\"].unique())} manzanas')\n",
    "print(f'BandaV solo tiene {len(df_banda[\"Manzanas\"].unique())} manzanas')\n",
    "print(f'Total de manzanas diferentes que abarcan los valores unitarios {len(df_area[\"Manzanas\"].unique()) + len(df_banda[~df_banda[\"Manzanas\"].isin(df_area[\"Manzanas\"])][\"Manzanas\"].unique())}')\n",
    "print(f'Manzanas en el cruce BandaV: {len(cruce1[\"Manzanas_BandaV\"].unique())}')\n",
    "print(f'Manzanas en el cruce AreaH: {len(cruce1[\"Manzanas_Manz\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos los que no tienen valores\n",
    "cruce1.loc[(cruce1['Val m2_BandaV'].fillna(0)==0) & (cruce1['Nombre Calle'].fillna(0)==0),['No_BandaV']] = 1\n",
    "cruce1.loc[(cruce1['Val m2_Manz'].fillna(0)==0) & (cruce1['Tipo calle'].fillna('0')=='0'),'No_AreaH'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolamos para rellenar faltantes\n",
    "cruce1['Val_m2_AH_I'] = cruce1['Val m2_Manz'].interpolate(method='pad') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Geodataframe el cruce1\n",
    "cruce1 = gpd.GeoDataFrame(cruce1, geometry='geometry').to_crs(3857)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 1\n",
    "Asociar un valor unitario a cada registro del modelo IA, para poder aproximar su valor catastral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos las columnas para llenar la sig celda\n",
    "cruce1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos columnas utiles\n",
    "# Valores unitarios para banda de valores\n",
    "col_vu_bv = 'Val m2_BandaV'\n",
    "# Valores unitarios para area homogenea\n",
    "col_vu_ah = 'Val_m2_AH_I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de valores 0, no permitidos en ambos Val m2\n",
    "cruce1[(cruce1[col_vu_ah].fillna(0)==0)&(cruce1[col_vu_bv].fillna(0)==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el GeoDataFrame del modelo de la IA\n",
    "gdf_modelo_c = gpd.read_file(path_modelo_casas).to_crs(3857)\n",
    "gdf_modelo_c.rename(columns={'area':'Area_Modelo'}, inplace=True)\n",
    "print('Shape original -> ',gdf_modelo_c.shape)\n",
    "gdf_modelo_c.drop_duplicates(subset='geometry', inplace=True)\n",
    "print('Shape final -> ',gdf_modelo_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_modelo_c.geometry.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos borrar la clase carros si es que existe\n",
    "existe_categoria = False\n",
    "try:\n",
    "    s = gdf_modelo_c.shape[0]\n",
    "    gdf_modelo_c.drop(index=gdf_modelo_c[gdf_modelo_c['clase_dete']=='carros'].index, inplace=True)\n",
    "    print('Se borraron: ',s-gdf_modelo_c.shape[0])\n",
    "    # Columnas de categorias\n",
    "    casas = ['casas', 'establecimiento','multivivienda']\n",
    "    terrenos = ['area_verde','terreno_baldio',]\n",
    "    existe_categoria = True\n",
    "except:\n",
    "    print('Revise que la columnas para borrar carros exista')\n",
    "    print(gdf_modelo_c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce de modelo IA vs Valores Unitarios & mz\n",
    "cruce2 = gpd.sjoin(gdf_modelo_c,cruce1, how='left', lsuffix='_Cruce1', rsuffix='_ModeloIA')\n",
    "#cruce2['Tipo_cruce1'] = cruce2['Tipo_cruce1'].astype(str)\n",
    "#cruce2['Tipo_cruce2'] = cruce2['Tipo_cruce2'].astype(str)\n",
    "print('Shape original = ', cruce2.shape)\n",
    "cruce2.reset_index(drop=True,inplace=True)\n",
    "cruce2.dropna(subset=['cve_cat','geometry'], inplace=True)\n",
    "print('Shape final    = ', cruce2.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "cruce2[(cruce2[col_vu_bv].fillna(0)==0)&(cruce2[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las medidas de los lados\n",
    "cruce2['Medida_lx'] = cruce2['geometry'].map(lambda x: get_lados_xy(x)[0]) \n",
    "cruce2['Medida_ly'] = cruce2['geometry'].map(lambda x: get_lados_xy(x)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos 15m\n",
    "\n",
    "# Clave de municipio\n",
    "cve_mun = '040'\n",
    "\n",
    "\n",
    "gdf_15m = gpd.read_file(path_info).to_crs(3857)\n",
    "\n",
    "# Filtramos\n",
    "gdf_15m = gdf_15m[gdf_15m['CVE_MUN']==cve_mun] \n",
    "gdf_15m['geometry'].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos 15m con el cruce2 (cruce IA vs Manzanas)\n",
    "# Cruce \n",
    "cruce3 = gpd.sjoin(cruce2, gdf_15m,\n",
    "                   how='left',lsuffix='_cruce2',rsuffix='_15m')\n",
    "cruce3.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cruce3[cruce3['manz'].fillna('vacio')=='vacio'].shape[0] == 0:\n",
    "    print('ok')\n",
    "    drop_mz = ['Zona_Manz','Manzanas_Manz','CVE_MZA']\n",
    "else:\n",
    "    print('revisa las filas vacias y buscales una manzana')\n",
    "    drop_mz = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar cols inecesarias\n",
    "cols_drop = ['key','Pseudo_clave_cat_BandaV','Pseudo_clave_cat_Manz',\n",
    "             'Municipio_BandaV','Municipio_Manz','mun','index__15m','CVE_MUN',\n",
    "             'CVE_ENT','CVE_LOC'] + drop_mz\n",
    "print('Shape original: ', cruce3.shape)\n",
    "cruce3.drop(columns=cols_drop,inplace=True)\n",
    "print('Shape final: ', cruce3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3['AMBITO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3['TIPOMZA'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 1.1\n",
    "Cruzamos con valores de chinchetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = gpd.read_file(path_chinchetas)\n",
    "gdf_dnue = gpd.read_file(path_dnue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_crs={'set_ch':3857,'to_ch':3857,'set_dnue':6364,'to_dnue':3857}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = gdf_chinchetas.set_crs(schema_crs['set_ch'],allow_override=True)\n",
    "gdf_dnue   = gdf_dnue.set_crs(schema_crs['set_dnue'],allow_override=True)\n",
    "gdf_chinchetas.set_geometry('geometry',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = cruzar_chinchetas_vs_dnue(gdf_chinchetas, gdf_dnue,\n",
    "                                           municipio='Ixtapan de la Sal',\n",
    "                                           show_crs=True,\n",
    "                                           show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos cruce IA vs chinchetas\n",
    "cruce4 = gpd.sjoin(cruce3, gdf_chinchetas, how='inner',\n",
    "          lsuffix='IA', rsuffix='ch')\n",
    "# Creamos diccionario de agrupacion\n",
    "cols_agg = ['Clase','tipoCenCom', 'tipo_asent', 'nombre_act', 'clee','id']\n",
    "dict_agg = {}\n",
    "for k in cols_agg:\n",
    "    dict_agg[k] = '|'.join\n",
    "    \n",
    "# Hacemos todo str menos la geometry para agrupar\n",
    "for col in cols_agg:\n",
    "    if col == 'geometry':\n",
    "        print('omitio ', col)\n",
    "        continue\n",
    "    cruce4[col] = cruce4[col].astype(str)\n",
    "        \n",
    "\n",
    "cruce4 = cruce4.groupby('geometry', as_index=False,sort=False).agg(dict_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos lo encontrado al original modelo IA\n",
    "for i in tqdm.tqdm(cruce4.index):\n",
    "    cruce3.loc[cruce3['geometry'] == cruce4.loc[i,'geometry'], cols_agg] = cruce4.loc[i,cols_agg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "c = pd.read_csv('/home/hector/Descargas/temporal/test_igecem_ch.csv',)\n",
    "\n",
    "geometry = [eval(x) for x in c.geometry.str.replace('POINT ','Point').str.replace(' ',',')]\n",
    "c = gpd.GeoDataFrame(c, geometry=geometry,crs=6364)\n",
    "print(c.crs)\n",
    "c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cruce_f = gpd.sjoin(cruce4, c, how='left',\n",
    "          rsuffix='IA',lsuffix='test')\n",
    "cruce_f.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 2\n",
    "Hacer una identificacion geodesica de cada registro en el modelo IA para poder obtener factores necesarios para la aproximacion del valor catastral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un cambio de variable para mejor visualizacion\n",
    "gdf = cruce3\n",
    "gdf.reset_index(drop=False, inplace=True)\n",
    "gdf.rename(columns={'index':'Indice_gdf'}, inplace=True)\n",
    "gdf = gdf.to_crs(3857)\n",
    "gdf['Esquinero|Intermedio'] = 0\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del cruce2, cruce1, gdf_modelo_c\n",
    "        print('Matamos las variables cruce2, cruce1, gdf_modelo_c, ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el shape de manzanas para analisis\n",
    "shape = gpd.read_file(path_manzanas)\n",
    "shape=shape.to_crs(\"3857\")\n",
    "shape[\"centroid\"]=shape.centroid\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "gdf[(gdf[col_vu_bv].fillna(0)==0)&(gdf[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos por distancias los mas cercanos al perimetro de la manzana\n",
    "\n",
    "nuevos = get_polygons_nearest_perimeter(falta_fp=gdf,\n",
    "                                        shape=shape,\n",
    "                                        col_cve_cat='cve_cat',\n",
    "                                        distancia_max=4,\n",
    "                                        col_id='Indice_gdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_rompio_arriba = False\n",
    "if se_rompio_arriba:\n",
    "    shape.geometry = shape.geometry.map(lambda y: y.convex_hull)\n",
    "    # Codigo para revisar los multipoligonos\n",
    "    # shape[shape.geometry.map(lambda y: True if isinstance(y,MultiPolygon) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etiquetamos los valores que son corner_polygons con el otro algoritmo\n",
    "gdf.loc[gdf['Indice_gdf'].isin(np.unique(nuevos['Indice_gdf'].values)), 'Esquinero|Intermedio'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de conteos nuevos en el gdf\n",
    "gdf['Esquinero|Intermedio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar duplicados\n",
    "print('Shape original ', gdf.shape)\n",
    "gdf.drop_duplicates(subset=['geometry','cve_cat'],inplace=True)\n",
    "print('Shape fianl ', gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "gdf[(gdf[col_vu_bv].fillna(0)==0)&(gdf[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 3\n",
    "Ahora ya tenemos la info necesaria para el calculo de los factores lo que nos llevara al valor catastral\n",
    "\n",
    "Todo este procedimiento a implementar es un seguimiento detallado del [manual catastral](!https://igecem.edomex.gob.mx/sites/igecem.edomex.gob.mx/files/files/ArchivosPDF/Servicios-catastrales/Manual%20Catastral%20del%20Estado%20de%20Mexico.pdf) que el IGECEM publica para el calculo del valor catastral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = gdf\n",
    "#datos.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del gdf\n",
    "        print('Matamos las variables cgdf   , ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrar duplicados again\n",
    "print('Shape original -> ',datos.shape)\n",
    "datos.drop_duplicates(subset=['geometry','cve_cat'],inplace=True)\n",
    "print('Shape nuevo    -> ',datos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de altura, nivel, y valores para borrarlas, ya que se hara de nuevo la clasificacion\n",
    "cols_altura = np.array([])\n",
    "cols_nivel = np.array([])\n",
    "cols_valor_uni = np.array([])\n",
    "cols_otros = np.array([])\n",
    "col_categoria = None\n",
    "#datos.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "for col in datos:\n",
    "    if col.lower().strip().startswith('altura'):\n",
    "        cols_altura = np.append(cols_altura, col)\n",
    "    elif col.lower().strip().startswith('nivel'):\n",
    "        cols_nivel = np.append(cols_nivel, col)\n",
    "    elif col.lower().strip().startswith('val'):\n",
    "        cols_valor_uni = np.append(cols_valor_uni,col)\n",
    "    # elif col in list(vu_const['Clase']):\n",
    "    #     cols_otros = np.append(cols_otros, col)\n",
    "    elif col.lower().strip().startswith('clase_dete'):\n",
    "        col_categoria = col\n",
    "len(cols_altura), len(cols_nivel), len(cols_valor_uni), len(cols_otros), col_categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios utiles para clasificacion\n",
    "\n",
    "dict_niveles = {\n",
    "    'Niveles_Bajo':1,\n",
    "    'Niveles_Medio':2,\n",
    "    'Niveles_Alto':3,\n",
    "    'Niveles_oficina':5,\n",
    "    'Niveles_edificios':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos en caso de ser necesario\n",
    "renombres = {'Area_H':'Area_AH'}\n",
    "datos.rename(columns=renombres,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas a utilizar, pueden variar, por eso se definen aqui\n",
    "col_area_modelo = 'Area_Modelo'\n",
    "col_area_h = 'Area_AH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner niveles \n",
    "for key,val in dict_niveles.items():\n",
    "    print(key,val)\n",
    "    datos[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_vu_construccion = './Data/Valores unitarios Construccion.xlsx'\n",
    "df_construccion = pd.read_excel(path_vu_construccion)\n",
    "df_construccion.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner valores unitarios de construccion\n",
    "\n",
    "cols_vu_cons = np.array([])\n",
    "usar = 'baja'  # baja, media, alta\n",
    "\n",
    "\n",
    "for tipo in datos['Tipo'].unique():\n",
    "    # print(tipo)\n",
    "    tipo = str(tipo).replace(' ','')\n",
    "    if tipo == '0':\n",
    "        tipo = 'H4'\n",
    "    df_aux = df_construccion.loc[df_construccion['Codigo']==tipo]\n",
    "    for clase, val in df_aux[['Clase','Valor m2']].values:\n",
    "        if str(clase).endswith(usar):\n",
    "            print(clase, val)\n",
    "            datos.loc[(datos['Tipo']==tipo), clase] = val\n",
    "            cols_vu_cons = np.append(cols_vu_cons,clase)\n",
    "            del clase, val\n",
    "        else:\n",
    "            continue\n",
    "    del df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de altura, nivel, y valores\n",
    "cols_altura = np.array([])\n",
    "cols_nivel = np.array([])\n",
    "cols_valor_uni = np.array([])\n",
    "cols_const = np.array([])\n",
    "#datos.fillna(0, inplace=True)\n",
    "\n",
    "for col in datos:\n",
    "    if col.lower().strip().startswith('altura'):\n",
    "        cols_altura = np.append(cols_altura, col)\n",
    "    elif col.lower().strip().startswith('nivel'):\n",
    "        cols_nivel = np.append(cols_nivel, col)\n",
    "    elif col.lower().strip().startswith('val'):\n",
    "        cols_valor_uni = np.append(cols_valor_uni,col)\n",
    "    # elif col in list(vu_const['Clase']):\n",
    "    #     cols_const = np.append(cols_const,col)\n",
    "len(cols_altura), len(cols_nivel), len(cols_valor_uni),# len(cols_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos faltantes\n",
    "datos['Frente_base'] = datos['Frente']\n",
    "datos['Fondo_base']  = datos['Fondo']\n",
    "datos['Area_base']   = datos[col_area_h]\n",
    "\n",
    "if existe_categoria:\n",
    "    datos.loc[datos[col_categoria].isin(casas),'grado_conservacion'] = datos.loc[datos[col_categoria].isin(casas)][col_area_h].map(lambda x:get_grado_conservacion())\n",
    "else:\n",
    "    datos['grado_conservacion'] = datos[col_area_h].map(lambda x:get_grado_conservacion())\n",
    "datos['Area_inscrita']     = datos[col_area_modelo].map(lambda x: float(x)*random.uniform(0.65,1))\n",
    "datos['Area_construccion'] = datos[col_area_modelo]*.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas a utilizar, pueden variar, por eso se definen aqui\n",
    "col_esquinero = 'Esquinero|Intermedio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Tipo_cruce1','Tipo_cruce2']:\n",
    "    datos[col] = datos[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['Area_base']  = datos['Area_base'].str.replace(',','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factores catastral del terreno\n",
    "\n",
    "datos.fillna(0, inplace=True)\n",
    "cols_factor_top = np.array([])\n",
    "\n",
    "datos['Factor_posicion']      = datos[col_esquinero].fillna(0).map(lambda x: get_factor_posicion(x))\n",
    "datos['Terreno_Posicion']     = datos['Factor_posicion'].map(lambda x: 'Interior' if x==0.5 else 'otro')\n",
    "datos['factor_frente']        = datos.apply(lambda x: factor_frente(x['Medida_lx'], x['Terreno_Posicion']),axis=1)\n",
    "datos['factor_fondo']         = datos.apply(lambda x: factor_fondo(x['Medida_ly'], x['Fondo_base'], x['Terreno_Posicion']), axis=1)\n",
    "datos['Factor_Topografia']    = datos.apply(lambda x: round(random.uniform(0.9,1),5), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "datos['factor_irregularidad'] = datos.apply(lambda x: factor_irregularidad(x[col_area_modelo], x['Area_inscrita'], x['Terreno_Posicion']), axis=1)\n",
    "datos['factor_area']          = datos.apply(lambda x: factor_area(x[col_area_modelo],x['Area_base'],x['Terreno_Posicion']), axis=1)\n",
    "datos['factor_restriccion']   = datos.apply(lambda x: factor_restriccion(x[col_area_modelo],x[col_area_modelo]*0.8,x['Terreno_Posicion']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revison de valores 0 en los factores de terreno y correccion\n",
    "\n",
    "cols_ft = {'factor_frente':0.5,'factor_fondo':0.6,'factor_irregularidad':0.5,'factor_area':0.7,'factor_restriccion':0.5}\n",
    "\n",
    "for col, val in cols_ft.items():\n",
    "    s = datos[datos[col].fillna(0)==0].shape\n",
    "    \n",
    "    if s[0] != 0:\n",
    "        datos.loc[datos[col].fillna(0)==0, col] = val\n",
    "        print(col)\n",
    "    print(s)\n",
    "    \n",
    "for col in cols_factor_top:\n",
    "    s = datos[datos[col].fillna(0)==0].shape\n",
    "    if s[0] != 0:\n",
    "        print(col)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factores catastral de la construcci√≥n\n",
    "\n",
    "cols_factor_nvl = np.array([])\n",
    "\n",
    "if existe_categoria:\n",
    "    datos.loc[datos[col_categoria].isin(casas),'factor_grado_conservacion'] = datos[datos[col_categoria].isin(casas)]['grado_conservacion'].map(lambda x: factor_grado_conservacion(x))\n",
    "    datos.loc[datos[col_categoria].isin(casas),'factor_edad']               = 0.6\n",
    "else:\n",
    "    datos['factor_grado_conservacion'] = datos['grado_conservacion'].map(lambda x: factor_grado_conservacion(x))\n",
    "    datos['factor_edad']               = 0.6\n",
    "\n",
    "\n",
    "for col in cols_nivel:\n",
    "    nombre = 'factor_numero_niveles_'+col\n",
    "    cols_factor_nvl = np.append(cols_factor_nvl, nombre)\n",
    "    if existe_categoria:\n",
    "        datos.loc[datos[col_categoria].isin(casas),nombre] = datos[datos[col_categoria].isin(casas)].apply(lambda x: factor_numero_niveles(x[col],x['grado_conservacion']), axis=1)\n",
    "    else:\n",
    "        datos[nombre] = datos.apply(lambda x: factor_numero_niveles(x[col],x['grado_conservacion']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de valores 0 en los factores de construccion\n",
    "if existe_categoria:\n",
    "    print(datos[(datos[col_categoria].isin(casas))&(datos['factor_grado_conservacion'].fillna(0)==0.0)].shape)\n",
    "    print(datos[(datos[col_categoria].isin(casas))&(datos['factor_edad'].fillna(0)==0.0)].shape)\n",
    "    \n",
    "    for col in cols_factor_nvl:\n",
    "        s = datos[(datos[col_categoria].isin(casas))&(datos[col].fillna(0)==0.0)].shape\n",
    "        if s[0] != 0:\n",
    "            print(col)\n",
    "        print(s)\n",
    "else:\n",
    "    print(datos[(datos['factor_grado_conservacion'].fillna(0)==0.0)].shape)\n",
    "    print(datos[(datos['factor_edad'].fillna(0)==0.0)].shape)\n",
    "    \n",
    "    for col in cols_factor_nvl:\n",
    "        s = datos[(datos[col].fillna(0)==0.0)].shape\n",
    "        if s[0] != 0:\n",
    "            print(col)\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion a flotantes de los valores que necesitamos\n",
    "\n",
    "cols_using = [col_area_modelo,'factor_frente','factor_fondo', 'factor_irregularidad','factor_area',\n",
    "              'Factor_posicion','factor_restriccion']\n",
    "datos.fillna(0,inplace=True)\n",
    "for col in cols_using:\n",
    "    datos[col] = datos[col].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Data/Valor_cat_terreno.png) \n",
    "\n",
    "Formula para obtener el valor catastral del terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor catastral del terreno\n",
    "print('Lista de valores unitarios para terreno \\n ', cols_valor_uni)\n",
    "index_use = input('Que valores quiere usar para el valor por metro cuadrado(separe cada indice con una coma, empezando en 0)?: ')\n",
    "if index_use.lower() in ['todos', 'all']:\n",
    "    cols_vu_terr = cols_valor_uni.copy()\n",
    "else:\n",
    "    cols_vu_terr = cols_valor_uni[[int(x) for x in index_use.split(',')]]\n",
    "cols_vc_terr = np.array([])\n",
    "\n",
    "for col_vu in cols_vu_terr:\n",
    "    name = col_vu.split('_')[-1]\n",
    "    name_col = 'Valor_catastral_terreno_'+name\n",
    "    datos[name_col] = datos[col_area_modelo].astype(float).fillna(0)*datos[col_vu].astype(float).fillna(0)*datos['factor_frente'].astype(float).fillna(0)*datos['factor_fondo'].fillna(0)*datos['factor_irregularidad'].fillna(0)*datos['factor_area'].fillna(0)*datos['Factor_Topografia'].fillna(0)*datos['Factor_posicion'].fillna(0)*datos['factor_restriccion'].fillna(0)\n",
    "    cols_vc_terr = np.append(cols_vc_terr,name_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Data/Valor_cat_const.png) <br>\n",
    " Formula para obtener el valor catastral de la construccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor catastral de la construccion\n",
    "cols_vc_const = np.array([])\n",
    "for col_vu in cols_vu_cons:\n",
    "    i = 0\n",
    "    name = col_vu.split('_')[-1]\n",
    "    for col_nv in cols_factor_nvl:\n",
    "        name_col = 'Valor_catastral_construccion_'+name+'_'+str(i)\n",
    "        cols_vc_const = np.append(cols_vc_const,name_col)\n",
    "        datos[name_col] = datos[col_area_modelo].astype(float).fillna(0)*datos[col_vu].astype(float).fillna(0)*datos['factor_edad'].astype(float).fillna(0)*datos['factor_grado_conservacion'].astype(float).fillna(0)*datos[col_nv].astype(float).fillna(0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revicion del total de columnas creadas\n",
    "print(f'Cols construccion -> {len(cols_vc_const)} \\nCols terreno      -> {len(cols_vc_terr)} \\nShape Final       -> {datos.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "datos[(datos[col_vu_bv].fillna(0)==0)&(datos[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint opcional\n",
    " <br>Hasta este punto hemos aproximado tantos valores catastrales como el numero de columnas creadas arriba.\n",
    "El siguiente proceso consume muchos recurso asi que se recomienda llevarlo a google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_file = 'New_casas_Naucalpan_proces2_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear en CSV para no truncar el nombre de columnas\n",
    "pd.DataFrame(datos).to_csv('Data/Completados/Modelo_Final/'+nombre_file+'.csv',\n",
    "                           index=False,\n",
    "                           encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el geopandas solo con las columnas utiles para reponerselas al csv\n",
    "datos[['geometry', 'cve_cat','Indice_gdf']].to_file('Data/Completados/Modelo_Final/Recuperacion_geometry/'+nombre_file+'.shp',\n",
    "                                         index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camnibio de variable otra vez\n",
    "df = datos\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df.rename(columns={'index':'Indice_Modelo'}, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del datos\n",
    "        print('Matamos las variables datos   , ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de interes\n",
    "cols_terreno = np.array([])\n",
    "cols_const = np.array([])\n",
    "for col in df.columns:\n",
    "    if col.lower().find('valor_catastral_construccion')>=0:\n",
    "        cols_const = np.append(cols_const, col)\n",
    "    elif col.lower().find('valor_catastral_terreno')>=0:\n",
    "        cols_terreno = np.append(cols_terreno, col)\n",
    "len(cols_terreno), len(cols_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "df[(df[col_vu_bv].fillna(0)==0)&(df[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols_const].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los estadisticos de interes, esta parte es la mas pesada\n",
    "df['Estadisticos_terreno'] = df.apply(lambda x: statistics_values(x[cols_terreno]), axis=1)\n",
    "df[df['Estadisticos_terreno']=='Revisar'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los estadisticos de interes, esta parte es la mas pesada\n",
    "df['Estadisticos_construccion'] = df.apply(lambda x: statistics_values(x[cols_const]), axis=1)\n",
    "df[df['Estadisticos_construccion']=='Revisar'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos formatoa las cols Minimo, Maximo, Media, desviacion_estandar, largo, media_percentil, desviacion_std_percentiles, moda_percentiles\n",
    "df = pd.concat([df,\n",
    "                df['Estadisticos_terreno'].str.split('|', expand=True).rename(columns={0:   'Min_terreno',\n",
    "                                                                                       1:   'Max_terreno',\n",
    "                                                                                       2: 'Media_terreno',\n",
    "                                                                                       3:   'STD_terreno',\n",
    "                                                                                       4:   'Len_terreno',\n",
    "                                                                                       5:'MediaP_terreno',\n",
    "                                                                                       6:  'STDP_terreno',\n",
    "                                                                                       7: 'ModaP_terreno'})], axis=1)\n",
    "\n",
    "df = pd.concat([df,\n",
    "                df['Estadisticos_construccion'].str.split('|', expand=True).rename(columns={0:   'Min_construccion',\n",
    "                                                                                            1:   'Max_construccion',\n",
    "                                                                                            2: 'Media_construccion',\n",
    "                                                                                            3:   'STD_construccion',\n",
    "                                                                                            4:   'Len_construccion',\n",
    "                                                                                            5:'MediaP_construccion',\n",
    "                                                                                            6:  'STDP_construccion',\n",
    "                                                                                            7: 'ModaP_construccion'})], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo del intervalo de confianza suponiendo distribucion normal en los valores catastrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor z con nivel de significancia al 95%\n",
    "z = stats.norm.ppf(.95)\n",
    "z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./Data/Valor_cat_final.png)\n",
    "\n",
    "Formula para obtener el valor catastral final \n",
    "\n",
    "![alt text](./Data/Intervalo_confianza_norm.png) Formula para intervalo de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_estadisticos = ['Media_terreno','STD_terreno','Len_terreno','Media_construccion','STD_construccion','Len_construccion']\n",
    "\n",
    "for col in cols_estadisticos:\n",
    "    try:\n",
    "        df[col] = df[col].astype(float)\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Media_terreno']#- (z*df['STD_terreno']/df['Len_terreno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limite inferior (LI) y superior (LS) de cada valor catastral\n",
    "df['LI_95%_vc_terreno'] = df['Media_terreno'].astype(float).fillna(0)- (z*df['STD_terreno'].astype(float).fillna(0)/df['Len_terreno'].astype(float).fillna(0))\n",
    "df['LS_95%_vc_terreno'] = df['Media_terreno'].astype(float).fillna(0)+ (z*df['STD_terreno'].astype(float).fillna(0)/df['Len_terreno'].astype(float).fillna(0)) \n",
    "\n",
    "df['LI_95%_vc_construccion'] = df['Media_construccion'].astype(float).fillna(0)- (z*df['STD_construccion'].astype(float).fillna(0)/df['Len_construccion'].astype(float).fillna(0))\n",
    "df['LS_95%_vc_construccion'] = df['Media_construccion'].astype(float).fillna(0)+ (z*df['STD_construccion'].astype(float).fillna(0)/df['Len_construccion'].astype(float).fillna(0) )\n",
    "\n",
    "df['LS_95%_catastral_final'] = df['LS_95%_vc_terreno'].fillna(0) + df['LS_95%_vc_construccion'].fillna(0) \n",
    "df['LI_95%_catastral_final'] = df['LI_95%_vc_terreno'].fillna(0) + df['LI_95%_vc_construccion'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[col_area_modelo,col_vu_ah, 'LI_95%_catastral_final','LS_95%_catastral_final']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_estadisticos = ['Media_terreno','STD_terreno','Len_terreno','Min_terreno','Max_terreno','MediaP_construccion','STDP_construccion','ModaP_construccion',\n",
    "                     'Media_construccion','STD_construccion','Len_construccion','Min_construccion','Max_construccion','MediaP_construccion','STDP_construccion','ModaP_construccion',\n",
    "                     'LI_95%_catastral_final','LS_95%_catastral_final']\n",
    "\n",
    "for col in cols_estadisticos:\n",
    "    try:\n",
    "        if col.lower().startswith('min'):\n",
    "            df[col] = df[col].str.replace('Revisar','0')\n",
    "        df[col] = df[col].astype(float)\n",
    "    except Exception as e:\n",
    "        print(col)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de valor catastral para estadisticos\n",
    "df['minVC'] = df['Min_terreno'].astype(float).fillna(0) + df['Min_construccion'].astype(float).fillna(0)\n",
    "df['maxVC'] = df['Max_construccion'].astype(float).fillna(0) + df['Max_terreno'].astype(float).fillna(0)\n",
    "df['mediaVC'] = df['Media_construccion'].astype(float).fillna(0) + df['Media_terreno'].astype(float).fillna(0)\n",
    "df['PmediaVC'] = df['MediaP_construccion'].astype(float).fillna(0) + df['MediaP_terreno'].astype(float).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo cols de interes a\n",
    "df[np.append(cols_estadisticos,['Indice_gdf','geometry','cve_cat'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En caso de haber hecho checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de haber hecho checkpoint\n",
    "path_gdf =  'Data/Completados/Modelo_Final/Recuperacion_geometry/'+nombre_file+'.shp'\n",
    "gdf = gpd.read_file(path_gdf)\n",
    "gdf.rename(columns={'Indice_gdf':'Indice_gdf1'},inplace=True)\n",
    "\n",
    "final = gpd.GeoDataFrame(pd.concat([gdf[['geometry', 'cve_cat','Indice_gdf1']] , df[cols_new]], axis=1), geometry='geometry')\n",
    "final.tail(2)\n",
    "\n",
    "gdf.shape, final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de empatamiento \n",
    "final[final['Indice_gdf']!=final['Indice_gdf1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el GeoDataFrame\n",
    "final.to_file('/content/drive/MyDrive/Equipo_Agua/Geo/Data/Completados/Modelo_Final/Solo_VC_Final/NewCasas_Valor_Catastral_Naucalpan_Final_v1.shp',\n",
    "                                                  index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En caso de no haber hecho checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del predial\n",
    "cols_calc_predial = ['minVC','maxVC','mediaVC','LI_95%_catastral_final','LS_95%_catastral_final','PmediaVC']\n",
    "cols_predial = []\n",
    "df_predial = pd.read_csv('./Data/Predial.csv',)\n",
    "df_predial['FACTOR'] = df_predial['FACTOR'].str.replace(',','.')\n",
    "for col in df_predial:\n",
    "    df_predial[col] = df_predial[col].astype(float)\n",
    "\n",
    "\n",
    "for col in cols_calc_predial:\n",
    "    name_col = 'Predial'+col\n",
    "    df[name_col] = df[col].map(lambda x: calculo_predial(x,df_predial))\n",
    "    cols_predial.append(name_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya terminamos solo exportamos el geodataframe\n",
    "ruta_and_name_save = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Ixtapan_completo_VC_v2.shp'\n",
    "if input('usar cols solo necesarias') in afirmativo:\n",
    "    cols_out = np.append(cols_predial,['cve_cat','Indice_gdf','geometry']+cols_agg)\n",
    "else:\n",
    "    cols_out = df.columns\n",
    "    \n",
    "df[cols_out].to_file(ruta_and_name_save,  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comparacion_min_max'] = df['PredialminVC'] == df['PredialmaxVC']\n",
    "df['comparacion_min_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.append(cols_predial,['cve_cat','Indice_gdf','geometry'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inteligencia_fiscal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
