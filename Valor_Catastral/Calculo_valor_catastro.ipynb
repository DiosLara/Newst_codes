{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon,mapping,LineString, Point\n",
    "import math\n",
    "import tqdm\n",
    "import sqlite3\n",
    "from calculo_predial import *\n",
    "from Valor_catastral_construccion import *\n",
    "from Valor_catastral_terreno import *\n",
    "from Herramientas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "# Modelo IA\n",
    "path_modelo_casas = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Ixtapan_Sal_casas.shp'\n",
    "# Manzanas del municipio\n",
    "path_manzanas     = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Manzana_Ixtapan_Sal.shp'\n",
    "# Cruce de valores unitarios vs Manzana\n",
    "#path_vu_and_mz    = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Valores_Unitarios_con_Manzanas_Naucalpan.shp'\n",
    "# Valores unitarios\n",
    "path_sql          ='Data/Valores_Unitarios_2022_v2'\n",
    "# shape 15m \n",
    "path_info = '/home/hector/Documentos/Infis/Geo/Data/Shapes/15m/15m.shp'\n",
    "# path de chinchetas\n",
    "path_chinchetas = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/chinchetas_limpieza1/Centro_chinchetas_limpieza1.shp'\n",
    "# ruta a dnue\n",
    "path_dnue = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Dnue/DENUE_EDOMEX_2022.shp'\n",
    "# Lista de afirmaciones en minisculas\n",
    "afirmativo = np.array(['si','1',1,'yes','claro','obvio','of course','sip','sipi','neta','ok'])\n",
    "# Municipio a procesar\n",
    "municipio = 'Ixtapan_de_la_sal'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar valores de SQL\n",
    "\n",
    "conexion = sqlite3.connect(path_sql)\n",
    "df_area = pd.read_sql(f'''\n",
    "SELECT Zona,Manzanas,COD,Tipo,Frente,Fondo,Area as Area_AH,[Val m2],\n",
    "        Pseudo_clave_cat, Municipio\n",
    "FROM area_homogenea\t\n",
    "WHERE Municipio = '{municipio}'\n",
    "    ''', conexion)\n",
    "df_banda = pd.read_sql(f'''\n",
    "SELECT [Tipo calle], [Nombre Calle], [Zona], [Manzanas], COD,\n",
    "       [Val m2], Pseudo_clave_cat, Municipio\n",
    "FROM banda_valores\n",
    "WHERE Municipio = '{municipio}'\n",
    "''', conexion)\n",
    "\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir formato del val m2 en ambas\n",
    "df_area['Val m2'] = df_area['Val m2'].map(lambda x: corregir_formato(str(x)))\n",
    "df_banda['Val m2'] = df_banda['Val m2'].map(lambda x: corregir_formato(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar que tenemos el municipio adecuado\n",
    "df_area['Municipio'].value_counts(), df_banda['Municipio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos duplicados\n",
    "print('Shape inicial de Area_H ', df_area.shape)\n",
    "print('Shape inicial de bandaV ', df_banda.shape)\n",
    "df_area.drop_duplicates(subset=['Zona', 'Manzanas', 'COD', 'Tipo', 'Frente', 'Fondo', 'Area_AH',\n",
    "       'Val m2', 'Pseudo_clave_cat'],\n",
    "       inplace=True)\n",
    "df_banda.drop_duplicates(subset=['Tipo calle', 'Nombre Calle', 'Zona', 'Manzanas', 'COD', 'Val m2',\n",
    "       'Pseudo_clave_cat'], inplace=True)\n",
    "print('Shape Final de Area_H ', df_area.shape)\n",
    "print('Shape Final de bandaV ', df_banda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el shape de manzanas para analisis\n",
    "shape = gpd.read_file(path_manzanas)\n",
    "shape=shape.to_crs(\"3857\")\n",
    "shape['key'] = shape['cve_cat'].map(lambda x: str(x)[:8])\n",
    "shape['Lon'] = shape['geometry'].centroid.x\n",
    "shape['Lat'] = shape['geometry'].centroid.y\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape de Area Homo= {df_area.shape}')\n",
    "print(f'Shape de Banda    = {df_banda.shape}')\n",
    "print(f'Shape de Manzanas = {shape.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_banda[~df_banda[\"Manzanas\"].isin(df_area[\"Manzanas\"])][\"Manzanas\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce area_h vs Mzs\n",
    "cruce1 = df_area.merge(shape, \n",
    "                       left_on='Pseudo_clave_cat', right_on='key', \n",
    "                       how='outer', indicator=True, \n",
    "                       suffixes=('_AreaH', '_Manz'))\n",
    "cruce1['Tipo_cruce1'] = cruce1['_merge'].map({'both':'AreaH_&_Manzana', 'left_only':'AreaH', 'right_only':'Manzanas' })\n",
    "cruce1.drop(columns=['_merge'], inplace=True)\n",
    "cruce1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce anterior vs BandaV\n",
    "cruce1 = df_banda.merge(cruce1, \n",
    "                        left_on='Pseudo_clave_cat', right_on='key', \n",
    "                        how='outer', indicator=True, \n",
    "                        suffixes=('_BandaV', '_Manz'))\n",
    "cruce1['Tipo_cruce2'] = cruce1['_merge'].map({'both':'BandaV_&_Manzana_&_AreaH', 'left_only':'BandaV', 'right_only':'Manzanas_&_AreaH' })\n",
    "cruce1.drop(columns=['_merge'], inplace=True)\n",
    "# Revisamos el tipo de variable\n",
    "for col in ['Val m2_BandaV','Val m2_Manz']:\n",
    "    cruce1[col] = cruce1[col].astype('float')\n",
    "cruce1[['Val m2_BandaV','Val m2_Manz']].fillna(0, inplace=True)\n",
    "# cruce1.sort_values('Val m2_Manz',inplace=True)\n",
    "cruce1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos duplicados por clave catastral y geomety\n",
    "print('Shape original --> ', cruce1.shape)\n",
    "cruce1.drop_duplicates(subset=['cve_cat','geometry'],inplace=True)\n",
    "print('Shape final    --> ', cruce1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AreaH solo tiene  {len(df_area[\"Manzanas\"].unique())} manzanas')\n",
    "print(f'BandaV solo tiene {len(df_banda[\"Manzanas\"].unique())} manzanas')\n",
    "print(f'Total de manzanas diferentes que abarcan los valores unitarios {len(df_area[\"Manzanas\"].unique()) + len(df_banda[~df_banda[\"Manzanas\"].isin(df_area[\"Manzanas\"])][\"Manzanas\"].unique())}')\n",
    "print(f'Manzanas en el cruce BandaV: {len(cruce1[\"Manzanas_BandaV\"].unique())}')\n",
    "print(f'Manzanas en el cruce AreaH: {len(cruce1[\"Manzanas_Manz\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos los que no tienen valores\n",
    "cruce1.loc[(cruce1['Val m2_BandaV'].fillna(0)==0) & (cruce1['Nombre Calle'].fillna(0)==0),['No_BandaV']] = 1\n",
    "cruce1.loc[(cruce1['Val m2_Manz'].fillna(0)==0) & (cruce1['Tipo calle'].fillna('0')=='0'),'No_AreaH'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolamos para rellenar faltantes\n",
    "cruce1['Val_m2_AH_I'] = cruce1['Val m2_Manz'].interpolate(method='pad') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Geodataframe el cruce1\n",
    "cruce1 = gpd.GeoDataFrame(cruce1, geometry='geometry').to_crs(3857)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 1\n",
    "Asociar un valor unitario a cada registro del modelo IA, para poder aproximar su valor catastral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos las columnas para llenar la sig celda\n",
    "cruce1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos columnas utiles\n",
    "# Valores unitarios para banda de valores\n",
    "col_vu_bv = 'Val m2_BandaV'\n",
    "# Valores unitarios para area homogenea\n",
    "col_vu_ah = 'Val_m2_AH_I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de valores 0, no permitidos en ambos Val m2\n",
    "cruce1[(cruce1[col_vu_ah].fillna(0)==0)&(cruce1[col_vu_bv].fillna(0)==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el GeoDataFrame del modelo de la IA\n",
    "gdf_modelo_c = gpd.read_file(path_modelo_casas).to_crs(3857)\n",
    "gdf_modelo_c.rename(columns={'area':'Area_Modelo'}, inplace=True)\n",
    "print('Shape original -> ',gdf_modelo_c.shape)\n",
    "gdf_modelo_c.drop_duplicates(subset='geometry', inplace=True)\n",
    "print('Shape final -> ',gdf_modelo_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_modelo_c.geometry.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos borrar la clase carros si es que existe\n",
    "existe_categoria = False\n",
    "try:\n",
    "    s = gdf_modelo_c.shape[0]\n",
    "    gdf_modelo_c.drop(index=gdf_modelo_c[gdf_modelo_c['clase_dete']=='carros'].index, inplace=True)\n",
    "    print('Se borraron: ',s-gdf_modelo_c.shape[0])\n",
    "    # Columnas de categorias\n",
    "    casas = ['casas', 'establecimiento','multivivienda']\n",
    "    terrenos = ['area_verde','terreno_baldio',]\n",
    "    existe_categoria = True\n",
    "except:\n",
    "    print('Revise que la columnas para borrar carros exista')\n",
    "    print(gdf_modelo_c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce de modelo IA vs Valores Unitarios & mz\n",
    "cruce2 = gpd.sjoin(gdf_modelo_c,cruce1, how='left', lsuffix='_Cruce1', rsuffix='_ModeloIA')\n",
    "#cruce2['Tipo_cruce1'] = cruce2['Tipo_cruce1'].astype(str)\n",
    "#cruce2['Tipo_cruce2'] = cruce2['Tipo_cruce2'].astype(str)\n",
    "print('Shape original = ', cruce2.shape)\n",
    "cruce2.reset_index(drop=True,inplace=True)\n",
    "cruce2.dropna(subset=['cve_cat','geometry'], inplace=True)\n",
    "print('Shape final    = ', cruce2.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "cruce2[(cruce2[col_vu_bv].fillna(0)==0)&(cruce2[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las medidas de los lados\n",
    "cruce2['Medida_lx'] = cruce2['geometry'].map(lambda x: get_lados_xy(x)[0]) \n",
    "cruce2['Medida_ly'] = cruce2['geometry'].map(lambda x: get_lados_xy(x)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos 15m\n",
    "\n",
    "# Clave de municipio\n",
    "cve_mun = '040'\n",
    "\n",
    "\n",
    "gdf_15m = gpd.read_file(path_info).to_crs(3857)\n",
    "\n",
    "# Filtramos\n",
    "gdf_15m = gdf_15m[gdf_15m['CVE_MUN']==cve_mun] \n",
    "gdf_15m['geometry'].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos 15m con el cruce2 (cruce IA vs Manzanas)\n",
    "# Cruce \n",
    "cruce3 = gpd.sjoin(cruce2, gdf_15m,\n",
    "                   how='left',lsuffix='_cruce2',rsuffix='_15m')\n",
    "cruce3.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cruce3[cruce3['manz'].fillna('vacio')=='vacio'].shape[0] == 0:\n",
    "    print('ok')\n",
    "    drop_mz = ['Zona_Manz','Manzanas_Manz','CVE_MZA']\n",
    "else:\n",
    "    print('revisa las filas vacias y buscales una manzana')\n",
    "    drop_mz = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar cols inecesarias\n",
    "cols_drop = ['index__Cruce1','key','Pseudo_clave_cat_BandaV','Pseudo_clave_cat_Manz',\n",
    "             'Municipio_BandaV','Municipio_Manz','mun','index__15m','CVE_MUN',\n",
    "             'CVE_ENT','CVE_LOC'] + drop_mz\n",
    "print('Shape original: ', cruce3.shape)\n",
    "cruce3.drop(columns=cols_drop,inplace=True)\n",
    "print('Shape final: ', cruce3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3['AMBITO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3['TIPOMZA'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 1.1\n",
    "Cruzamos con valores de chinchetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = gpd.read_file(path_chinchetas)\n",
    "gdf_dnue = gpd.read_file(path_dnue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_crs={'set_ch':3857,'to_ch':3857,'set_dnue':6364,'to_dnue':3857}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = gdf_chinchetas.set_crs(schema_crs['set_ch'],allow_override=True)\n",
    "gdf_dnue   = gdf_dnue.set_crs(schema_crs['set_dnue'],allow_override=True)\n",
    "gdf_chinchetas.set_geometry('geometry',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_chinchetas = cruzar_chinchetas_vs_dnue(gdf_chinchetas, gdf_dnue,\n",
    "                                           municipio='Ixtapan de la Sal',\n",
    "                                           show_crs=True,\n",
    "                                           show_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_cruce_chinchetas( cruce1, cols_agg):\n",
    "    '''\n",
    "    Luego de hacer un primer cruce, es razonable pensar que un id, este en 1 o mas poligonos de chinchetas, las razones pueden ser; <br>\n",
    "    - Es una plaza <br>\n",
    "    - Es un mercado <br>\n",
    "    - La separacion entre poligonos es minima <br>\n",
    "    - otra <br>\n",
    "\n",
    "    Entonces compactaremos todos esos id, en un solo registro de manere que concatenemos los posibles id que se corresponden a esa chincheta.\n",
    "    '''\n",
    "    # Hacemos todo str menos la geometry para agrupar\n",
    "    for col in cols_agg:\n",
    "        if col == 'geometry':\n",
    "            print('omitio ', col)\n",
    "            continue\n",
    "        cruce1[col] = cruce1[col].astype(str)\n",
    "\n",
    "\n",
    "    # Creamos diccionario de agrupacion\n",
    "    dict_agg = {}\n",
    "    for k in cols_agg:\n",
    "        dict_agg[k] = '|'.join\n",
    "\n",
    "\n",
    "    # Agrupamos para concatenar los datos duplicados de cada geometria\n",
    "    cruce1_ = cruce1.groupby('geometry', as_index=False,sort=False).agg(dict_agg).reset_index(drop=True)\n",
    "    # Hacemos GeoDataFrame\n",
    "    cruce1_ = gpd.GeoDataFrame(cruce1_, geometry='geometry')\n",
    "    \n",
    "    # Encontrar los repetidos\n",
    "    ind_f = pd.Series(cruce1_.id.str.replace('nan','').str.strip('|').value_counts().index)\n",
    "    ind_f = ind_f.map(lambda y: y if str(y).find('|')>0 else 'vacio')\n",
    "    ind_f[ind_f != 'vacio']\n",
    "    \n",
    "    # Borramos duplicados\n",
    "    print('Shape original: ', cruce1.shape)\n",
    "    cruce1.drop_duplicates(['geometry','cve_cat'],inplace=True)\n",
    "    print('Shape final  : ',cruce1.shape)\n",
    "\n",
    "    # Asignamos lo encontrado al de chinchetas\n",
    "    for i in tqdm.tqdm(cruce1_[cruce1_.id.isin(ind_f)].index):\n",
    "        for col in cols_agg:\n",
    "            cruce1.loc[cruce1['geometry'] == cruce1.loc[i,'geometry'], col] = cruce1_.loc[i,col]\n",
    "    return cruce1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos cruce IA vs chinchetas\n",
    "cruce4 = gpd.sjoin(cruce3, gdf_chinchetas, how='left',\n",
    "          lsuffix='IA', rsuffix='ch')\n",
    "\n",
    "cruce4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_agg = ['Clase','tipoCenCom', 'tipo_asent', 'nombre_act', 'clee','id']\n",
    "cruce = agrupar_cruce_chinchetas(cruce3,cruce4,cols_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "c = pd.read_csv('/home/hector/Descargas/temporal/test_igecem_ch.csv',)\n",
    "\n",
    "geometry = [eval(x) for x in c.geometry.str.replace('POINT ','Point').str.replace(' ',',')]\n",
    "c = gpd.GeoDataFrame(c, geometry=geometry,crs=6364)\n",
    "print(c.crs)\n",
    "c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cruce_f = gpd.sjoin(cruce4, c, how='left',\n",
    "          rsuffix='IA',lsuffix='test')\n",
    "cruce_f.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 2\n",
    "Hacer una identificacion geodesica de cada registro en el modelo IA para poder obtener factores necesarios para la aproximacion del valor catastral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un cambio de variable para mejor visualizacion\n",
    "gdf = cruce3\n",
    "gdf.reset_index(drop=False, inplace=True)\n",
    "gdf.rename(columns={'index':'Indice_gdf'}, inplace=True)\n",
    "gdf = gdf.to_crs(3857)\n",
    "gdf['Esquinero|Intermedio'] = 0\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del cruce2, cruce1, gdf_modelo_c\n",
    "        print('Matamos las variables cruce2, cruce1, gdf_modelo_c, ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el shape de manzanas para analisis\n",
    "shape = gpd.read_file(path_manzanas)\n",
    "shape=shape.to_crs(\"3857\")\n",
    "shape[\"centroid\"]=shape.centroid\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "gdf[(gdf[col_vu_bv].fillna(0)==0)&(gdf[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos por distancias los mas cercanos al perimetro de la manzana\n",
    "\n",
    "nuevos = get_polygons_nearest_perimeter(falta_fp=gdf,\n",
    "                                        shape=shape,\n",
    "                                        col_cve_cat='cve_cat',\n",
    "                                        distancia_max=4,\n",
    "                                        col_id='Indice_gdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etiquetamos los valores que son corner_polygons con el otro algoritmo\n",
    "gdf.loc[gdf['Indice_gdf'].isin(np.unique(nuevos['Indice_gdf'].values)), 'Esquinero|Intermedio'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de conteos nuevos en el gdf\n",
    "gdf['Esquinero|Intermedio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar duplicados\n",
    "print('Shape original ', gdf.shape)\n",
    "gdf.drop_duplicates(subset=['geometry','cve_cat'],inplace=True)\n",
    "print('Shape fianl ', gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "gdf[(gdf[col_vu_bv].fillna(0)==0)&(gdf[col_vu_ah].fillna(0)==0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso 3\n",
    "Ahora ya tenemos la info necesaria para el calculo de los factores lo que nos llevara al valor catastral\n",
    "\n",
    "Todo este procedimiento a implementar es un seguimiento detallado del [manual catastral](!https://igecem.edomex.gob.mx/sites/igecem.edomex.gob.mx/files/files/ArchivosPDF/Servicios-catastrales/Manual%20Catastral%20del%20Estado%20de%20Mexico.pdf) que el IGECEM publica para el calculo del valor catastral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = gdf\n",
    "datos.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del gdf\n",
    "        print('Matamos las variables cgdf   , ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrar duplicados again\n",
    "print('Shape original -> ',datos.shape)\n",
    "datos.drop_duplicates(subset=['geometry','cve_cat'],inplace=True)\n",
    "print('Shape nuevo    -> ',datos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu_const = pd.read_excel('./Data/Valor de construccion unitario habitacional naucalpan.xlsx')\n",
    "vu_const.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de altura, nivel, y valores para borrarlas, ya que se hara de nuevo la clasificacion\n",
    "cols_altura = np.array([])\n",
    "cols_nivel = np.array([])\n",
    "cols_valor_uni = np.array([])\n",
    "cols_otros = np.array([])\n",
    "col_categoria = None\n",
    "datos.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "for col in datos:\n",
    "    if col.lower().strip().startswith('altura'):\n",
    "        cols_altura = np.append(cols_altura, col)\n",
    "    elif col.lower().strip().startswith('nivel'):\n",
    "        cols_nivel = np.append(cols_nivel, col)\n",
    "    elif col.lower().strip().startswith('val'):\n",
    "        cols_valor_uni = np.append(cols_valor_uni,col)\n",
    "    elif col in list(vu_const['Categoría']):\n",
    "        cols_otros = np.append(cols_otros, col)\n",
    "    elif col.lower().strip().startswith('clase_dete'):\n",
    "        col_categoria = col\n",
    "len(cols_altura), len(cols_nivel), len(cols_valor_uni), len(cols_otros), col_categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios utiles para clasificacion\n",
    "dict_intervalos = {\n",
    "    'Medio'    :(60,250),'Popular'  :(40,80),\n",
    "    'Interes'  :(0,70),'Campestre':(50, 400),\n",
    "    'Rural'    :(50, 400),'Comercial':(400,10000000000000000)\n",
    "}\n",
    "dict_niveles = {\n",
    "    'NivelesM_HMEA' :18,'NivelesM_HMEM' :10,\n",
    "    'NivelesM_HMEB' :4,'NivelesP_HPOM' :8,\n",
    "    'NivelesP_HPOB' :6,'NivelesIS_HISM':8,\n",
    "    'NivelesIS_HISB':6,'NivelesC_HCAM' :2,\n",
    "    'NivelesR_HRUR' :3,'NivelesCom'    :14\n",
    "}\n",
    "dict_alturas = {\n",
    "    'AlturaM_HMEA' :75.6,'AlturaM_HMEM' :42,\n",
    "    'AlturaM_HMEB' :16.8,'AlturaP_HPOM' :33.6,\n",
    "    'AlturaP_HPOB' :25.2,'AlturaIS_HISM':33.6,\n",
    "    'AlturaIS_HISB':25.2,'AlturaC_HCAM' :8.4,\n",
    "    'AlturaR_HRUR' :12.6,'AlturaCom'    :35\n",
    "}\n",
    "dict_construccion = {}\n",
    "for i in range(len(vu_const)):\n",
    "  dict_construccion[str(vu_const['Categoría'][i])]=(vu_const['min'][i],vu_const['Max'][i])\n",
    "\n",
    "dict_vu_construccion = {}\n",
    "for i in range(len(vu_const)):\n",
    "    dict_vu_construccion['VU_'+str(vu_const['Categoría'][i])] = vu_const['Valor m2'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vu_construccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos en caso de ser necesario\n",
    "renombres = {'Area_H':'Area_AH'}\n",
    "datos.rename(columns=renombres,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas a utilizar, pueden variar, por eso se definen aqui\n",
    "col_area_modelo = 'Area_Model'\n",
    "col_area_h = 'Area_AH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizar superficies por valor de construccion\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "for key, val in dict_construccion.items():\n",
    "    print(key, val)\n",
    "    if existe_categoria:\n",
    "        datos.loc[datos[col_categoria].isin(casas),key] = datos[datos[col_categoria].isin(casas)][col_area_modelo].map(lambda x: Categorizar_por_intervalos(x, val[0], val[1]) )  \n",
    "    else:\n",
    "        datos[key] = datos[col_area_modelo].map(lambda x: Categorizar_por_intervalos(x, val[0], val[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['Comercial buena'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizar superficies\n",
    "for key, val in dict_intervalos.items():\n",
    "    print(key, val)\n",
    "    datos[key] = datos[col_area_modelo].map(lambda x: Categorizar_por_intervalos(x, val[0], val[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner niveles maximos\n",
    "for key,val in dict_niveles.items():\n",
    "    print(key,val)\n",
    "    datos[key] = val\n",
    "    if key.find('AlturaM')>=0:\n",
    "        datos[key] = datos[key]*datos['Medio']\n",
    "    elif key.find('AlturaP') >= 0:\n",
    "        datos[key] = datos[key]*datos['Popular']\n",
    "    elif key.find('AlturaIS') >= 0:\n",
    "        datos[key] = datos[key]*datos['Interes']\n",
    "    elif key.find('AlturaC') >= 0:\n",
    "        datos[key] = datos[key]*datos['Campestre']\n",
    "    elif key.find('AlturaR') >= 0:\n",
    "        datos[key] = datos[key]*datos['Rural']\n",
    "    elif key.find('AlturaCom') >= 0:\n",
    "        datos[key] = datos[key]*datos['Comercial']\n",
    "datos['Nivel_minimo'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner alturas maximas\n",
    "for key,val in dict_alturas.items():\n",
    "    print(key,val)\n",
    "    datos[key] = val\n",
    "    if key.find('NivelesM')>=0:\n",
    "        datos[key] = datos[key]*datos['Medio']\n",
    "    elif key.find('NivelesP') >= 0:\n",
    "        datos[key] = datos[key]*datos['Popular']\n",
    "    elif key.find('NivelesIS') >= 0:\n",
    "        datos[key] = datos[key]*datos['Interes']\n",
    "    elif key.find('NivelesC') >= 0:\n",
    "        datos[key] = datos[key]*datos['Campestre']\n",
    "    elif key.find('NivelesR') >= 0:\n",
    "        datos[key] = datos[key]*datos['Rural']\n",
    "    elif key.find('NivelesCom') >= 0:\n",
    "        datos[key] = datos[key]*datos['Comercial']\n",
    "datos['Altura_min'] = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner valores unitarios de construccion\n",
    "\n",
    "cols_vu_cons = np.array([])\n",
    "for key, val in dict_vu_construccion.items():\n",
    "    print(key,val)\n",
    "    nombre_cat = str(key).split('_')[-1]\n",
    "    datos.loc[(datos[nombre_cat]!=0), key] = val\n",
    "    cols_vu_cons = np.append(cols_vu_cons,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de altura, nivel, y valores\n",
    "cols_altura = np.array([])\n",
    "cols_nivel = np.array([])\n",
    "cols_valor_uni = np.array([])\n",
    "cols_const = np.array([])\n",
    "datos.fillna(0, inplace=True)\n",
    "\n",
    "for col in datos:\n",
    "    if col.lower().strip().startswith('altura'):\n",
    "        cols_altura = np.append(cols_altura, col)\n",
    "    elif col.lower().strip().startswith('nivel'):\n",
    "        cols_nivel = np.append(cols_nivel, col)\n",
    "    elif col.lower().strip().startswith('val'):\n",
    "        cols_valor_uni = np.append(cols_valor_uni,col)\n",
    "    elif col in list(vu_const['Categoría']):\n",
    "        cols_const = np.append(cols_const,col)\n",
    "len(cols_altura), len(cols_nivel), len(cols_valor_uni), len(cols_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos faltantes\n",
    "datos['Frente_base'] = datos['Frente']\n",
    "datos['Fondo_base']  = datos['Fondo']\n",
    "datos['Area_base']   = datos[col_area_h]\n",
    "\n",
    "if existe_categoria:\n",
    "    datos.loc[datos[col_categoria].isin(casas),'grado_conservacion'] = datos.loc[datos[col_categoria].isin(casas)][col_area_h].map(lambda x:get_grado_conservacion())\n",
    "else:\n",
    "    datos['grado_conservacion'] = datos[col_area_h].map(lambda x:get_grado_conservacion())\n",
    "datos['Area_inscrita']     = datos[col_area_modelo].map(lambda x: float(x)*random.uniform(0.65,1))\n",
    "datos['Area_construccion'] = datos[col_area_modelo]*.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas a utilizar, pueden variar, por eso se definen aqui\n",
    "col_esquinero = 'Esquinero|Intermedio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factores catastral del terreno\n",
    "\n",
    "datos.fillna(0, inplace=True)\n",
    "cols_factor_top = np.array([])\n",
    "\n",
    "datos['Factor_posicion']      = datos[col_esquinero].fillna(0).map(lambda x: get_factor_posicion(x))\n",
    "datos['Terreno_Posicion']     = datos['Factor_posicion'].map(lambda x: 'Interior' if x==0.5 else 'otro')\n",
    "datos['factor_frente']        = datos.apply(lambda x: factor_frente(x['Medida_lx'], x['Terreno_Posicion']),axis=1)\n",
    "datos['factor_fondo']         = datos.apply(lambda x: factor_fondo(x['Medida_ly'], x['Fondo_base'], x['Terreno_Posicion']), axis=1)\n",
    "\n",
    "for col in cols_altura:\n",
    "    nombre_col = 'Factor_Topografia_'+col\n",
    "    cols_factor_top = np.append(cols_factor_top, nombre_col)\n",
    "    datos[nombre_col] = datos.apply(lambda x: factor_topografia(x[col], x['Medida_ly'], x['Terreno_Posicion']), axis=1)\n",
    "\n",
    "\n",
    "datos['factor_irregularidad'] = datos.apply(lambda x: factor_irregularidad(x[col_area_modelo], x['Area_inscrita'], x['Terreno_Posicion']), axis=1)\n",
    "datos['factor_area']          = datos.apply(lambda x: factor_area(x[col_area_modelo],x['Area_base'],x['Terreno_Posicion']), axis=1)\n",
    "datos['factor_restriccion']   = datos.apply(lambda x: factor_restriccion(x[col_area_modelo],x[col_area_modelo]*0.8,x['Terreno_Posicion']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revison de valores 0 en los factores de terreno y correccion\n",
    "\n",
    "cols_ft = {'factor_frente':0.5,'factor_fondo':0.6,'factor_irregularidad':0.5,'factor_area':0.7,'factor_restriccion':0.5}\n",
    "\n",
    "for col, val in cols_ft.items():\n",
    "    s = datos[datos[col].fillna(0)==0].shape\n",
    "    \n",
    "    if s[0] != 0:\n",
    "        datos.loc[datos[col].fillna(0)==0, col] = val\n",
    "        print(col)\n",
    "    print(s)\n",
    "    \n",
    "for col in cols_factor_top:\n",
    "    s = datos[datos[col].fillna(0)==0].shape\n",
    "    if s[0] != 0:\n",
    "        print(col)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factores catastral de la construcción\n",
    "\n",
    "cols_factor_nvl = np.array([])\n",
    "\n",
    "if existe_categoria:\n",
    "    datos.loc[datos[col_categoria].isin(casas),'factor_grado_conservacion'] = datos[datos[col_categoria].isin(casas)]['grado_conservacion'].map(lambda x: factor_grado_conservacion(x))\n",
    "    datos.loc[datos[col_categoria].isin(casas),'factor_edad']               = 0.6\n",
    "else:\n",
    "    datos['factor_grado_conservacion'] = datos['grado_conservacion'].map(lambda x: factor_grado_conservacion(x))\n",
    "    datos['factor_edad']               = 0.6\n",
    "\n",
    "\n",
    "for col in cols_nivel:\n",
    "    nombre = 'factor_numero_niveles_'+col\n",
    "    cols_factor_nvl = np.append(cols_factor_nvl, nombre)\n",
    "    if existe_categoria:\n",
    "        datos.loc[datos[col_categoria].isin(casas),nombre] = datos[datos[col_categoria].isin(casas)].apply(lambda x: factor_numero_niveles(x[col],x['grado_conservacion']), axis=1)\n",
    "    else:\n",
    "        datos[nombre] = datos.apply(lambda x: factor_numero_niveles(x[col],x['grado_conservacion']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de valores 0 en los factores de construccion\n",
    "if existe_categoria:\n",
    "    print(datos[(datos[col_categoria].isin(casas))&(datos['factor_grado_conservacion'].fillna(0)==0.0)].shape)\n",
    "    print(datos[(datos[col_categoria].isin(casas))&(datos['factor_edad'].fillna(0)==0.0)].shape)\n",
    "    \n",
    "    for col in cols_factor_nvl:\n",
    "        s = datos[(datos[col_categoria].isin(casas))&(datos[col].fillna(0)==0.0)].shape\n",
    "        if s[0] != 0:\n",
    "            print(col)\n",
    "        print(s)\n",
    "else:\n",
    "    print(datos[(datos['factor_grado_conservacion'].fillna(0)==0.0)].shape)\n",
    "    print(datos[(datos['factor_edad'].fillna(0)==0.0)].shape)\n",
    "    \n",
    "    for col in cols_factor_nvl:\n",
    "        s = datos[(datos[col].fillna(0)==0.0)].shape\n",
    "        if s[0] != 0:\n",
    "            print(col)\n",
    "        print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion a flotantes de los valores que necesitamos\n",
    "\n",
    "cols_using = [col_area_modelo,'factor_frente','factor_fondo', 'factor_irregularidad','factor_area',\n",
    "              'Factor_posicion','factor_restriccion']\n",
    "datos.fillna(0,inplace=True)\n",
    "for col in cols_using:\n",
    "    datos[col] = datos[col].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Data/Valor_cat_terreno.png) \n",
    "\n",
    "Formula para obtener el valor catastral del terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor catastral del terreno\n",
    "\n",
    "cols_vc_terr = np.array([])\n",
    "\n",
    "for col_vu in cols_valor_uni:\n",
    "    name = col_vu.split('_')[-1]\n",
    "    \n",
    "    for col_ft in cols_factor_top:\n",
    "        name_col = 'Valor_catastral_terreno_'+name+'_'+col_ft.split('_')[-1]\n",
    "        datos[name_col] = datos[col_area_modelo].astype(float).fillna(0)*datos[col_vu].astype(float).fillna(0)*datos['factor_frente'].astype(float).fillna(0)*datos['factor_fondo'].fillna(0)*datos['factor_irregularidad'].fillna(0)*datos['factor_area'].fillna(0)*datos[col_ft].fillna(0)*datos['Factor_posicion'].fillna(0)*datos['factor_restriccion'].fillna(0)\n",
    "        cols_vc_terr = np.append(cols_vc_terr,name_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Data/Valor_cat_const.png) <br>\n",
    " Formula para obtener el valor catastral de la construccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor catastral de la construccion\n",
    "cols_vc_const = np.array([])\n",
    "for col_vu in cols_vu_cons:\n",
    "    i = 0\n",
    "    name = col_vu.split('_')[-1]\n",
    "    for col_nv in cols_factor_nvl:\n",
    "        name_col = 'Valor_catastral_construccion_'+name+'_'+str(i)\n",
    "        cols_vc_const = np.append(cols_vc_const,name_col)\n",
    "        datos[name_col] = datos['Area_Model'].astype(float).fillna(0)*datos[col_vu].astype(float).fillna(0)*datos['factor_edad'].astype(float).fillna(0)*datos['factor_grado_conservacion'].astype(float).fillna(0)*datos[col_nv].astype(float).fillna(0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revicion del total de columnas creadas\n",
    "print(f'Cols construccion -> {len(cols_vc_const)} \\nCols terreno      -> {len(cols_vc_terr)} \\nShape Final       -> {datos.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhkjhl1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint opcional\n",
    " <br>Hasta este punto hemos aproximado tantos valores catastrales como el numero de columnas creadas arriba.\n",
    "El siguiente proceso consume muchos recurso asi que se recomienda llevarlo a google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_file = 'New_casas_Naucalpan_proces2_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear en CSV para no truncar el nombre de columnas\n",
    "pd.DataFrame(datos).to_csv('Data/Completados/Modelo_Final/'+nombre_file+'.csv',\n",
    "                           index=False,\n",
    "                           encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el geopandas solo con las columnas utiles para reponerselas al csv\n",
    "datos[['geometry', 'cve_cat','Indice_gdf']].to_file('Data/Completados/Modelo_Final/Recuperacion_geometry/'+nombre_file+'.shp',\n",
    "                                         index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camnibio de variable otra vez\n",
    "df = datos\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df.rename(columns={'index':'Indice_Modelo'}, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matamos variables para liberar memoria\n",
    "if input('Esta seguro de matar las variables?').lower() in afirmativo:\n",
    "    if input('Realmente esta seguro de matar las variables?').lower() in afirmativo:\n",
    "        del datos\n",
    "        print('Matamos las variables datos   , ya no hay vuelta atras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las columnas de interes\n",
    "cols_terreno = np.array([])\n",
    "cols_const = np.array([])\n",
    "for col in df.columns:\n",
    "    if col.lower().find('valor_catastral_construccion')>=0:\n",
    "        cols_const = np.append(cols_const, col)\n",
    "    elif col.lower().find('valor_catastral_terreno')>=0:\n",
    "        cols_terreno = np.append(cols_terreno, col)\n",
    "len(cols_terreno), len(cols_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar que los val por m2 esten llenos\n",
    "df[(df['Val m2_Ban'].fillna(0)==0)&(df['Val m2_Man'].fillna(0)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los estadisticos de interes, esta parte es la mas pesada\n",
    "df['Estadisticos_terreno'] = df.apply(lambda x: statistics_values(x[cols_terreno]), axis=1)\n",
    "df[df['Estadisticos_terreno']=='Revisar'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los estadisticos de interes, esta parte es la mas pesada\n",
    "df['Estadisticos_construccion'] = df.apply(lambda x: statistics_values(x[cols_const]), axis=1)\n",
    "df[df['Estadisticos_construccion']=='Revisar'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos formatoa las cols Minimo, Maximo, Media, desviacion_estandar, largo, media_percentil, desviacion_std_percentiles, moda_percentiles\n",
    "df = pd.concat([df,\n",
    "                df['Estadisticos_terreno'].str.split('|', expand=True).rename(columns={0:   'Min_terreno',\n",
    "                                                                                       1:   'Max_terreno',\n",
    "                                                                                       2: 'Media_terreno',\n",
    "                                                                                       3:   'STD_terreno',\n",
    "                                                                                       4:   'Len_terreno',\n",
    "                                                                                       5:'MediaP_terreno',\n",
    "                                                                                       6:  'STDP_terreno',\n",
    "                                                                                       7: 'ModaP_terreno'})], axis=1)\n",
    "\n",
    "df = pd.concat([df,\n",
    "                df['Estadisticos_construccion'].str.split('|', expand=True).rename(columns={0:   'Min_construccion',\n",
    "                                                                                            1:   'Max_construccion',\n",
    "                                                                                            2: 'Media_construccion',\n",
    "                                                                                            3:   'STD_construccion',\n",
    "                                                                                            4:   'Len_construccion',\n",
    "                                                                                            5:'MediaP_construccion',\n",
    "                                                                                            6:  'STDP_construccion',\n",
    "                                                                                            7: 'ModaP_construccion'})], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo del intervalo de confianza suponiendo distribucion normal en los valores catastrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor z con nivel de significancia al 95%\n",
    "z = stats.norm.ppf(.95)\n",
    "z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./Data/Valor_cat_final.png)\n",
    "\n",
    "Formula para obtener el valor catastral final \n",
    "\n",
    "![alt text](./Data/Intervalo_confianza_norm.png) Formula para intervalo de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_estadisticos = ['Media_terreno','STD_terreno','Len_terreno','Media_construccion','STD_construccion','Len_construccion']\n",
    "\n",
    "for col in cols_estadisticos:\n",
    "    try:\n",
    "        df[col] = df[col].astype(float)\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Media_terreno']#- (z*df['STD_terreno']/df['Len_terreno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limite inferior (LI) y superior (LS) de cada valor catastral\n",
    "df['LI_95%_vc_terreno'] = df['Media_terreno']- (z*df['STD_terreno']/df['Len_terreno'])\n",
    "df['LS_95%_vc_terreno'] = df['Media_terreno']+ (z*df['STD_terreno']/df['Len_terreno']) \n",
    "\n",
    "df['LI_95%_vc_construccion'] = df['Media_construccion']- (z*df['STD_construccion']/df['Len_construccion'])\n",
    "df['LS_95%_vc_construccion'] = df['Media_construccion']+ (z*df['STD_construccion']/df['Len_construccion']) \n",
    "\n",
    "df['LI_95%_catastral_final'] = df['LI_95%_vc_terreno'] + df['LI_95%_vc_construccion'] \n",
    "df['LS_95%_catastral_final'] = df['LS_95%_vc_terreno'] + df['LS_95%_vc_construccion'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo cols de interes\n",
    "df[np.append(cols_estadisticos,[])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En caso de haber hecho checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de haber hecho checkpoint\n",
    "path_gdf =  'Data/Completados/Modelo_Final/Recuperacion_geometry/'+nombre_file+'.shp'\n",
    "gdf = gpd.read_file(path_gdf)\n",
    "gdf.rename(columns={'Indice_gdf':'Indice_gdf1'},inplace=True)\n",
    "\n",
    "final = gpd.GeoDataFrame(pd.concat([gdf[['geometry', 'cve_cat','Indice_gdf1']] , df[cols_new]], axis=1), geometry='geometry')\n",
    "final.tail(2)\n",
    "\n",
    "gdf.shape, final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de empatamiento \n",
    "final[final['Indice_gdf']!=final['Indice_gdf1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el GeoDataFrame\n",
    "final.to_file('/content/drive/MyDrive/Equipo_Agua/Geo/Data/Completados/Modelo_Final/Solo_VC_Final/NewCasas_Valor_Catastral_Naucalpan_Final_v1.shp',\n",
    "                                                  index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En caso de no haber hecho checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del predial\n",
    "calculo_predial(83783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya terminamos solo exportamos el geodataframe\n",
    "df.to_file('/content/drive/MyDrive/Equipo_Agua/Geo/Data/Completados/Modelo_Final/Solo_VC_Final/NewCasas_Valor_Catastral_Naucalpan_Final_v1.shp',\n",
    "                                                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inteligencia_fiscal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
