{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tqdm\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta raiz\n",
    "PATH=r\"C:\\Users\\ASUS\\modelado3d\\render\\resnder1\\ortofoto\"\n",
    "#ruta de datos de entrada\n",
    "INPATH=PATH + '/input'\n",
    "#ruta de datos de salida\n",
    "OUPATH=PATH + '/target'\n",
    "#ruta de checkpoints\n",
    "CKPATH=r\"D:\\checkpoint\"#PATH+'/ckp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini=[str(x)[len(INPATH)+1:] for x in glob.glob(INPATH+\"/*.png\")]\n",
    "tar=[x[len(OUPATH)+1:] for x in glob.glob(OUPATH+\"/*.png\")]\n",
    "imgurls=[\"/\"+str(x) for x in ini if x in tar]\n",
    "# tar=[\"/\"+str(x) for x in tar if x in ini] \n",
    "n=len(imgurls)\n",
    "train_n=round(n*0.8)\n",
    "#listado random\n",
    "randurls=np.copy(imgurls)\n",
    "# np.random.seed(3)\n",
    "np.random.shuffle(randurls)\n",
    " \n",
    "#particion train/test\n",
    "tr_urls=randurls[:train_n]\n",
    "ts_urls=randurls[train_n:n]\n",
    "# print(imgurls)\n",
    "print(len(imgurls),len(tr_urls),len(ts_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=256\n",
    "IMG_HEIGHT=IMG_WIDTH\n",
    " \n",
    "#Reescalar imagen\n",
    "def resize(inimg,tgimg,height,width):\n",
    "    #inimg=tf.image.resize(inimg,[250,250])\n",
    "    #inimg=tf.image.resize(inimg,[128,128])\n",
    "    inimg=tf.image.resize(inimg,[height,width])\n",
    "    tgimg=tf.image.resize(tgimg,[height,width])\n",
    "    return inimg,tgimg\n",
    " \n",
    "#normaliza al rango [-1:1] la imagen\n",
    "def normalize(inimg,tgimg):\n",
    "    inimg=(inimg/127.5)-1\n",
    "    tgimg=(tgimg/127.5)-1\n",
    "    return inimg,tgimg\n",
    " \n",
    "@tf.function()\n",
    "#aumentar datos: Randomcrop+flip\n",
    "def random_jitter(inimg,tgimg):\n",
    "    inimg,tgimg=resize(inimg,tgimg,int(IMG_WIDTH*1.3),int(IMG_WIDTH*1.3))\n",
    "    stacked_image=tf.stack([inimg,tgimg],axis=0)\n",
    "    cropped_image=tf.image.random_crop(stacked_image,size=[2,IMG_HEIGHT,IMG_WIDTH,3])\n",
    "    inimg,tgimg=cropped_image[0],cropped_image[1]\n",
    "    return inimg,tgimg \n",
    " \n",
    "def load_image(filename,augment=True):\n",
    "    inimg=tf.cast(tf.image.decode_jpeg(tf.io.read_file(INPATH+filename)),tf.float32)[...,:3]\n",
    "    tgimg=tf.cast(tf.image.decode_jpeg(tf.io.read_file(OUPATH+filename)),tf.float32)[...,:3]\n",
    "    inimg,tgimg=resize(inimg,tgimg,IMG_HEIGHT,IMG_WIDTH)    \n",
    "    if augment:\n",
    "        inimg,tgimg=random_jitter(inimg,tgimg)\n",
    "    inimg,tgimg=normalize(inimg,tgimg)\n",
    "    return inimg,tgimg\n",
    " \n",
    " \n",
    "def load_train_image(filename):\n",
    "    return load_image(filename,True)\n",
    " \n",
    "def load_test_image(filename):\n",
    "    return load_image(filename,True)\n",
    " \n",
    "plt.imshow(((load_train_image(randurls[0])[1])+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.data.Dataset.from_tensor_slices(tr_urls)\n",
    "train_dataset=train_dataset.map(load_train_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset=train_dataset.batch(1)\n",
    " \n",
    "test_dataset=tf.data.Dataset.from_tensor_slices(ts_urls)\n",
    "test_dataset=test_dataset.map(load_test_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset=test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, apply_batchnorm=True):\n",
    "  result=Sequential()\n",
    "  initializer=tf.random_normal_initializer(0,0.02)\n",
    "  #capa convolucional\n",
    "  result.add(Conv2D(filters,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=initializer,\n",
    "                    use_bias=not apply_batchnorm))\n",
    "  if apply_batchnorm:\n",
    "    #capa BatchNorm\n",
    "    result.add(BatchNormalization())\n",
    "  #capa de activacion\n",
    "  result.add(LeakyReLU())\n",
    "  return result\n",
    "\n",
    "def upsample(filters, apply_dropout=False):\n",
    "  result=Sequential()\n",
    "  initializer=tf.random_normal_initializer(0,0.02)\n",
    "  #capa convolucional\n",
    "  result.add(Conv2DTranspose(filters,\n",
    "                             kernel_size=4,\n",
    "                             strides=2,\n",
    "                             padding=\"same\",\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "  #capa BatchNorm\n",
    "  result.add(BatchNormalization())\n",
    "  if apply_dropout:\n",
    "    #capa de Dropout\n",
    "    result.add(Dropout(0.1))\n",
    "  #capa de activacion\n",
    "  result.add(LeakyReLU())##\n",
    "  return result\n",
    "\n",
    "def Generator():\n",
    "    inputs=tf.keras.layers.Input(shape=[IMG_WIDTH,IMG_WIDTH,3])\n",
    "    down_stack=[downsample(64,apply_batchnorm=True),\n",
    "              downsample(128),\n",
    "              downsample(256),\n",
    "              downsample(512),\n",
    "              downsample(512),\n",
    "              downsample(512)]\n",
    "\n",
    "    up_stack=[upsample(512,apply_dropout=True),\n",
    "            upsample(512),\n",
    "            upsample(256),\n",
    "            upsample(128),\n",
    "            upsample(64)]\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    last=Conv2DTranspose(filters=3,\n",
    "                       kernel_size=4,\n",
    "                       strides=2,\n",
    "                       padding=\"same\",\n",
    "                       kernel_initializer=initializer,\n",
    "                       activation=\"tanh\")  \n",
    "    x=inputs\n",
    "    s=[]\n",
    "    concat=Concatenate()\n",
    "    for down in down_stack:\n",
    "        x=down(x)\n",
    "        s.append(x)\n",
    "    s=reversed(s[:-1]) \n",
    "    for up,sk in zip(up_stack,s):\n",
    "        x=up(x)\n",
    "        x=concat([x,sk])\n",
    "    last=last(x)\n",
    "    return Model(inputs=inputs,outputs=last)\n",
    "\n",
    "generator=Generator()\n",
    "generator.summary()\n",
    "\n",
    "def Discriminator():\n",
    "  ini=Input(shape=[None,None,3],name=\"input_img\")\n",
    "  gen=Input(shape=[None,None,3],name=\"gener_img\")\n",
    "  con=concatenate([ini,gen])\n",
    "  initializer=tf.random_normal_initializer(0,0.02)\n",
    "  down1=downsample(64,apply_batchnorm=False)(con)\n",
    "  down2=downsample(128)(down1)\n",
    "  down3=downsample(256)(down2)\n",
    "  down4=downsample(512)(down3)\n",
    "  last=tf.keras.layers.Conv2D(filters=1,\n",
    "                              kernel_size=4,\n",
    "                              strides=1,\n",
    "                              kernel_initializer=initializer,\n",
    "                              padding=\"same\")(down4)\n",
    "  return tf.keras.Model(inputs=[ini,gen],outputs=last)\n",
    "\n",
    "discriminator=Discriminator()\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4,beta_1=0.5)\n",
    "discriminator_optimizer=tf.keras.optimizers.Adam(2e-4,beta_1=0.5)\n",
    " \n",
    "checkpoint_prefix=os.path.join(CKPATH,\"ortofoto_2\")\n",
    "checkpoint=tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                               discriminator_optimizer=discriminator_optimizer,\n",
    "                              generator=generator,\n",
    "                               discriminator=discriminator)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(CKPATH)).expect_partial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output,disc_generated_output):\n",
    "  #diferencia entre los true por ser real y el detectado por el discriminador\n",
    "  real_loss=loss_object(tf.ones_like(disc_real_output),disc_real_output)\n",
    "  #diferencia entre los false por ser generado y el detectado por el discriminador\n",
    "  generated_loss=loss_object(tf.zeros_like(disc_generated_output),disc_generated_output)\n",
    " \n",
    "  total_disc_loss=real_loss+generated_loss\n",
    "  return total_disc_loss\n",
    "\n",
    "LAMBDA=100\n",
    "def generator_loss(disc_generated_output,gen_output,target):\n",
    "  gan_loss=loss_object(tf.ones_like(disc_generated_output),disc_generated_output)\n",
    "  #mean absolute error\n",
    "  l1_loss=tf.reduce_mean(tf.abs(target-gen_output))\n",
    "  total_gen_loss=gan_loss+(LAMBDA*l1_loss)\n",
    "  return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(model,test_input,tar,save_filename=False,display_imgs=True):\n",
    "  prediction=model(test_input,training=True)\n",
    "  if save_filename:\n",
    "    tf.keras.preprocessing.image.save_img(PATH+'/output/'+ save_filename+'.jpg',prediction[0,...])\n",
    "    \n",
    "  plt.figure(figsize=(10,10))\n",
    "  display_list=[test_input[0],tar[0],prediction[0]]\n",
    "  title=['Input image', 'Ground truth', 'predicted Image']\n",
    " \n",
    "  if display_imgs:\n",
    "    for i in range(3):\n",
    "      plt.subplot(1,3,i+1)\n",
    "      plt.title(title[i])\n",
    "      plt.imshow(display_list[i]*0.5+0.5)\n",
    "      plt.axis('on')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image,target):\n",
    "  with tf.GradientTape() as gen_tape,tf.GradientTape() as discr_tape:\n",
    "    output_image=generator(input_image,training=True)\n",
    "    output_gen_discr=discriminator([output_image,input_image],training=True)\n",
    "    output_trg_discr=discriminator([target,input_image],training=True)\n",
    "    discr_loss= discriminator_loss(output_trg_discr,output_gen_discr)\n",
    "    gen_loss=generator_loss(output_gen_discr,output_image,target)\n",
    "    generator_grads=gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    discriminator_grads=discr_tape.gradient(discr_loss,discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_grads,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_grads,discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epoch):\n",
    "  for epoch in tqdm.tqdm(range(epoch)):\n",
    "    for input_image, target in dataset:\n",
    "      train_step(input_image,target)\n",
    "    for inp,tar in test_dataset.take(5):\n",
    "      generate_image(generator,inp,tar,str(imgi)+'_'+str(epoch),display_imgs=True)\n",
    "    if(epoch +1)%20==0:\n",
    "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "      print(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset,60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
