{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        # transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        # transforms.RandomRotation(degrees=15),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        # transforms.Resize(size=256),\n",
    "        # transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "{0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Set train and valid directory paths\n",
    "\n",
    "dataset = r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\"\n",
    "train_directory = os.path.join(dataset, 'train_pad')\n",
    "valid_directory = os.path.join(dataset, 'validacion_pad')\n",
    "\n",
    "# Batch size\n",
    "bs = 1\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  #10#2#257\n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5584, 1804)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size, valid_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "# alexnet.classifier[6] = nn.Linear(4096, 800)\n",
    "# # alexnet.classifier[7] = nn.Linear(800, num_classes)\n",
    "# # alexnet.classifier[8] =nn.Softmax()\n",
    "# alexnet.classifier.add_module(\"7\", nn.Linear(800, num_classes))\n",
    "# # alexnet.classifier.add_module(\"8\",nn.Softmax())\n",
    "# alexnet.classifier.add_module(\"8\", nn.LogSoftmax(dim = 1))\n",
    "# alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=7, bias=True)\n",
       "    (7): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 7]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
      "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
      "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
      "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
      "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
      "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
      "==========================================================================================\n",
      "Total params: 57,032,519\n",
      "Trainable params: 28,679\n",
      "Non-trainable params: 57,003,840\n",
      "Total mult-adds (M): 767.14\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 217.56\n",
      "Estimated Total Size (MB): 221.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 7]                   --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
       "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
       "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
       "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
       "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
       "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
       "==========================================================================================\n",
       "Total params: 57,032,519\n",
       "Trainable params: 28,679\n",
       "Non-trainable params: 57,003,840\n",
       "Total mult-adds (M): 767.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.76\n",
       "Params size (MB): 217.56\n",
       "Estimated Total Size (MB): 221.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(alexnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "loss_func = nn.NLLLoss()\n",
    "#loss_func=nn.MSELoss()\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lr=0.00001,params=alexnet.parameters())#alexnet.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25,device=0):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in tqdm.tqdm(enumerate(train_data_loader),total=len(train_data_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in tqdm.tqdm(enumerate(valid_data_loader),total=len(valid_data_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                \n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##restore_checkpoint\n",
    "checkpoint=torch.load(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\ckpoint\\best_model1.pth\")\n",
    "alexnet.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:57<00:00, 97.73it/s] \n",
      "100%|██████████| 1804/1804 [00:15<00:00, 114.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 001, Training: Loss: 0.3685, Accuracy: 89.3983%, \n",
      "\t\tValidation : Loss : 0.2898, Accuracy: 93.1818%, Time: 72.8629s\n",
      "Epoch: 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:52<00:00, 106.70it/s]\n",
      "100%|██████████| 1804/1804 [00:15<00:00, 115.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 002, Training: Loss: 0.3397, Accuracy: 89.8639%, \n",
      "\t\tValidation : Loss : 0.3271, Accuracy: 91.6851%, Time: 67.9690s\n",
      "Epoch: 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:45<00:00, 122.97it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 132.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 003, Training: Loss: 0.3139, Accuracy: 89.7206%, \n",
      "\t\tValidation : Loss : 0.3448, Accuracy: 90.9091%, Time: 58.9850s\n",
      "Epoch: 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:43<00:00, 127.79it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 132.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 004, Training: Loss: 0.3056, Accuracy: 90.4907%, \n",
      "\t\tValidation : Loss : 0.3482, Accuracy: 90.1885%, Time: 57.3646s\n",
      "Epoch: 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 130.03it/s]\n",
      "100%|██████████| 1804/1804 [00:15<00:00, 119.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 005, Training: Loss: 0.3033, Accuracy: 90.3295%, \n",
      "\t\tValidation : Loss : 0.3582, Accuracy: 90.1330%, Time: 58.0027s\n",
      "Epoch: 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 130.69it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 134.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 006, Training: Loss: 0.2990, Accuracy: 90.1146%, \n",
      "\t\tValidation : Loss : 0.3389, Accuracy: 90.1330%, Time: 56.1352s\n",
      "Epoch: 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 130.34it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 137.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 007, Training: Loss: 0.2920, Accuracy: 90.7235%, \n",
      "\t\tValidation : Loss : 0.4135, Accuracy: 86.6962%, Time: 55.9262s\n",
      "Epoch: 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:44<00:00, 125.68it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 138.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 008, Training: Loss: 0.2858, Accuracy: 90.5623%, \n",
      "\t\tValidation : Loss : 0.3694, Accuracy: 89.2461%, Time: 57.5032s\n",
      "Epoch: 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:43<00:00, 129.47it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 133.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 009, Training: Loss: 0.2878, Accuracy: 90.1862%, \n",
      "\t\tValidation : Loss : 0.3953, Accuracy: 87.3060%, Time: 56.6633s\n",
      "Epoch: 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:43<00:00, 129.11it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 136.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 010, Training: Loss: 0.2867, Accuracy: 90.4011%, \n",
      "\t\tValidation : Loss : 0.3707, Accuracy: 88.7472%, Time: 56.4346s\n",
      "Epoch: 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 130.06it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 135.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 011, Training: Loss: 0.2797, Accuracy: 90.6519%, \n",
      "\t\tValidation : Loss : 0.3958, Accuracy: 87.4723%, Time: 56.2789s\n",
      "Epoch: 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:43<00:00, 129.59it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 137.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 012, Training: Loss: 0.2823, Accuracy: 90.6698%, \n",
      "\t\tValidation : Loss : 0.3704, Accuracy: 88.6364%, Time: 56.1974s\n",
      "Epoch: 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 131.92it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 134.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 013, Training: Loss: 0.2781, Accuracy: 90.7593%, \n",
      "\t\tValidation : Loss : 0.3913, Accuracy: 87.8603%, Time: 55.7585s\n",
      "Epoch: 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:42<00:00, 130.28it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 137.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 014, Training: Loss: 0.2776, Accuracy: 90.8847%, \n",
      "\t\tValidation : Loss : 0.3875, Accuracy: 88.2483%, Time: 55.9409s\n",
      "Epoch: 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5584/5584 [00:43<00:00, 129.36it/s]\n",
      "100%|██████████| 1804/1804 [00:13<00:00, 134.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 015, Training: Loss: 0.2754, Accuracy: 90.5623%, \n",
      "\t\tValidation : Loss : 0.4215, Accuracy: 86.9180%, Time: 56.5464s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(0)\n",
    "num_epochs =15\n",
    "trained_model, history = train_and_validate(alexnet, loss_func, optimizer, num_epochs)\n",
    "\n",
    "#torch.save(history, dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ñ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12084/1031318041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mñ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ñ' is not defined"
     ]
    }
   ],
   "source": [
    "ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({    'epoch': 111,\n",
    "                'model_state_dict': alexnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss_func,\n",
    "                }, r'C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\ckpoint/best_model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmOklEQVR4nO3de3hU9b3v8fd3ZhKScA8gKqDQFryDVYrWK1tOu7VSsRVFut2t2uqxrdbL6Tm1d92t++l2a22t3Sr1oLWbhtpWtpfj/d6txRqVO16ooERQINwMJCQz8z1/rDXJJMyE4TKZJOvzep71rFmXWfMlJL/PrNtvmbsjIiLRFSt1ASIiUloKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARibiiBYGZzTazdWa2JM9yM7NbzWyFmS0ys2OKVYuIiORXzD2Ce4DTO1l+BjA2HC4Fbi9iLSIikkfRgsDdXwA2drLKNOBeD8wHBpnZAcWqR0REckuU8LNHAKuzpuvCeWs7rmhmlxLsNdC3b99jDz300C4pUESkt3j11Vc3uPuwXMtKGQSWY17O/i7cfRYwC2DixIleW1tbzLpERHodM3s337JSXjVUB4zKmh4JrClRLSIikVXKIHgQ+HJ49dDxwBZ33+mwkIiIFFfRDg2ZWQ0wGRhqZnXAj4EyAHe/A3gE+BywAtgOXFSsWkREJL+iBYG7z9zFcge+WazPFxGRwujOYhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxpex0rmt9uAxeuxeGfByGfAKGjoX+B0JMWSgi0RadIKhfEQRBy7a2eYnKtmDIDEPHBvMqB5euVhGRLhSdIDj8LDjs8/DR2iAU6lfAhnD8wWJY/hB4qm39qiEwZGwYDllBUf0xSPQp3b9DRGQfi04QAJjBgAODYcwp7Zclm2Hzu1kh8TbU/x1WPAUL/jNrGzEYOCpr7+ETMOjgIDiqqoNxn/7BZ4mI9ADRCoLOJMqDhn3o2J2XNW2FjX8PgmHD221h8frL0Nyw8/qxsjAYMuFQnTWdNb8ya355X4WHiJSEgqAQFQPgwE8GQzZ3aPgQNq+Gxo2wvb7DsDEY1r0RTDduBE/n/ox4n53DozIzHhy8rhzcfrpiIMT1X1iIllSaj5qSbG1s4aOmJCl3EjEjHjPK4kY8FmudbhvHiMeD6cw8U1jnlE47zak0zak0ngbPetighy+9ddo7TLdtp/V9O70H0u6k3XGHVNrD6bb56XTW68z8dO7XKXfcnVS6bVuZcTIVLE+ng3Eq3TakW9+TDsZ51ouZ0acsRkUiTp+yGH0SMfok4lSUBeM+iViwvCyed1mfRJx4rGt+39SK7A0z6L9/MBQinYamzWFA1LeFw07hUR+ct9i+MVg/X3hAEAZhMKQrB9NcNpDGxAC2xfrzkfVnk/ejPt2PdckqPkxW8sGOClKWIBaLE48bsViCeMzC6RiJuBGPJYjFYiTisayGMbMsq2GMt288E/EY5fGgAS1LxCiLWTAO1ytPBOOyeCwcMu8Jtp3I09C6O40tKbY2JvmoqYWtTS1sDRv1rU3hvNZlmca+/bLGllSOH97ui3cIi7J2PyOjoiz4g64si4ev4+HrcF55nIpEnMrytvnZ61W2Lm+bX56IkUw5Lal0ODjJsNFtmx+Mk+k0zUknmU63m9+STJMMG+vs9zQng/Vaxx1etyQ9x7w0zSmnOZkKtpFKk0rnfMpsJMRjRtyMWIxwbLjDjvDnszfK4tYaDhVlcS44/mC+Pvnj+6jyNgqCAmQaom07UmxvTraNm1Ns35GkOZVu12DGY7R+w4yZtTagcTPisTiJ+H4kKoYTq2z71hksC7YRC8fbm1Ns2tbE1k31bNuynqYtG2huqCfVUE+6cSOxxk0kmrfQZ+tmKjdtpV96JYPYxiBrYKRt2/U/rABpN9IYjuGAE8OBdIcx4fI90RwOhNuBtqNkGxjE/0sdxwPJ41nhI/NuoyxuDKwso39FGQMqEvSvKGP/gRUMqCijf0WibRyuk4gZybSTSgcNYirtrdPJ8FtdMhU0qMm0k0p52/x00BBnT6fSQQPblEzR1JKmsTlFw44k6z/aQVNLOK8lRVNLih3JToK9i5hBWSxGeSIYyuJBqJUngmAuT7SF9YDyMsrjljWv43rt3xvLCvPMS2udtpzzsw+LWodZFs6JGcTCv6mY0bqHFrOgAc68jllm7y3365gRrpvVgMfa/gbj4Wdk/z1mGvjWeR22lU8qHYRt5v99RzIYt063dL5sR/j7lFk2qrpyL/7X84tMEKzZ3Ejtu5vYvqOtAd/WvHPD3pijod/ekmq3+1paQ6gs24/qvuUM7lvG4AHlDK4qD6arwnlV5VRXxhmaaGJw7CMG0kCf5i3QuCkY0slgX9vTQDh2D/fRvd2ymKeJuePpNGkPh3SaWNpJp1PEPBh7OtzVdsJd7o677Xl20dPBwYC2Xf32u/jDm1ZyecM8rojfz6b+4/hg1Jls/cTnKR/6saDRrwwa+T6JWI85bJNOZwVGGA6NzamdAiMzbk6mg72quLU2zsFeVozyRLgHlj0/buFeVtu8dvN1mKvLxGMW7P2Vx0tdSqciEwSvv7eZb9W83m5eeSJG3/I4VeUJqsrjVPVJ0Lc8zoGDyunbJ5jfN2t+67g80bq8qjxOWTzW2qi1fUPMvE6TTkMynW53DDGZfTwyPMYYfPNs+6ZZWR5vbeQHVZW1NvYVZV3/S2VAPBy63EcfwLIHGLzkzwxedgssuwUOPAaOPAeO+AKUjShFVZDcAXWvwMq/wKq/wPuvwcARcMAE2H98MD5gQnBeJ0ssZuHvTmnKFunIvPt81S3IxIkTvba2drfft7WphXVbd+zUgEsPs/k9WDoPlvwZ1i4M5h10Ahx1Dhw2DfoNK95np1qCxn7VC0Hjv/plSDYBFjT4oybB1jWwdhFsea/tfQMPggOygmH/8cF5pa74Rp5OwZbVwRVvG98Jx+HrZDMMOggGHxxcAp39uv/+ECtB7KfTwQUYW98P6t5SFwwNHwZX1mVfeZd91V1VNVQMUk8BnTCzV919Ys5lUQkC6YU2rICl98PiP8GGN8Hi8LFTgz2FQ6dC5aC92346BWsXtH3jf/evbXemDz8SRp8MY06Gg0/Y+U707Rvhg0VBWK1dGIRD/Qpar4Ppu18YDFkBMejgPQuHdBq21mU19FkN/qZVkGo7A0NZFVR/HKrHQKIiCNbN7wY3WmaLlcGgUUE4DDo4KyzCwOi3357V2rQ1bOTrshr6rOmtayDd0v495f2g33Bo2R5cSJH978lmsaxw6DjuMFQObrvnJ9kELY3B9nOOs4dcyzrMSzYFN50OHr3zMGBEaQIWBYH0du6wblmwl7Dkz0HjFyuDsZ+BI74Ih5wBffrtejvpNHy4JGj0V/4F3n0JdmwJlg09JGj0R58Mo0+CvkN3v84dH8EHS4JgyITEuuVtd7RXDGx/SOmACcENi7F4UNtHa9vuZ9n4d6h/J/x2vxJSO9o+J1EZ3AFfPSboLqX6423jfHsiLU1BY7x5VRAOm95tC4lN78L2De3XT1SGIZHZizioLSSSTW3f5DsOmZ9nhsWDGzwHjmwbBowIbtrMTFcMbKvZPbh3J/vy7I6XbTfmmJ9O7v7/V14WBGpZZdY4e6gKatz0bhBu2Z+dCdh2ATEmHB8c/FuLREEg0eEOa16DJfcHw0drgkZr3D8GewpjPxP8sWbWXf8mrHwhONyz6sWgEYHgj3PMKcEw+qTCLxHeXS1NQYhl9hw+WBSERaZhL6sKGsPNqyHZ2Pa+eJ+goa/+OAz5WIfG/oB9f4ikedvOAZEJic3vQtOW3O+rHBw26KOyGvms6a44BOUOO7aGobCpfUA0NwR7Ru0a9I6NfIdliT6F7w2lksHe2qZVuYfGTe3Xr6zOvSeR2ZvYi/uGFAQSTek0rJ4f7CUs/a/gW215fzj0c8Hx/lX/DdvWBesOHBUe6jkl+OY/MP+lqkWXaoENbwWHk9YuDBqSQQcH3/Izjf2AEd3reHjj5jAg3gsazIGjghPn5X1LXVn31rg5DNRVbcPGlcF4p72JBJx0DZz2/T36KAWBSCoZfOtfcj8sfzDYS8gc6hlzSvCNS5dTSneSSgbnU7JD4qDjg73bPaAgEMmW+Z1Xwy8R0lkQROY+ApFWCgCRdrrRQUYRESkFBYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJuKIGgZmdbmZvmtkKM7s2x/KBZvaQmS00s6VmdlEx6xERkZ0VLQjMLA78GjgDOByYaWaHd1jtm8Ayd58ATAZuNjM9wE9EpAsVc49gErDC3d9x92ZgLjCtwzoO9LfgKdr9gI3AvnyChIiI7EIxg2AEsDprui6cl+024DBgDbAYuNLd0x03ZGaXmlmtmdWuX7++WPWKiERSMYMgVxePHfu8/kdgAXAgcDRwm5kN2OlN7rPcfaK7Txw2rIgPJxcRiaBiBkEdMCpreiTBN/9sFwH3e2AFsBI4tIg1iYhIB8UMgleAsWY2JjwBfD7wYId13gOmAJjZcOAQ4J0i1iQiIh0U7cE07p40s8uBx4E4MNvdl5rZZeHyO4CfAPeY2WKCQ0nfcfcNxapJRER2VtQnlLn7I8AjHebdkfV6DfDZYtYgIiKd053FIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJuKIGgZmdbmZvmtkKM7s2zzqTzWyBmS01s+eLWY+IiOwsUawNm1kc+DXwGaAOeMXMHnT3ZVnrDAL+Azjd3d8zs/2KVY+IiORWzD2CScAKd3/H3ZuBucC0Dut8Cbjf3d8DcPd1RaxHRERyKGYQjABWZ03XhfOyjQMGm9lzZvaqmX0514bM7FIzqzWz2vXr1xepXBGRaCpmEFiOed5hOgEcC5wJ/CPwQzMbt9Ob3Ge5+0R3nzhs2LB9X6mISITtMgjMbKqZ7Ulg1AGjsqZHAmtyrPOYu29z9w3AC8CEPfgsERHZQ4U08OcDb5vZjWZ22G5s+xVgrJmNMbPycDsPdljnAeBkM0uYWRVwHLB8Nz5DRET20i6vGnL3C8xsADATuNvMHLgbqHH3jzp5X9LMLgceB+LAbHdfamaXhcvvcPflZvYYsAhIA3e5+5K9/2eJiEihzL3jYfs8K5oNBS4AriL41v4J4FZ3/1XRqsth4sSJXltb25UfKSLS45nZq+4+MdeyQs4RfN7M5gHPAGXAJHc/g+BY/rf3aaUiItLlCrmh7FzgFnd/IXumu283s4uLU5aIiHSVQoLgx8DazISZVQLD3X2Vuz9dtMpERKRLFHLV0B8JTuRmpMJ5IiLSCxQSBImwiwgAwtflxStJRES6UiFBsN7MzspMmNk0YEPxShIRka5UyDmCy4A5ZnYbQbcRq4GcfQKJiEjPU8gNZX8HjjezfgT3HeS9iUxERHqegp5HYGZnAkcAFWZBX3Lu/i9FrEtERLpIITeU3QHMAK4gODR0LnBwkesSEZEuUsjJ4hPc/cvAJne/Hvg07XsVFRGRHqyQIGgKx9vN7ECgBRhTvJJERKQrFXKO4KHw2cL/DrxG8HCZ3xSzKBER6TqdBkH4QJqn3X0z8GczexiocPctXVGciIgUX6eHhtw9DdycNb1DISAi0rsUco7gCTM7xzLXjYqISK9SyDmCa4C+QNLMmgguIXV3H1DUykREpEsUcmdx/64oRERESmOXQWBmp+Sa3/FBNSIi0jMVcmjof2e9rgAmAa8CpxWlIhER6VKFHBr6fPa0mY0CbixaRSIi0qUKuWqoozrgyH1diIiIlEYh5wh+RXA3MQTBcTSwsIg1iYhIFyrkHEFt1uskUOPuLxapHhER6WKFBMGfgCZ3TwGYWdzMqtx9e3FLExGRrlDIOYKngcqs6UrgqeKUIyIiXa2QIKhw94bMRPi6qngliYhIVyokCLaZ2TGZCTM7FmgsXkkiItKVCjlHcBXwRzNbE04fQPDoShER6QUKuaHsFTM7FDiEoMO5N9y9peiViYhIlyjk4fXfBPq6+xJ3Xwz0M7NvFL80ERHpCoWcI7gkfEIZAO6+CbikaBWJiEiXKiQIYtkPpTGzOFBevJJERKQrFXKy+HHgPjO7g6CricuAR4talYiIdJlCguA7wKXA1wlOFr9OcOWQiIj0Ars8NBQ+wH4+8A4wEZgCLC9k42Z2upm9aWYrzOzaTtb7lJmlzGx6gXWLiMg+knePwMzGAecDM4F64A8A7v4PhWw4PJfwa+AzBF1Xv2JmD7r7shzr/RvBISgREeline0RvEHw7f/z7n6Su/8KSO3GticBK9z9HXdvBuYC03KsdwXwZ2DdbmxbRET2kc6C4BzgA+BZM/uNmU0hOEdQqBHA6qzpunBeKzMbAXwBuKOzDZnZpWZWa2a169ev340SRERkV/IGgbvPc/cZwKHAc8DVwHAzu93MPlvAtnOFhneY/gXwnUwX153UMsvdJ7r7xGHDhhXw0SIiUqhCupjYBswB5phZNXAucC3wxC7eWgeMypoeCazpsM5EYG54m8JQ4HNmlnT3/yqoehER2WuFXD7ayt03AneGw668Aow1szHA+wQnnr/UYXtjMq/N7B7gYYWAiEjX2q0g2B3unjSzywmuBooDs919qZldFi7v9LyAiIh0jaIFAYC7PwI80mFezgBw9wuLWYuIiORWSF9DIiLSiykIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIq6oQWBmp5vZm2a2wsyuzbH8n8xsUTi8ZGYTilmPiIjsrGhBYGZx4NfAGcDhwEwzO7zDaiuBU919PPATYFax6hERkdyKuUcwCVjh7u+4ezMwF5iWvYK7v+Tum8LJ+cDIItYjIiI5FDMIRgCrs6brwnn5fBV4NNcCM7vUzGrNrHb9+vX7sEQRESlmEFiOeZ5zRbN/IAiC7+Ra7u6z3H2iu08cNmzYPixRREQSRdx2HTAqa3oksKbjSmY2HrgLOMPd64tYj4iI5FDMPYJXgLFmNsbMyoHzgQezVzCzg4D7gX9297eKWIuIiORRtD0Cd0+a2eXA40AcmO3uS83ssnD5HcCPgCHAf5gZQNLdJxarJhER2Zm55zxs321NnDjRa2trS12GiEiPYmav5vuiXcxzBF2mpaWFuro6mpqaSl1K5FVUVDBy5EjKyspKXYqIFKhXBEFdXR39+/dn9OjRhIeYpATcnfr6eurq6hgzZkypyxGRAvWKvoaampoYMmSIQqDEzIwhQ4Zoz0ykh+kVQQAoBLoJ/T+I9Dy9JghERGTPKAj2gfr6eo4++miOPvpo9t9/f0aMGNE63dzcnPd9V155JSNGjCCdTndhtSIi7fWKk8WlNmTIEBYsWADAddddR79+/fj2t7/dujyZTJJItP9Rp9Np5s2bx6hRo3jhhReYPHlyUWpLpVLE4/GibFtEeodeFwTXP7SUZWu27tNtHn7gAH78+SN26z0XXngh1dXVvP766xxzzDHcfPPN7ZY/++yzHHnkkcyYMYOamprWIPjwww+57LLLeOeddwC4/fbbOeGEE7j33nu56aabMDPGjx/P7373Oy688EKmTp3K9OnTAejXrx8NDQ0899xzXH/99RxwwAEsWLCAZcuWcfbZZ7N69Wqampq48sorufTSSwF47LHH+N73vkcqlWLo0KE8+eSTHHLIIbz00ksMGzaMdDrNuHHjmD9/PkOHDt3Ln6SIdEe9Lgi6k7feeounnnoq5zfympoaZs6cybRp0/je975HS0sLZWVlfOtb3+LUU09l3rx5pFIpGhoaWLp0KTfccAMvvvgiQ4cOZePGjbv87L/97W8sWbKk9TLO2bNnU11dTWNjI5/61Kc455xzSKfTXHLJJbzwwguMGTOGjRs3EovFuOCCC5gzZw5XXXUVTz31FBMmTFAIiPRivS4IdvebezGde+65OUOgubmZRx55hFtuuYX+/ftz3HHH8cQTT3DmmWfyzDPPcO+99wIQj8cZOHAg9957L9OnT29tjKurq3f52ZMmTWp3Lf+tt97KvHnzAFi9ejVvv/0269ev55RTTmldL7Pdiy++mGnTpnHVVVcxe/ZsLrroor37QYhIt9brgqA76du3b875jz32GFu2bOGoo44CYPv27VRVVXHmmWfmXN/dc16WmUgkWk80u3u7E9PZn/3cc8/x1FNP8de//pWqqiomT55MU1NT3u2OGjWK4cOH88wzz/Dyyy8zZ86cwv/RItLj6KqhEqipqeGuu+5i1apVrFq1ipUrV/LEE0+wfft2pkyZwu233w4EJ3q3bt3KlClTuO+++6ivD3rpzhwaGj16NK+++ioADzzwAC0tLTk/b8uWLQwePJiqqireeOMN5s+fD8CnP/1pnn/+eVauXNluuwBf+9rXuOCCCzjvvPN0slmkl1MQdLHt27fz+OOPt/v237dvX0466SQeeughfvnLX/Lss89y1FFHceyxx7J06VKOOOIIvv/973PqqacyYcIErrnmGgAuueQSnn/+eSZNmsTLL7+cdw/k9NNPJ5lMMn78eH74wx9y/PHHAzBs2DBmzZrFF7/4RSZMmMCMGTNa33PWWWfR0NCgw0IiEdAreh9dvnw5hx12WIkq6p1qa2u5+uqr+ctf/rLb79X/h0j30+t7H5V962c/+xm33367zg2IRIQODclOrr32Wt59911OOumkUpciIl1AQSAiEnEKAhGRiFMQiIhEnIJARCTiFAT7wOTJk3n88cfbzfvFL37BN77xjU7f0/Ey2Iz169dTVlbGnXfeuU/rFBHJRUGwD8ycOZO5c+e2mzd37lxmzpy5R9v74x//yPHHH09NTc2+KC+vZDJZ1O2LSM/Q++4jePRa+GDxvt3m/kfBGT/Lu3j69On84Ac/YMeOHfTp04dVq1axZs0aTjrpJL7+9a/zyiuv0NjYyPTp07n++ut3+XE1NTXcfPPNfOlLX+L9999nxIgRADm7os7VbfWBBx7I1KlTWbJkCQA33XQTDQ0NXHfddUyePJkTTjiBF198kbPOOotx48bx05/+lObmZoYMGcKcOXMYPnw4DQ0NXHHFFdTW1mJm/PjHP2bz5s0sWbKEW265BYDf/OY3LF++nJ///Od7+xMWkRLqfUFQAkOGDGHSpEk89thjTJs2jblz5zJjxgzMjBtuuIHq6mpSqRRTpkxh0aJFjB8/Pu+2Vq9ezQcffMCkSZM477zz+MMf/sA111yTtyvqXN1Wb9q0qdN6N2/ezPPPPw/Apk2bmD9/PmbGXXfdxY033sjNN9/MT37yEwYOHMjixYtb1ysvL2f8+PHceOONlJWVcffdd+vwlUgv0PuCoJNv7sWUOTyUCYLZs2cDcN999zFr1iySySRr165l2bJlnQbB3LlzOe+88wA4//zz+epXv8o111zDM888k7Mr6lzdVu8qCLL7FKqrq2PGjBmsXbuW5ubm1i6pn3rqqXaHuwYPHgzAaaedxsMPP8xhhx1GS0tLaw+qItJz6RzBPnL22Wfz9NNP89prr9HY2MgxxxzDypUruemmm3j66adZtGgRZ555Jk1NTZ1up6amhnvuuYfRo0dz1llnsXDhQt5+++28XUbnkt09NbDTZ2Z3TnfFFVdw+eWXs3jxYu68887WdfN93te+9jXuuece7r77bnVIJ9JLKAj2kX79+jF58mQuvvji1pPEW7dupW/fvgwcOJAPP/yQRx99tNNtvPnmm2zbto3333+/tYvq7373u8ydOzdvV9S5uq0ePnw469ato76+nh07dvDwww/n/cwtW7a0noP47W9/2zr/s5/9LLfddlvrdGYv47jjjmP16tX8/ve/3+OT4SLSvSgI9qGZM2eycOFCzj//fAAmTJjAJz/5SY444gguvvhiTjzxxE7fX1NTwxe+8IV288455xxqamrydkWdq9vqsrIyfvSjH3HccccxdepUDj300Lyfed1113Huuedy8sknt3sc5Q9+8AM2bdrEkUceyYQJE3j22Wdbl5133nmceOKJrYeLRKRnUzfUstumTp3K1VdfzZQpU3Iu1/+HSPfTWTfU2iOQgm3evJlx48ZRWVmZNwREpOfpfVcNSdEMGjSIt956q9RliMg+1mv2CHraIa7eSv8PIj1PrwiCiooK6uvr1QiVmLtTX19PRUVFqUsRkd3QKw4NjRw5krq6OtavX1/qUiKvoqKCkSNHlroMEdkNvSIIysrKWu+IFRGR3VPUQ0NmdrqZvWlmK8zs2hzLzcxuDZcvMrNjilmPiIjsrGhBYGZx4NfAGcDhwEwzO7zDamcAY8PhUuD2YtUjIiK5FXOPYBKwwt3fcfdmYC4wrcM604B7PTAfGGRmBxSxJhER6aCY5whGAKuzpuuA4wpYZwSwNnslM7uUYI8BoMHM3tzDmoYCG/bwvaXQk+rtSbVCz6q3J9UKPavenlQr7F29B+dbUMwgyNVVZsfrOwtZB3efBcza64LMavPdYt0d9aR6e1Kt0LPq7Um1Qs+qtyfVCsWrt5iHhuqAUVnTI4E1e7COiIgUUTGD4BVgrJmNMbNy4HzgwQ7rPAh8Obx66Hhgi7uv7bghEREpnqIdGnL3pJldDjwOxIHZ7r7UzC4Ll98BPAJ8DlgBbAeK/aSTvT681MV6Ur09qVboWfX2pFqhZ9Xbk2qFItXb47qhFhGRfatX9DUkIiJ7TkEgIhJxkQmCXXV30V2Y2Sgze9bMlpvZUjO7stQ1FcLM4mb2upnlf0ByN2Bmg8zsT2b2Rvgz/nSpa+qMmV0d/h4sMbMaM+tWXbua2WwzW2dmS7LmVZvZk2b2djjuFs80zVPrv4e/C4vMbJ6ZDSphie3kqjdr2bfNzM1saK737q5IBEGB3V10F0ngf7n7YcDxwDe7ca3ZrgSWl7qIAvwSeMzdDwUm0I1rNrMRwLeAie5+JMFFF+eXtqqd3AOc3mHetcDT7j4WeDqc7g7uYedanwSOdPfxwFvAd7u6qE7cw871YmajgM8A7+2rD4pEEFBYdxfdgruvdffXwtcfETRUI0pbVefMbCRwJnBXqWvpjJkNAE4B/i+Auze7++aSFrVrCaDSzBJAFd3sPht3fwHY2GH2NOC34evfAmd3ZU355KrV3Z9w92Q4OZ/gXqZuIc/PFuAW4P+Q4+bbPRWVIMjXlUW3ZmajgU8CL5e4lF35BcEvZrrEdezKx4D1wN3hYay7zKxvqYvKx93fB24i+Oa3luA+mydKW1VBhmfuBwrH+5W4nkJdDDxa6iI6Y2ZnAe+7+8J9ud2oBEFBXVl0J2bWD/gzcJW7by11PfmY2VRgnbu/WupaCpAAjgFud/dPAtvoPoctdhIeW58GjAEOBPqa2QWlrap3MrPvExyWnVPqWvIxsyrg+8CP9vW2oxIEPaorCzMrIwiBOe5+f6nr2YUTgbPMbBXBIbfTzOw/S1tSXnVAnbtn9rD+RBAM3dX/AFa6+3p3bwHuB04ocU2F+DDTi3A4XlfiejplZl8BpgL/5N37xqqPE3wpWBj+vY0EXjOz/fd2w1EJgkK6u+gWzMwIjmEvd/efl7qeXXH377r7SHcfTfBzfcbdu+W3Vnf/AFhtZoeEs6YAy0pY0q68BxxvZlXh78UUuvHJ7SwPAl8JX38FeKCEtXTKzE4HvgOc5e7bS11PZ9x9sbvv5+6jw7+3OuCY8Pd6r0QiCMKTQZnuLpYD97n70tJWldeJwD8TfLNeEA6fK3VRvcgVwBwzWwQcDfxracvJL9xz+RPwGrCY4O+1W3WJYGY1wF+BQ8yszsy+CvwM+IyZvU1wdcvPSlljRp5abwP6A0+Gf2t3lLTILHnqLc5nde89IRERKbZI7BGIiEh+CgIRkYhTEIiIRJyCQEQk4hQEIiIRpyCQHs3MUlmX2S7Ylz3LmtnoXD0/5ljvOjPbbmb7Zc1r6MoaRPZG0R5VKdJFGt396FIXAWwA/hfBzUndhpklsjpVE8lJewTSK5nZKjP7NzP7Wzh8Ipx/sJk9HfY//7SZHRTOHx72R78wHDJdOcTN7DfhMwGeMLPKPB85G5hhZtUd6mj3jT7sR/668PVzZnaLmb0QPhvhU2Z2f9iP/0+zNpMws9+GNf8p7HMGMzvWzJ43s1fN7PGsbh2eM7N/NbPnCboHF+mUgkB6usoOh4ZmZC3b6u6TCO4e/UU47zbg3rD/+TnAreH8W4Hn3X0CQf9DmTvPxwK/dvcjgM3AOXnqaCAIg91teJvd/RTgDoKuGL4JHAlcaGZDwnUOAWaFNW8FvhH2R/UrYLq7Hxt+9g1Z2x3k7qe6+827WY9EkA4NSU/X2aGhmqzxLeHrTwNfDF//DrgxfH0a8GUAd08BW8LeP1e6+4JwnVeB0Z3UciuwwMx2p/HN9Hm1GFia6b7ZzN4h6ChxM7Da3V8M1/tPgofVPEYQGE8G3RARJ+iqOuMPu1GDRJyCQHozz/M63zq57Mh6nQLyHRrC3Teb2e+Bb2TNTtJ+z7vjoyYz2093+Kw0bX+fHWt0gq7Vl7p7vkdtbstXp0hHOjQkvdmMrPFfw9cv0fa4x38C/jt8/TTwdWh9/vKAPfzMnwP/k7ZG/ENgPzMbYmZ9CLo73l0HWduzlWeGNb8JDMvMN7MyMztiD2uWiFMQSE/X8RxBdk+XfczsZYLj9leH874FXBT2PvrPtB3TvxL4BzNbTHAIaI8aVXffAMwD+oTTLcC/EDxl7mHgjT3Y7HLgK2HN1QQP1mkGpgP/ZmYLgQX0jGcVSDek3kelVwof3DExbJhFpBPaIxARiTjtEYiIRJz2CEREIk5BICIScQoCEZGIUxCIiEScgkBEJOL+P2g53/uibXeiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import cv2\n",
    "import torch,torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class={0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n",
    "# Get a mapping of the indices to the class names, in order to see the ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Alberto(file,model,pad=False):\n",
    "    x = Image.open(file)\n",
    "    x = np.asarray(x)\n",
    "    # if pad:\n",
    "    #     x=add_pad(x)\n",
    "    # else:\n",
    "    x=cv2.resize(x,(224,224))\n",
    "    x=x.astype(\"float32\")\n",
    "    x=x/255\n",
    "    x=np.moveaxis(x,-1,0)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    img = torch.from_numpy(x).to(device)\n",
    "    res=list(model(img).cpu().detach().numpy()[0])\n",
    "    indice=res.index(max(res))\n",
    "    clase=idx_to_class.get(indice)\n",
    "    # print(clase)\n",
    "    return clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train_pad\\multivivienda\\75_13.png\"\n",
    "clase=predict_Alberto(file,alexnet)\n",
    "imagen=cv2.imread(file)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (10, 50)\n",
    "fontScale = 1\n",
    "color = (0, 0, 224)\n",
    "thickness = 2\n",
    "image = cv2.putText(imagen, clase, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "cv2.imshow(\"imagen\",imagen)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet1 = models.alexnet(pretrained=True)\n",
    "alexnet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=6\n",
    "alexnet1.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet1.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train\\en_construccion\\Lerma_1.PNG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(device=device)\n",
    "res=list(alexnet(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet1 = models.alexnet(pretrained=False)\n",
    "checkpoint=torch.load(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\ckpoint\\best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_Alberto(file=file, model=alexnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=6\n",
    "alexnet1.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet1.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "\n",
    "#alexnet1.eval()\n",
    "\n",
    "alexnet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet1.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file=r\"C:\\Users\\mfpen\\Pictures\\Clasificador\\train\\area_verde\\605_1.png\"\n",
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train_pad\\casas\\63_11.png\"\n",
    "import cv2\n",
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(device)\n",
    "res=list(alexnet1(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
