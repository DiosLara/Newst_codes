{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Set train and valid directory paths\n",
    "\n",
    "dataset = r\"C:\\Users\\mfpen\\Pictures\\Clasificador\"\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "valid_directory = os.path.join(dataset, 'validacion')\n",
    "\n",
    "# Batch size\n",
    "bs = 2\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  #10#2#257\n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size, valid_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(alexnet.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in tqdm.tqdm(enumerate(train_data_loader),total=len(train_data_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in tqdm.tqdm(enumerate(valid_data_loader),total=len(valid_data_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(0)\n",
    "num_epochs = 10\n",
    "trained_model, history = train_and_validate(alexnet, loss_func, optimizer, num_epochs)\n",
    "\n",
    "#torch.save(history, dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({    'epoch': 1,\n",
    "                #'model_state_dict': alexnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss_func,\n",
    "                }, r'C:\\Users\\mfpen\\Pictures\\Clasificador\\outputs/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,10)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfpen\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "import cv2\n",
    "import torch,torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class={0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n",
    "# Get a mapping of the indices to the class names, in order to see the ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Alberto(file,model):\n",
    "    x = Image.open(file)\n",
    "    x = np.asarray(x)\n",
    "    x=cv2.resize(x,(224,224))\n",
    "    x=x.astype(\"float32\")\n",
    "    x=np.moveaxis(x,-1,0)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    img = torch.from_numpy(x).to(device)\n",
    "    res=list(model(img).cpu().detach().numpy()[0])\n",
    "    indice=res.index(max(res))\n",
    "    clase=idx_to_class.get(indice)\n",
    "    print(clase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfpen\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mfpen\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=7, bias=True)\n",
       "    (7): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=7\n",
    "alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 7]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
      "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
      "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
      "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
      "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
      "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
      "==========================================================================================\n",
      "Total params: 57,032,519\n",
      "Trainable params: 28,679\n",
      "Non-trainable params: 57,003,840\n",
      "Total mult-adds (M): 767.14\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 217.56\n",
      "Estimated Total Size (MB): 221.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 7]                   --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
       "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
       "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
       "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
       "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
       "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
       "==========================================================================================\n",
       "Total params: 57,032,519\n",
       "Trainable params: 28,679\n",
       "Non-trainable params: 57,003,840\n",
       "Total mult-adds (M): 767.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.76\n",
       "Params size (MB): 217.56\n",
       "Estimated Total Size (MB): 221.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(alexnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r\"C:\\Users\\mfpen\\Pictures\\Clasificador\\train\\area_verde\\605_1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casas\n"
     ]
    }
   ],
   "source": [
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(\"cpu\")\n",
    "res=list(alexnet(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfpen\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "alexnet1 = models.alexnet(pretrained=False)\n",
    "checkpoint=torch.load(r\"C:\\Users\\mfpen\\Pictures\\Clasificador\\outputs\\best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "predict_Alberto(file=file, model=alexnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=7, bias=True)\n",
       "    (7): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=7\n",
    "alexnet1.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet1.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "\n",
    "#alexnet1.eval()\n",
    "\n",
    "alexnet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 7]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
      "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
      "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
      "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
      "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
      "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
      "==========================================================================================\n",
      "Total params: 57,032,519\n",
      "Trainable params: 28,679\n",
      "Non-trainable params: 57,003,840\n",
      "Total mult-adds (M): 767.14\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 217.56\n",
      "Estimated Total Size (MB): 221.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 7]                   --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
       "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
       "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
       "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
       "|    └─Linear: 2-20                      [-1, 7]                   28,679\n",
       "|    └─LogSoftmax: 2-21                  [-1, 7]                   --\n",
       "==========================================================================================\n",
       "Total params: 57,032,519\n",
       "Trainable params: 28,679\n",
       "Non-trainable params: 57,003,840\n",
       "Total mult-adds (M): 767.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.76\n",
       "Params size (MB): 217.56\n",
       "Estimated Total Size (MB): 221.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(alexnet1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet1.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casas\n"
     ]
    }
   ],
   "source": [
    "file=r\"C:\\Users\\mfpen\\Pictures\\Clasificador\\train\\area_verde\\605_1.png\"\n",
    "import cv2\n",
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(\"cpu\")\n",
    "res=list(alexnet1(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
