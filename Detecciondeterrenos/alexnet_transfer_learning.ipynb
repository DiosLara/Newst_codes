{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        # transforms.RandomResizedCrop(size=300, scale=(0.8, 1.2)),\n",
    "        # transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        # transforms.Resize(size=256),\n",
    "        # transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406],\n",
    "        #                      [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Set train and valid directory paths\n",
    "dataset=r\"D:/alexnet\"\n",
    "\n",
    "train_directory = os.path.join(dataset, 'train_pad')\n",
    "# dataset = r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\"\n",
    "valid_directory = os.path.join(dataset, 'valid_pad')\n",
    "\n",
    "# Batch size\n",
    "bs =10\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  #10#2#257\n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pd.DataFrame([x.replace(\"\\\\\",\"/\").split(\"/\") for x in glob.glob(\"D:/alexnet/train_pad/*/*\")])[3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size, valid_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features[1]= nn.Hardtanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[6] = nn.Linear(4096, 4096)\n",
    "alexnet.classifier.add_module(\"7\",nn.Softplus())\n",
    "alexnet.classifier.add_module(\"8\", nn.Linear(4096, 4096))\n",
    "alexnet.classifier.add_module(\"9\",nn.Softplus())\n",
    "alexnet.classifier.add_module(\"10\", nn.Linear(4096, 2048))\n",
    "alexnet.classifier.add_module(\"11\", nn.Softplus())\n",
    "alexnet.classifier.add_module(\"12\", nn.Linear(2048, num_classes))\n",
    "alexnet.classifier.add_module(\"13\", nn.Softplus())\n",
    "alexnet.classifier.add_module(\"14\",  nn.LogSoftmax(dim = 1))\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "# loss_func = nn.NLLLoss()\n",
    "#loss_func=nn.MSELoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.RMSprop(lr=0.0001,params=alexnet.parameters())#alexnet.parameters())\n",
    "optimizer= optim.SGD(alexnet.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25,device=0):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in tqdm.tqdm(enumerate(train_data_loader),total=len(train_data_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in tqdm.tqdm(enumerate(valid_data_loader),total=len(valid_data_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                \n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore_checkpoint\n",
    "checkpoint=torch.load(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint\\best_modell7.pth\")\n",
    "alexnet.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(0)\n",
    "num_epochs =100\n",
    "\n",
    "\n",
    "trained_model, history = train_and_validate(alexnet, loss_func, optimizer, num_epochs)\n",
    "\n",
    "#torch.save(history, dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ñ ##breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({    'epoch': 1,\n",
    "                'model_state_dict':alexnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss_func,\n",
    "                }, r'C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint/best_modell7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "from rasterio.windows import Window\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "sys.path.append(r'E:/gitlab/geoloc2/Detecciondeterrenos')\n",
    "from codigos import Generar_txt\n",
    "###path de yolo dentro de computadora\n",
    "os.chdir(r'C:/Users/ASUS/Inteligencia_Artificial/yolov7')\n",
    "from detect_Alberto_v4 import *\n",
    "from scipy.ndimage import rotate as rotate_image\n",
    "from shapely import geometry\n",
    "import time\n",
    "import datetime\n",
    "from torchsummary import summary\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint\\best_modell7.pth\"\n",
    "num_classes=6\n",
    "diciconario={0: 'carros', 1: 'casas', 2: 'en_construccion', 3: 'establecimiento', 4: 'multivivienda', 5: 'terreno_baldio'}\n",
    "model_class=alexnet(weights=weights,num_classes=num_classes,idx_to_class=diciconario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = []\n",
    "y_predict =[]\n",
    "import glob\n",
    "filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\train_pad/*/*\")\n",
    "for file in tqdm.tqdm(filenames):\n",
    "    file=file.replace(\"\\\\\",\"/\")\n",
    "    y_true.append(file.split(\"/\")[-2])\n",
    "    y_predict.append(model_class.predict_file(file,pad=False))\n",
    "labels=[]\n",
    "for k,v in diciconario.items():\n",
    "    labels.append(v)\n",
    "labels\n",
    "confusion_mat = confusion_matrix(y_true, y_predict,labels=labels)\n",
    "conteos=pd.DataFrame(y_true,columns=[\"clases\"]).value_counts()\n",
    "conteos=conteos.reset_index(drop=False)\n",
    "matrix=[]\n",
    "for i,label in enumerate(labels):\n",
    "    matrix.append(confusion_mat[i]/conteos[conteos[\"clases\"]==label][0].values[0])\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(matrix)\n",
    "matrix,labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import cv2\n",
    "import torch,torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class={0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n",
    "# Get a mapping of the indices to the class names, in order to see the ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Alberto(file,model,pad=False):\n",
    "    x = Image.open(file)\n",
    "    x = np.asarray(x)\n",
    "    # if pad:\n",
    "    #     x=add_pad(x)\n",
    "    # else:\n",
    "    x=cv2.resize(x,(224,224))\n",
    "    x=x.astype(\"float32\")\n",
    "    x=x/255\n",
    "    x=np.moveaxis(x,-1,0)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    img = torch.from_numpy(x).to(device)\n",
    "    res=list(model(img).cpu().detach().numpy()[0])\n",
    "    indice=res.index(max(res))\n",
    "    clase=idx_to_class.get(indice)\n",
    "    # print(clase)\n",
    "    return clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train_pad\\multivivienda\\75_13.png\"\n",
    "clase=predict_Alberto(file,alexnet)\n",
    "imagen=cv2.imread(file)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (10, 50)\n",
    "fontScale = 1\n",
    "color = (0, 0, 224)\n",
    "thickness = 2\n",
    "image = cv2.putText(imagen, clase, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "cv2.imshow(\"imagen\",imagen)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet1 = models.alexnet(pretrained=True)\n",
    "alexnet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=6\n",
    "alexnet1.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet1.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train\\en_construccion\\Lerma_1.PNG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(device=device)\n",
    "res=list(alexnet(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet1 = models.alexnet(pretrained=False)\n",
    "checkpoint=torch.load(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\ckpoint\\best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_Alberto(file=file, model=alexnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "num_classes=6\n",
    "alexnet1.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet1.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "\n",
    "#alexnet1.eval()\n",
    "\n",
    "alexnet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(alexnet1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet1.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file=r\"C:\\Users\\mfpen\\Pictures\\Clasificador\\train\\area_verde\\605_1.png\"\n",
    "file=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\train_pad\\casas\\63_11.png\"\n",
    "import cv2\n",
    "x = cv2.imread(file)\n",
    "x=cv2.resize(x,(224,224))\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "x = np.asarray(x)\n",
    "x=x.astype(\"float32\")\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img = torch.from_numpy(x).to(device)\n",
    "res=list(alexnet1(img).cpu().detach().numpy()[0])\n",
    "indice=res.index(max(res))\n",
    "clase=idx_to_class.get(indice)\n",
    "print(clase) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
