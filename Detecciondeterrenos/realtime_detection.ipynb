{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179deaa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:35.706145Z",
     "start_time": "2023-03-30T22:18:27.487381Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "# from osgeo import gdal\n",
    "# import rasterio\n",
    "# import geopandas as gpd\n",
    "# import rasterio.mask\n",
    "# from rasterio.windows import Window\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "sys.path.append(r'E:/gitlab/geoloc2/Detecciondeterrenos')\n",
    "from codigos import Generar_txt\n",
    "###path de yolo dentro de computadora\n",
    "os.chdir(r'C:/Users/ASUS/Inteligencia_Artificial/yolov7')\n",
    "from detect_Alberto_v4 import *\n",
    "from scipy.ndimage import rotate as rotate_image\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798b3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:35.721669Z",
     "start_time": "2023-03-30T22:18:35.708147Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54995a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.188873Z",
     "start_time": "2023-03-30T22:18:35.724284Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ASUS/Inteligencia_Artificial/yolov7\")\n",
    "from detect_Alberto_v4 import modelo\n",
    "Modelo=modelo(weights='Modelos/best_Fer_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "### se requiere una segunda pantalla o modificar los parametro\n",
    "pyautogui.position() ## sobre el qgis en la esquina superior izquierda del mapa correr esta celda con ctrl+enter y modificar los parametro x1,y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f29714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk \n",
    "from PIL import ImageGrab\n",
    "path_save=\"D:/nuevas_detecciones\" ## guardar txt\n",
    "path_minimagen=r\"D:/imagenes\"\n",
    "import datetime\n",
    "dim=600\n",
    "x1=2289#+300\n",
    "y1=159#+200\n",
    "x2=x1+dim#3284\n",
    "y2=y1+dim-60#703\n",
    "bbox= (x1,y1,x2,y2)\n",
    "import time \n",
    "le=0\n",
    "vector=0\n",
    "vector_final=[]\n",
    "while True:\n",
    "    \n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    im = ImageGrab.grab(bbox,all_screens=True)\n",
    "    nameimg=str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")\n",
    "    im=np.asarray(im)\n",
    "    im=np.moveaxis(im,-1,0)\n",
    "    im=np.stack([im[2],im[1],im[0]])\n",
    "    im=np.moveaxis(im,0,-1)\n",
    "    image_ro=im.copy()\n",
    "#     image_ro=im.copy()\n",
    "    cv2.imshow(\"1\",image_ro)\n",
    "    if k == ord('w'):\n",
    "        image_ro1=im.copy()\n",
    "        angulo=correct_orientation(im,dim=dim)[0]\n",
    "    #     M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n",
    "    #     image_ro = cv2.warpAffine(image_ro, M, (dim,dim))\n",
    "        image_ro1=ndimage.rotate(image_ro1,angulo,reshape=True)\n",
    "        image_ro1=cv2.resize(image_ro1,(dim*2,dim*2))\n",
    "        image_ro2=image_ro1.copy()\n",
    "\n",
    "        w=image_ro1.shape[0]\n",
    "        h=image_ro1.shape[1]\n",
    "        \n",
    "        conf=0.06\n",
    "    #     vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro)\n",
    "        vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro1)\n",
    "        \n",
    "    #     df_cache=vector2xy(vector,w,h,dim=dim,nameimg=nameimg)\n",
    "    #     for i in range(len(df_cache)):\n",
    "    #             if df_cache[\"Tipo\"][i]==\"casa\":\n",
    "    #                 cv2.rectangle(image_ro,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,0,255),2)\n",
    "    #             else:\n",
    "    #                 cv2.rectangle(image_ro,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,255,0),2)\n",
    "        df_cache1=vector2xy(vector,w,h,dim=image_ro1.shape[0],nameimg=nameimg)\n",
    "        df_cache1=df_cache1.sort_values(by=\"area\").reset_index(drop=True)\n",
    "        image_ro3=image_ro2.copy()\n",
    "        image_ro4=image_ro2.copy()\n",
    "        for i in range(len(df_cache1)):\n",
    "            x,y=df_cache1[\"start_point_im\"][i]\n",
    "            if df_cache1[\"Tipo\"][i]==\"casa\":\n",
    "                cv2.rectangle(image_ro3,df_cache1[\"start_point_im\"][i],df_cache1[\"end_point_im\"][i],(0,0,255),2)\n",
    "                cv2.putText(image_ro3, str(i), (x+50,y+50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(image_ro3,df_cache1[\"start_point_im\"][i],df_cache1[\"end_point_im\"][i],(0,255,0),2)\n",
    "                cv2.putText(image_ro3, str(i), (x+50,y+50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            cv2.namedWindow('finalImg1', cv2.WINDOW_NORMAL)\n",
    "#             cv2.imshow(\"finalImg\",finalImg)\n",
    "            x1,y1=df_cache1.loc[i,'start_point_im']\n",
    "            x2,y2=df_cache1.loc[i,'end_point_im']\n",
    "            Tipo=df_cache1.loc[i,'Tipo']\n",
    "            df_aux=image_ro2.copy()\n",
    "            df_aux=df_aux[y1:y2,x1:x2]\n",
    "            vector_final.append(list(df_cache1.loc[i,\"vector_o\"].split())+list([\"0\",nameimg]))\n",
    "#             if np.sum(df_aux)>10:\n",
    "#                 name=path_minimagen+\"/\"+Tipo+\"_\"+str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")+\".png\"\n",
    "#                 cv2.imwrite(name,df_aux)\n",
    "        cv2.imshow('finalImg1',image_ro3)\n",
    "        \n",
    "        \n",
    "    if k == ord('t'):\n",
    "        Generar_txt([list(x) for(x) in vector_final],save_folder=path_save)\n",
    "        cv2.imwrite(path_save+\"/\"+nameimg+\".png\",image_ro2)\n",
    "        vector_final=[]\n",
    "\n",
    "    if k<=27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac8db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:33:16.282445Z",
     "start_time": "2023-03-30T22:33:00.367023Z"
    }
   },
   "outputs": [],
   "source": [
    "from tkinter import Tk \n",
    "from PIL import ImageGrab\n",
    "path_save=\"D:/nuevas_detecciones\" ## guardar txt\n",
    "path_minimagen=\"D:/imagenes/nuevas\"\n",
    "conf=0.06\n",
    "import datetime\n",
    "dim=540\n",
    "x1=2289#+300\n",
    "y1=159#+200\n",
    "x2=x1+dim#3284\n",
    "y2=y1+dim#703\n",
    "bbox= (x1,y1,x2,y2)\n",
    "import time \n",
    "le=0\n",
    "vector=0\n",
    "while True:\n",
    "    \n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    im = ImageGrab.grab(bbox,all_screens=True)\n",
    "    nameimg=str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")\n",
    "    im=np.asarray(im)\n",
    "    im=np.moveaxis(im,-1,0)\n",
    "    im=np.stack([im[2],im[1],im[0]])\n",
    "    im=np.moveaxis(im,0,-1)\n",
    "    image_ro=im.copy()\n",
    "#     image_ro=im.copy()\n",
    "    cv2.imshow(\"1\",image_ro)\n",
    "    if k == ord('w'):\n",
    "        image_ro1=im.copy()\n",
    "        angulo=correct_orientation(im,dim=dim)[0]\n",
    "    #     M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n",
    "    #     image_ro = cv2.warpAffine(image_ro, M, (dim,dim))\n",
    "        image_ro1=ndimage.rotate(image_ro1,angulo,reshape=True)\n",
    "        image_ro1=cv2.resize(image_ro1,(dim*2,dim*2))\n",
    "        image_ro2=image_ro1.copy()\n",
    "\n",
    "        w=image_ro1.shape[0]\n",
    "        h=image_ro1.shape[1]\n",
    "        \n",
    "    #     vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro)\n",
    "        vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro1)\n",
    "        \n",
    "    #     df_cache=vector2xy(vector,w,h,dim=dim,nameimg=nameimg)\n",
    "    #     for i in range(len(df_cache)):\n",
    "    #             if df_cache[\"Tipo\"][i]==\"casa\":\n",
    "    #                 cv2.rectangle(image_ro,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,0,255),2)\n",
    "    #             else:\n",
    "    #                 cv2.rectangle(image_ro,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,255,0),2)\n",
    "        df_cache1=vector2xy(vector,w,h,dim=image_ro1.shape[0],nameimg=nameimg)\n",
    "        for i in range(len(df_cache1)):\n",
    "                if df_cache1[\"Tipo\"][i]==\"casa\":\n",
    "                    cv2.rectangle(image_ro1,df_cache1[\"start_point_im\"][i],df_cache1[\"end_point_im\"][i],(0,0,255),2)\n",
    "                else:\n",
    "                    cv2.rectangle(image_ro1,df_cache1[\"start_point_im\"][i],df_cache1[\"end_point_im\"][i],(0,255,0),2)\n",
    "        \n",
    "        cv2.imshow(\"2\",image_ro1)\n",
    "    \n",
    "    if k == ord('t'):\n",
    "        Generar_txt([list(x)+list([nameimg]) for(x) in vector],save_folder=path_save)\n",
    "        cv2.imwrite(path_save+\"/\"+nameimg+\".png\",image_ro2)\n",
    "    if k == ord('s'):\n",
    "        for cs_1 in range(len(df_cache1)):\n",
    "            x1,y1=df_cache1.loc[cs_1,'start_point_im']\n",
    "            x2,y2=df_cache1.loc[cs_1,'end_point_im']\n",
    "            Tipo=df_cache1.loc[cs_1,'Tipo']\n",
    "            df_aux=image_ro2.copy()\n",
    "            df_aux=df_aux[y1:y2,x1:x2]\n",
    "            if np.sum(df_aux)>10:\n",
    "                name=path_minimagen+Tipo+\"_\"+str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")+\".png\"\n",
    "                cv2.imwrite(name,df_aux)\n",
    "    if k<=27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514ce38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:28:49.492762Z",
     "start_time": "2023-03-30T22:28:49.477244Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbf6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.801495Z",
     "start_time": "2023-03-30T22:18:45.801495Z"
    }
   },
   "outputs": [],
   "source": [
    "im=np.moveaxis(im,-1,0)\n",
    "np.stack([im[2],im[1],im[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bf32e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.802482Z",
     "start_time": "2023-03-30T22:18:45.802482Z"
    }
   },
   "outputs": [],
   "source": [
    "i=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd4a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.803483Z",
     "start_time": "2023-03-30T22:18:45.803483Z"
    }
   },
   "outputs": [],
   "source": [
    "from tkinter import Tk \n",
    "from PIL import ImageGrab\n",
    "import pyautogui as mo\n",
    "dim=600-60\n",
    "x1=2289#+300\n",
    "y1=159#+200\n",
    "x2=x1+dim#3284\n",
    "y2=y1+dim#703\n",
    "bbox= (x1,y1,x2,y2)\n",
    "df_rs=pd.DataFrame()\n",
    "for i in range(10):\n",
    "    le=0\n",
    "    vector=0\n",
    "    im = ImageGrab.grab(bbox,all_screens=True)\n",
    "    nameimg=str(i)\n",
    "    im=np.asarray(im)\n",
    "    im=np.moveaxis(im,-1,0)\n",
    "    im=np.stack([im[2],im[1],im[0]])\n",
    "    im=np.moveaxis(im,0,-1)\n",
    "\n",
    "    image_ro=im.copy()\n",
    "    image_ro1=im.copy()\n",
    "    angulo=correct_orientation(imagen_n,dim=dim)[0]\n",
    "#     M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n",
    "#     image_ro = cv2.warpAffine(image_ro, M, (dim,dim))\n",
    "    image_ro1=ndimage.rotate(image_ro1,angulo,reshape=True)\n",
    "#     image_ro1=cv2.resize(image_ro1,(dim,dim))\n",
    "    w=image_ro1.shape[0]\n",
    "    h=image_ro1.shape[1]\n",
    "    conf=0.06\n",
    "#     vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro)\n",
    "    vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=conf,imagen_s=image_ro1)\n",
    "    df_cache=vector2xy(vector,w,h,dim=dim,nameimg=nameimg)\n",
    "    df_cache[\"w\"]=w\n",
    "    df_cache[\"h\"]=h\n",
    "    df_cache[\"angulo\"]=angulo\n",
    "    df_rs=pd.concat([df_rs,df_cache],ignore_index=True)\n",
    "    mo.moveTo(x1,y1)\n",
    "    mo.click()\n",
    "    mo.moveTo(x2,y1)\n",
    "    mo.click()\n",
    "    mo.moveTo(x2,y2)\n",
    "    mo.click()\n",
    "    mo.moveTo(x1,y2)\n",
    "    mo.click()\n",
    "    mo.click(button='right')\n",
    "    mo.write(str(i))\n",
    "    mo.keyDown(\"enter\")\n",
    "    mo.keyUp(\"enter\")\n",
    "    mo.keyDown(\"right\")\n",
    "    mo.keyUp(\"right\")\n",
    "    mo.keyDown(\"right\")\n",
    "    mo.keyUp(\"right\")\n",
    "# i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ae9d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.804483Z",
     "start_time": "2023-03-30T22:18:45.804483Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rs.reset_index(drop=True,inplace=True)\n",
    "df_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215df32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.805669Z",
     "start_time": "2023-03-30T22:18:45.805669Z"
    }
   },
   "outputs": [],
   "source": [
    "a=gpd.read_file(\"C:/Users/ASUS/Desktop/a.shp\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac6be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.806667Z",
     "start_time": "2023-03-30T22:18:45.806667Z"
    }
   },
   "outputs": [],
   "source": [
    "casas=[]\n",
    "terrenos=[]\n",
    "for i in range(10):\n",
    "    df_cache1=df_rs[df_rs[\"imagen\"]==str(i)].reset_index(drop=True)\n",
    "    shapes=mapping(a[a[\"id\"]==i][\"geometry\"].values[0])\n",
    "    proyecciones=shapes.get('coordinates')[0][:-1]\n",
    "    angulo=df_cache1[\"angulo\"][0]\n",
    "    w=df_cache1[\"w\"][0]\n",
    "    h=df_cache1[\"h\"][0]\n",
    "    for cs_1 in range(len(df_cache1)):\n",
    "        deteccion=rotacion_detect(df_cache1.loc[cs_1,'start_point_100'], df_cache1.loc[cs_1,'end_point_100'],-angulo,proyecciones,w,h,dim)\n",
    "        if df_cache1.loc[cs_1,\"Tipo\"]==\"casa\":\n",
    "            casas.append(deteccion)\n",
    "        else:\n",
    "            terrenos.append(deteccion)\n",
    "        \n",
    "casas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e52310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.808669Z",
     "start_time": "2023-03-30T22:18:45.808669Z"
    }
   },
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(geometry=casas,crs=3857).to_file(r\"E:\\geoshapes/r.shp\")\n",
    "gpd.GeoDataFrame(geometry=terrenos,crs=3857).to_file(r\"E:\\geoshapes/ra.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90681748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.809666Z",
     "start_time": "2023-03-30T22:18:45.809666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rs[df_rs[\"imagen\"]==str(0)]#.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1717d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.810667Z",
     "start_time": "2023-03-30T22:18:45.810667Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cache[\"imagen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5170648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.811667Z",
     "start_time": "2023-03-30T22:18:45.811667Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping(a[a[\"id\"]==1][\"geometry\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db20b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.812667Z",
     "start_time": "2023-03-30T22:18:45.812667Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cache1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909be38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.813667Z",
     "start_time": "2023-03-30T22:18:45.813667Z"
    }
   },
   "outputs": [],
   "source": [
    "Ã±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79921145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.814667Z",
     "start_time": "2023-03-30T22:18:45.814667Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('cache.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "kernel=np.array([[0,1,2],\n",
    "               [-1,1.5,1],\n",
    "                [-2,-1,0]])\n",
    "img=cv.filter2D(img, ddepth=-1,kernel=kernel)\n",
    "# edges = cv.Canny(img,150,255)\n",
    "cv.imshow(\"image\",img)\n",
    "# cv.imshow(\"edge\",edges)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()\n",
    "# plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "# plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "# plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316b4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.815975Z",
     "start_time": "2023-03-30T22:18:45.815975Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('cache.png')\n",
    "kernel=np.array([[0,1,2],\n",
    "               [-1,1.5,1],\n",
    "                [-2,-1,0]])\n",
    "img=cv.filter2D(img, ddepth=-1,kernel=kernel)\n",
    "a=100\n",
    "r=img[:,:,0]\n",
    "ret,r1 = cv.threshold(r,23+a,255,cv.THRESH_BINARY)\n",
    "g=img[:,:,1]\n",
    "ret,g1 = cv.threshold(g,29+a,255,cv.THRESH_BINARY)\n",
    "b=img[:,:,2]\n",
    "ret,b1 = cv.threshold(b,22+a,255,cv.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52636e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.816975Z",
     "start_time": "2023-03-30T22:18:45.816975Z"
    }
   },
   "outputs": [],
   "source": [
    "ima1=np.stack([r1,g1,b1],axis=-1)\n",
    "ima1 = cv.cvtColor(ima1, cv.COLOR_BGR2GRAY)\n",
    "kernel=np.array([[0,0,0],\n",
    "               [0,1,0],\n",
    "                [0,0,0]])\n",
    "ima1=cv.filter2D(ima1, ddepth=-1,kernel=kernel)\n",
    "cv.imshow(\"a\",ima1)\n",
    "edges = cv.Canny(img,200,255)\n",
    "# cv.imshow(\"image\",img)\n",
    "cv.imshow(\"edge\",edges)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc9831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.817982Z",
     "start_time": "2023-03-30T22:18:45.817982Z"
    }
   },
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in r:\n",
    "    for j in i:\n",
    "        f.append(j)\n",
    "res=pd.DataFrame(f)\n",
    "res[\"count\"]=1\n",
    "res.groupby(by=0).count()\n",
    "res1=res.groupby(by=0).count()\n",
    "res1=res1.sort_values(by=\"count\",ascending=False)[2:].sort_index()\n",
    "res1,res1[res1[\"count\"]==res1.max()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ab3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.818983Z",
     "start_time": "2023-03-30T22:18:45.818983Z"
    }
   },
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in g:\n",
    "    for j in i:\n",
    "        f.append(j)\n",
    "res=pd.DataFrame(f)\n",
    "res[\"count\"]=1\n",
    "res.groupby(by=0).count()\n",
    "res1=res.groupby(by=0).count()\n",
    "res1=res1.sort_values(by=\"count\",ascending=False)[2:].sort_index()\n",
    "res1,res1[res1[\"count\"]==res1.max()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab6145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.819980Z",
     "start_time": "2023-03-30T22:18:45.819980Z"
    }
   },
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in b:\n",
    "    for j in i:\n",
    "        f.append(j)\n",
    "res=pd.DataFrame(f)\n",
    "res[\"count\"]=1\n",
    "res.groupby(by=0).count()\n",
    "res1=res.groupby(by=0).count()\n",
    "res1=res1.sort_values(by=\"count\",ascending=False)[2:].sort_index()\n",
    "res1,res1[res1[\"count\"]==res1.max()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525df460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.820982Z",
     "start_time": "2023-03-30T22:18:45.820982Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('cache.png')[:,:,0]\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df5b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.821983Z",
     "start_time": "2023-03-30T22:18:45.821983Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('cache.png')[:,:,1]\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63841b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.822988Z",
     "start_time": "2023-03-30T22:18:45.822988Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('cache.png')[:,:,2]\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46f028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918f0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.822988Z",
     "start_time": "2023-03-30T22:18:45.822988Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax1, ax2, ax3 = fig.subplots(1, 3)\n",
    "img = misc.ascent()\n",
    "= ndimage.rotate(img, 45, reshape=False)\n",
    "full_img_45 = ndimage.rotate(img, 45, reshape=True)\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "ax2.imshow(img_45, cmap='gray')\n",
    "ax2.set_axis_off()\n",
    "ax3.imshow(full_img_45, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35594b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.824496Z",
     "start_time": "2023-03-30T22:18:45.824496Z"
    }
   },
   "outputs": [],
   "source": [
    "img_45.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af3cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.825503Z",
     "start_time": "2023-03-30T22:18:45.825503Z"
    }
   },
   "outputs": [],
   "source": [
    "full_img_45.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e817d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.826504Z",
     "start_time": "2023-03-30T22:18:45.826504Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.applications.MobileNet(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02716cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.828010Z",
     "start_time": "2023-03-30T22:18:45.828010Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd75d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.829019Z",
     "start_time": "2023-03-30T22:18:45.829019Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead7f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.830018Z",
     "start_time": "2023-03-30T22:18:45.830018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca53ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.831018Z",
     "start_time": "2023-03-30T22:18:45.831018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Set train and valid directory paths\n",
    "\n",
    "dataset = r'C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador'\n",
    "\n",
    "train_directory = os.path.join(dataset, 'train_pad')\n",
    "valid_directory = os.path.join(dataset, 'valid')\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  #10#2#257\n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baaa4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.831018Z",
     "start_time": "2023-03-30T22:18:45.831018Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5e852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.833020Z",
     "start_time": "2023-03-30T22:18:45.833020Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_size, valid_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42b48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.833020Z",
     "start_time": "2023-03-30T22:18:45.833020Z"
    }
   },
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b455ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.834528Z",
     "start_time": "2023-03-30T22:18:45.834528Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66d654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.835536Z",
     "start_time": "2023-03-30T22:18:45.835536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the final layer of AlexNet Model for Transfer Learning\n",
    "alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4a730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.836535Z",
     "start_time": "2023-03-30T22:18:45.836535Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(alexnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca3a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.837537Z",
     "start_time": "2023-03-30T22:18:45.837537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(alexnet.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be55dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.838533Z",
     "start_time": "2023-03-30T22:18:45.838533Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in tqdm.tqdm(enumerate(train_data_loader),total=len(train_data_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in tqdm.tqdm(enumerate(valid_data_loader),total=len(valid_data_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfaa797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.839535Z",
     "start_time": "2023-03-30T22:18:45.839535Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(0)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098485a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.839535Z",
     "start_time": "2023-03-30T22:18:45.839535Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(0)\n",
    "num_epochs = 2\n",
    "trained_model, history = train_and_validate(alexnet, loss_func, optimizer, num_epochs)\n",
    "\n",
    "torch.save(history, dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbca36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5f567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.840535Z",
     "start_time": "2023-03-30T22:18:45.840535Z"
    }
   },
   "outputs": [],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,10)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dfcc75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.842540Z",
     "start_time": "2023-03-30T22:18:45.842540Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7313d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.843535Z",
     "start_time": "2023-03-30T22:18:45.843535Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "    '''\n",
    "    Function to predict the class of a single test image\n",
    "    Parameters\n",
    "        :param model: Model to test\n",
    "        :param test_image_name: Test image\n",
    "\n",
    "    '''\n",
    "    \n",
    "    transform = image_transforms['test']\n",
    "\n",
    "    test_image = Image.open(test_image_name)\n",
    "    plt.imshow(test_image)\n",
    "    \n",
    "    test_image_tensor = transform(test_image)\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n",
    "#     else:\n",
    "    test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(test_image_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        topk, topclass = ps.topk(3, dim=1)\n",
    "        for i in range(3):\n",
    "            print(\"Predcition\", i+1, \":\", idx_to_class[topclass.numpy()[0][i]], \", Score: \", topk.numpy()[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595604b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.844540Z",
     "start_time": "2023-03-30T22:18:45.844540Z"
    }
   },
   "outputs": [],
   "source": [
    "predict(trained_model, r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\valid\\casas\\814_25.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebc807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.846670Z",
     "start_time": "2023-03-30T22:18:45.846670Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\cache.png\", cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img = cv.medianBlur(img,5)\n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "import cv2\n",
    "cv2.imshow(\"th1\",th1)\n",
    "cv2.imshow(\"th2\",th2)\n",
    "cv2.imshow(\"th3\",th3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "# titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "#             'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "# # images = [img, th1, th2, th3]\n",
    "# # for i in range(4):\n",
    "# #     plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "# #     plt.title(titles[i])\n",
    "# #     plt.xticks([]),plt.yticks([])\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240640e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:18:45.847680Z",
     "start_time": "2023-03-30T22:18:45.847680Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\cache1.png\")\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa708c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
