{"cells":[{"cell_type":"code","source":["!pip install rasterio\n","!pip install geopandas"],"metadata":{"id":"-hptFtUIAeOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pL7gYjYACJ6","executionInfo":{"status":"ok","timestamp":1682721378095,"user_tz":360,"elapsed":4240,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}},"outputId":"67dd4d69-03b0-4ff5-f386-ec2f7232e39f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["%matplotlib inline\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from osgeo import gdal\n","import rasterio\n","import geopandas as gpd\n","import rasterio.mask\n","from rasterio.windows import Window\n","import sys\n","from shapely.geometry import mapping\n","sys.path.append(r'/content/drive/MyDrive/Equipo_Agua/Geo/codigos/Detecciondeterrenos')\n","from codigos import Generar_txt\n","###path de yolo dentro de computadora\n","os.chdir(r'/content/drive/MyDrive/Equipo_Agua/Geo/Data/yolov7')\n","# from detect_Alberto_v4 import *\n","from scipy.ndimage import rotate as rotate_image\n","from shapely import geometry\n","import time\n","import datetime"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"JAhc35fnACJ8","executionInfo":{"status":"ok","timestamp":1682724500122,"user_tz":360,"elapsed":379,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Mar 29 10:45:35 2023\n","@author: Alberto\n","\"\"\"\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import math\n","from shapely.geometry import Polygon\n","import cv2\n","import time\n","from pathlib import Path\n","import torch\n","import tqdm\n","import numpy as np\n","from models.experimental import attempt_load\n","from utils.datasets import LoadImages , letterbox\n","from utils.general import check_img_size, non_max_suppression, scale_coords, xyxy2xywh, set_logging\n","from utils.torch_utils import select_device, time_synchronized, TracedModel\n","import os\n","from osgeo import gdal\n","import rasterio\n","import geopandas as gpd\n","import rasterio.mask\n","from rasterio.windows import Window\n","import sys\n","from shapely.geometry import mapping\n","from scipy.ndimage import rotate as rotate_image\n","from shapely import geometry\n","import cv2\n","import torch,torchvision\n","import numpy as np\n","import torch.nn as nn\n","from PIL import Image\n","from torchvision import models\n","from torchsummary import summary\n","opt_img_size=256\n","class modelo():\n","    def __init__(self,weights=[\"yolov7.pt\"]):\n","        \"\"\"inicializa el modelo con los pesos\"\"\"\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        model = attempt_load(weights, map_location=self.device)\n","        model = TracedModel(model, self.device, opt_img_size)\n","        self.model= model\n","        \n","    def detect(self,opt_conf_thres,opt_source=\"train/images\",display=False,imagen_s=np.array([1,1])):\n","        \"\"\"Genera las deteccion de objetos por imagen precargada o por carpeta/archivo\"\"\"\n","        vector=[]\n","        opt_no_trace=False\n","        opt_iou_thres=0.45\n","        opt_save_conf=True\n","        opt_classes=None\n","        opt_agnostic_nms=False\n","        opt_augment=False\n","        opt_no_trace=False\n","        source,  imgsz, trace = opt_source, opt_img_size, not opt_no_trace\n","        set_logging()\n","        half = self.device.type != 'cpu'  # half precision only supported on CUDA\n","    # load FP32 model\n","        stride = int(self.model.stride.max())  # self.model stride\n","        imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","        if half:\n","            self.model.half()  # to FP16\n","        names = self.model.module.names if hasattr(self.model, 'module') else self.model.names\n","        # Set Dataloader\n","        if imagen_s.shape[0]==2:\n","            dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","            t0 = time.time()\n","            for path, img, im0s, vid_cap in tqdm.tqdm(dataset):\n","                img = torch.from_numpy(img).to(self.device)\n","                img = img.half() if half else img.float()  # uint8 to fp16/32\n","                img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","                if img.ndimension() == 3:\n","                    img = img.unsqueeze(0)\n","                t1 = time_synchronized()\n","                with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","                    pred = self.model(img, augment=opt_augment)[0]\n","                t2 = time_synchronized()\n","                pred = non_max_suppression(pred, opt_conf_thres, opt_iou_thres, classes=opt_classes, agnostic=opt_agnostic_nms)\n","                t3 = time_synchronized()\n","                for i, det in enumerate(pred):  # detections per image\n","                    p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","                    p = Path(p)  # to Path\n","                    gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","                    if len(det):\n","                        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","                        for c in det[:, -1].unique():\n","                            n = (det[:, -1] == c).sum()  # detections per class\n","                            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","                        for *xyxy, conf, cls in reversed(det):\n","                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                            line = (cls, *xywh, conf) if opt_save_conf else (cls, *xywh)  # label format\n","                            vector.append(list(line)+[p.name[:-4]])  \n","                if display:\n","                    print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","        else:\n","            img0=imagen_s  \n","            img = letterbox(img0, imgsz, stride)[0]\n","            img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n","            img = np.ascontiguousarray(img)\n","            img = torch.from_numpy(img).to(self.device)\n","            img = img.half() if half else img.float()\n","            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","            if img.ndimension() == 3:\n","                img = img.unsqueeze(0)\n","            t1 = time_synchronized()\n","            with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","                pred = self.model(img, augment=opt_augment)[0]\n","                # pred_o=pred\n","            t2 = time_synchronized()\n","            pred = non_max_suppression(pred, opt_conf_thres, opt_iou_thres, classes=opt_classes, agnostic=opt_agnostic_nms)\n","            t3 = time_synchronized()\n","            for i, det in enumerate(pred):  # detections per image\n","                s, im0 =  '', img0\n","#                 p = Path(p)  # to Path\n","                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","                if len(det):\n","                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n","                    for c in det[:, -1].unique():\n","                        n = (det[:, -1] == c).sum()  # detections per class\n","                        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","                    for *xyxy, conf, cls in reversed(det):\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if opt_save_conf else (cls, *xywh)  # label format\n","                        vector.append(line)\n","        return vector\n","    \n","def correct_orientation(img_rgb,dim,pattern_path=\"pattern1.png\"):\n","    \"\"\"Determina el angulo donde existe la mayor deteccion de lineas rectas\"\"\"\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n","    template = cv2.imread(pattern_path,0)\n","    w, h = template.shape[::-1]\n","    template  = cv2.resize(template,(int(w/4),int(h/4)))\n","    image_ro=img_gray.copy()\n","    angulo=0\n","    an=[]\n","    le=0\n","    angulo_f=0\n","    imagen_final=img_rgb.copy()\n","    for i in range(-45,45,1):\n","        angulo=i\n","        M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n","        image_ro = cv2.warpAffine(img_gray, M, (dim,dim))\n","        res = cv2.matchTemplate(image_ro,template,cv2.TM_CCOEFF_NORMED)\n","        threshold =.5\n","        loc = np.where( res >= threshold)\n","        com=len(loc[0])\n","        if com>0:\n","            an.append(angulo)\n","            if le<com:\n","                le=com\n","                angulo_f=angulo\n","                M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n","                imagen_final = cv2.warpAffine(img_rgb, M, (dim,dim))\n","    return angulo_f,imagen_final\n","\n","def verificacion(im):\n","    \"\"\"filtro para determinar cuanta area verde existe en la imagen\"\"\"\n","    hsv=cv2.cvtColor(im,cv2.COLOR_BGR2HSV)\n","    mask=cv2.inRange(hsv,(12,30,0),(160,232,160))\n","    verde=int((np.sum(mask)/im.shape[0]**2/255)*100)\n","    return verde \n","\n","def vector2xy(vector,w,h,dim=700,nameimg=\"image\",angle=0):\n","    \"\"\"Transforma el vector de deteccion en coordendas porcentuales y enteras de la imagen\"\"\"\n","    s=[]\n","    for v in vector:\n","        str_v=(str(v).replace(\"tensor(\",\"\").replace(\"=\",\"\").replace(\", device\",\"\").replace(\"[\",\"\").replace(\"'cuda:0'\",\"\").replace(\"]\",\"\").replace(\".)\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"']\",\"\").replace(\"'\",\"\").strip().split(\",\"))\n","#         h,w=dim,dim\n","        x1 = int( float(str_v[1]) * w )\n","        y1 = int( float(str_v[2]) * h )\n","        xw = int( float(str_v[3]) * w /2)\n","        yw = int( float(str_v[4]) * h /2)\n","        start_point_im = ((x1 - xw), (y1 - yw))\n","        end_point_im   = ((x1 + xw), (y1 + yw))\n","        start_point_100 = ((x1 - xw)/w, (y1 - yw)/h)\n","        end_point_100   = ((x1 + xw)/w, (y1 + yw)/h)\n","        area=xw*yw\n","        conf=str_v[5]\n","        try:\n","            nameimg=str_v[6]\n","        except:\n","            pass\n","        if str(str_v[0])==\"0\":\n","            tipo=\"casa\"\n","        else:\n","            tipo=\"terreno\"\n","        if int(xw)!=0 and int(yw)!=0:# and (xw/yw<=3.2 and yw/xw<=3.2):\n","            s.append([tipo,start_point_im,end_point_im,start_point_100,end_point_100,area,conf,nameimg,\" \".join(str_v[:5])])\n","    df_cache=pd.DataFrame(s,columns=[\"Tipo\",\"start_point_im\",\"end_point_im\",\"start_point_100\",\"end_point_100\",\"area\",\"conf\",\"imagen\",\"vector_o\"])\n","    df_cache.drop_duplicates().reset_index(drop=True,inplace=True)\n","    return df_cache\n","    \n","def imshow_detect(df_cache,imagen_n,nameimg=\"image\"):\n","    \"\"\"muestra la imagen con las detecciones\"\"\"\n","    for i in range(len(df_cache)):\n","            if df_cache[\"Tipo\"][i]==\"casa\":\n","                x,y=df_cache[\"start_point_im\"][i]\n","                cv2.rectangle(imagen_n,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,0,255),2)\n","#                 cv2.putText(imagen_n, str(df_cache[\"conf\"][i]), (x+50,y+50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n","            else:\n","                x,y=df_cache[\"start_point_im\"][i]\n","                cv2.rectangle(imagen_n,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,255,0),2)\n","#                 cv2.putText(imagen_n, str(int(float(df_cache[\"conf\"][i])*100)/100),(x+50,y+50) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","    cv2.imshow(nameimg,imagen_n)\n","    cv2.waitKey()\n","    cv2.destroyAllWindows()\n","\n","def rotacion_detect(startpoint,endpoint,angle,proyecciones,w,h,dim):\n","    \"\"\"Rotata el cuadro detectado en el sistema de coordenadas inicial\"\"\"\n","    point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","    min_y,min_x=point1[0],point1[1]\n","    point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","    max_y,max_x=point2[0],point2[1]\n","    min_y,min_x,max_y,max_x,proyecciones\n","    tipos=[\"casa\",\"terreno\"]\n","    y1,x1=startpoint\n","    y2,x2=endpoint\n","    x1,y1=(x1)*2-1,(y1)*2-1\n","    x2,y2=(x2)*2-1,(y2)*2-1\n","    angle=angle*math.pi/180\n","    x1,y1=x1*(w/dim),y1*(h/dim)\n","    x2,y2=x2*(w/dim),y2*(h/dim)\n","    #x_p, y_p son los puntos de un rectangulo en el orden inverso al manecillas del reloj\n","    x1p=max_x-((x1*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y1p=min_y+((x1*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x2p=max_x-((x2*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y2p=min_y+((x2*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x3p=max_x-((x2*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y3p=min_y+((x2*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x4p=max_x-((x1*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y4p=min_y+((x1*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    return Polygon(((y1p,x1p),(y2p,x2p),(y3p,x3p),(y4p,x4p),(y1p,x1p)))\n","\n","def map_d(x, in_min, in_max, out_min, out_max):\n","    \"\"\"Genera una interpolacion para pasar de un rango a otro\"\"\"\n","    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n","\n","def postproceso(Modelo,model_class,casas,conf_casas,clase_casas,terreno,conf_terreno,clase_terreno,raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0,opt_conf_thres=0.05,imshow=False,imsave=False,path=\"\"):\n","    with rasterio.open(raster) as src:\n","        with tqdm.tqdm(total=alto*ancho) as pbar:\n","            for j in range(ancho):#ancho\n","                for i in range(alto):#alto\n","                    generar=0\n","                    label=raster.replace('\\\\','/').split('/')[-1][:-4]+'_'\n","                    nameimg=label.lower()+str(i)+'_'+str(j)\n","                    cuadro=[]\n","                    for k in range(2):\n","                        for l in range(2):\n","                            cuadro.append((minx+(maxx-minx)/ancho*(j+k),maxy-(maxy-miny)/alto*(i+l)))\n","                    cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n","                    cvees=[]\n","                    for punto in cuadro:\n","                        x=float(punto[0])\n","                        y=float(punto[1])\n","                        mini_df=shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)]\n","                        if len(mini_df)>0:\n","                            generar=1\n","                            cvees.append(mini_df[\"cve_cat\"].values)### traer todas las cve_catastrales del punto sobre el raster ...Pendiente\n","#                             print(cvees)\n","                    if generar==1:\n","                        shapes=[{'type':'Polygon','coordinates':[cuadro]}]\n","                        vector=[]\n","                        array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","                        if np.sum(array)<100:\n","                            pbar.update(1)\n","                            continue\n","                        four_images=[array[2],array[1],array[0]]\n","                        imagen_n = np.stack(four_images, axis=-1)\n","                        if imsave:\n","                            cv2.imwrite(path+\"/\"+nameimg+\".png\",imagen_n)\n","                            # print(path+\"/\"+nameimg+\".png\")\n","                        if angulo_get!=0:\n","                            angulo=-angulo_get\n","                        else:\n","                            angulo=correct_orientation(imagen_n,dim=dim)[0]\n","                        image_ro=imagen_n.copy()\n","                        image_ro=rotate_image(image_ro,angulo,reshape=True)\n","                        w=image_ro.shape[0]\n","                        h=image_ro.shape[1]\n","                        with torch.no_grad():\n","                            vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=opt_conf_thres,imagen_s=image_ro)\n","                        proyecciones=shapes[0].get('coordinates')[0][:-1]\n","                        df_cache=vector2xy(vector,w,h,dim=dim,nameimg=nameimg)\n","                        for cs_1 in (range(len(df_cache))):\n","    #                         x1,y1=df_cache.loc[cs_1,'start_point_im']\n","    #                         x2,y2=df_cache.loc[cs_1,'end_point_im']\n","    #                         df_aux=image_ro.copy()\n","    #                         df_aux=df_aux[y1:y2,x1:x2]\n","    #                         clase,imagen=model_class.predict_iamge(df_aux)\n","    #                         if np.sum(df_aux)>500:\n","    #                             if crear:\n","    #                                 name=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\salida/\"+clase+\"/\"+str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")+\".png\"\n","    #                                 cv2.imwrite(name,imagen)\n","                            x1,y1=df_cache.loc[cs_1,'start_point_im']\n","                            x2,y2=df_cache.loc[cs_1,'end_point_im']\n","                            df_aux=image_ro.copy()\n","                            df_aux=df_aux[y1:y2,x1:x2]\n","                            clase,imagen=model_class.predict_image(df_aux)\n","                            if df_cache['Tipo'][cs_1]=='casa':\n","                                if np.sum(df_aux)>500:\n","                                    casas.append(rotacion_detect(df_cache.loc[cs_1,'start_point_100'], df_cache.loc[cs_1,'end_point_100'],-angulo,proyecciones,w,h,dim))\n","                                    conf_casas.append(df_cache.loc[cs_1,'conf'])\n","                                    clase_casas.append(clase)\n","\n","                            else:\n","                                terreno.append(rotacion_detect(df_cache.loc[cs_1,'start_point_100'], df_cache.loc[cs_1,'end_point_100'],-angulo,proyecciones,w,h,dim))\n","                                conf_terreno.append(df_cache.loc[cs_1,'conf'])\n","                                clase_terreno.append(clase)\n","                        if imshow:\n","                            print(angulo)\n","                            imshow_detect(df_cache,image_ro)\n","\n","                    pbar.update(1)\n","                    \n","def Parametro_raster(raster,metros=120):\n","    \"\"\"Se obtienen las dimensiones del raster y del cuadro de corte\"\"\"\n","    gdal_interpeter = gdal.Open(raster)\n","    width = gdal_interpeter.RasterXSize\n","    height = gdal_interpeter.RasterYSize\n","    coordenadas_gdal = gdal_interpeter.GetGeoTransform()\n","    minx = coordenadas_gdal[0]\n","    miny = coordenadas_gdal[3] + width*coordenadas_gdal[4] + height*coordenadas_gdal[5] \n","    maxx = coordenadas_gdal[0] + width*coordenadas_gdal[1] + height*coordenadas_gdal[2]\n","    maxy = coordenadas_gdal[3]\n","    src_raster_path = raster\n","    src=rasterio.open(src_raster_path)\n","    H,W=src.shape\n","    dim=int(np.ceil(map_d(minx+metros,minx,maxx,0,W)))\n","    alto=np.max([1,int(np.floor(H/dim))])\n","    ancho=np.max([1,int(np.floor(W/dim))])\n","    return alto,ancho,dim,src.crs,H,W,minx,maxx,miny,maxy\n","\n","\n","def shape_transform(shape):\n","    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n","    c=[]\n","    angulo_manzana=[]\n","    for manzana in range(len(shape)):\n","        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","        angulos=[]\n","        d=[]\n","        poly=pd.DataFrame(proyecciones1[0])\n","        for point in range(1,len(poly)):\n","            d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n","            angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n","        angulo_manzana.append(angulos[d.index(max(d))])\n","    shape[\"angulo_manzana\"]=angulo_manzana\n","    shape[\"geometry\"]=shape[\"geometry\"].envelope\n","    for manzana in range(len(shape)):\n","        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","        proyecciones=proyecciones1[0]\n","        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","        min_y,min_x=point1[0],point1[1]\n","        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","        max_y,max_x=point2[0],point2[1]\n","        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n","    shape1=pd.DataFrame()\n","    shape1['points']=c\n","    shape1=shape1['points'].str.split(',',expand=True)\n","    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n","    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n","    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n","    shape=shape1\n","    return shape\n","    \n","def ampliar_shape(shape,factor_ampliacion=2):\n","    \"\"\"Amplifica el polygon de cada manzana con el fin de extrar imagenes sin perder informacion de la manzana\"\"\"\n","    shape[\"geometry\"]=shape[\"geometry\"].envelope\n","    shape['centroid']=shape.centroid\n","    geometry=[]\n","    for i,polygon in enumerate(shape['geometry']):\n","        point=mapping(shape['centroid'][i]).get('coordinates')\n","        x=point[0]\n","        y=point[1]\n","        go=[]\n","        coodinates=mapping(polygon).get('coordinates')[0]\n","        for a in coodinates:\n","            x1=a[0]\n","            y1=a[1]\n","            x2=x+(x1-x)*factor_ampliacion\n","            y2=y+(y1-y)*factor_ampliacion\n","            go.append((x2,y2))\n","        geometry.append(Polygon(go))\n","    return gpd.GeoDataFrame(shape[\"cve_cat\"],geometry=geometry)\n","\n","# idx_to_class={0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n","class alexnet():\n","    def __init__(self,weights,num_classes,idx_to_class):\n","        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n","        alexnet=models.alexnet(pretrained=True)\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        checkpoint=torch.load(weights,map_location=self.device)\n","        # \n","        alexnet.features[1]= nn.Hardtanh()\n","        alexnet.classifier[6] = nn.Linear(4096, 4096)\n","        alexnet.classifier.add_module(\"7\",nn.Softplus())\n","        alexnet.classifier.add_module(\"8\", nn.Linear(4096, 4096))\n","        alexnet.classifier.add_module(\"9\",nn.Softplus())\n","        alexnet.classifier.add_module(\"10\", nn.Linear(4096, 2048))\n","        alexnet.classifier.add_module(\"11\", nn.Softplus())\n","        alexnet.classifier.add_module(\"12\", nn.Linear(2048, num_classes))\n","        alexnet.classifier.add_module(\"13\", nn.Softplus())\n","        alexnet.classifier.add_module(\"14\",  nn.LogSoftmax(dim = 1))\n","        # for param in alexnet.parameters():\n","        #     param.requires_grad = False\n","        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n","        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n","        alexnet.load_state_dict(checkpoint['model_state_dict'])\n","        summary(alexnet, (3, 224, 224))\n","        self.model=alexnet\n","        self.idx_to_class=idx_to_class\n","    \n","    def predict_file(self,file,pad=True):\n","        \"\"\"Genera prediccion sobre archivo\"\"\"\n","        x = Image.open(file)\n","        x = np.asarray(x)\n","        if pad:\n","            x=padding(x)\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        img = torch.from_numpy(x).to(self.device)\n","        res=list(self.model(img).cpu().detach().numpy()[0])\n","        indice=res.index(max(res))\n","        clase=self.idx_to_class.get(indice)\n","        return clase \n","    \n","    def predict_image(self,image,pad=True):\n","        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n","        x = np.asarray(image)\n","        if pad:\n","            x=padding(x)\n","        imagen=x.copy()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        img = torch.from_numpy(x).to(self.device)\n","        res=list(self.model(img).cpu().detach().numpy()[0])\n","        indice=res.index(max(res))\n","        clase=self.idx_to_class.get(indice)\n","        return clase, imagen \n","    \n","def padding(img):\n","    \"\"\"Escala la imagen y completa el sobrante con franjas negras, para no perder proporciones\"\"\"                \n","    old_image_height, old_image_width, channels = img.shape\n","    new_image_width = 224\n","    new_image_height = 224\n","    color = (0,0,0)\n","    if old_image_height<=old_image_width:\n","        f=new_image_width/old_image_width\n","    else:\n","        f=new_image_height/old_image_height\n","    img=cv2.resize(img,(int(f*old_image_width),int(f*old_image_height)))\n","    old_image_height, old_image_width, channels = img.shape\n","    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n","    x_center = (new_image_width - old_image_width) // 2\n","    y_center = (new_image_height - old_image_height) // 2\n","    try:\n","        result[y_center:y_center+old_image_height, \n","            x_center:x_center+old_image_width] = img\n","    except:\n","        result=img \n","    return result        \n","class mobilenet_class():\n","    def __init__(self,alexnet,weights,num_classes,idx_to_class):\n","        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n","        # alexnet=models.alexnet(pretrained=True)\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        \n","        checkpoint=torch.load(weights,map_location=self.device)\n","        # checkpoint=torch.load(weights)\n","        # \n","        alexnet.classifier[3] = nn.Linear(1024, num_classes)\n","        alexnet.classifier.add_module(\"4\", nn.LogSoftmax(dim = 1))\n","        # for param in alexnet.parameters():\n","        #     param.requires_grad = False\n","        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n","        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n","        alexnet.load_state_dict(checkpoint['model_state_dict'])\n","        summary(alexnet.to(self.device), (3, 224, 224))\n","        self.model=alexnet\n","        self.idx_to_class=idx_to_class\n","\n","    \n","    def predict_file(self,file,pad=True):\n","        \"\"\"Genera prediccion sobre archivo\"\"\"\n","        x = Image.open(file)\n","        x = np.asarray(x)\n","        # if pad:\n","        #     # resize\n","        #     x= x.resize()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        # Cambiar normalizacion\n","        x=x/255*2-1\n","\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase \n","    \n","    def predict_image(self,image,pad=True):\n","        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n","        x = np.asarray(image)\n","        # if pad:\n","        #     x=padding(x)\n","        imagen=x.copy()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        # Cambiar normalizacion\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase, imagen "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"H03QvtpAACKB","executionInfo":{"status":"ok","timestamp":1682721469663,"user_tz":360,"elapsed":165,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"outputs":[],"source":["def matchingTemplate(img_rgb,template,nameimg,threshold = .7):\n","    '''\n","(Function)\n","(Parameters)\n","    - threshold: Porcentaje de coincidencia \n","    '''\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n","    w, h = template.shape[::-1]\n","    res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n","    loc = np.where( res >=threshold)\n","    startpoints=[]\n","    endpoints=[]\n","    x=-10\n","    y=-10\n","    for i,pt in enumerate(zip(*loc[::-1])):\n","        if i==0:\n","            x=pt[0]\n","            y=pt[1]\n","            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","            cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","            startpoints.append(pt)\n","            endpoints.append((pt[0] + w, pt[1] + h))\n","        if (pt[0]!=x and pt[0]+1!=x and pt[0]-1!=x and pt[0]+2!=x and pt[0]-2!=x) and (pt[1]!=y and pt[1]+1!=y and pt[1]-1!=y and pt[1]+2!=y and pt[1]-2!=y):\n","            x=pt[0]\n","            y=pt[1]\n","            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","            cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","            startpoints.append(pt)\n","            endpoints.append((pt[0] + w, pt[1] + h))\n","    return img_rgb,startpoints,endpoints"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2R-tQRcWACKC","executionInfo":{"status":"ok","timestamp":1682721491409,"user_tz":360,"elapsed":778,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}},"outputId":"573597e0-71c6-49a8-e9ca-38d3425d81b0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(123,\n"," 105,\n"," 667,\n"," CRS.from_epsg(3857),\n"," 82172,\n"," 70382,\n"," -11084278.6993,\n"," -11063163.9539,\n"," 2181047.5457,\n"," 2205699.1587)"]},"metadata":{},"execution_count":8}],"source":["raster=r\"/content/drive/MyDrive/Equipo_Agua/Geo/Data/geoshaps/lerma/ler_a.tif\"\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=200)\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"8cLkCch2ACKC","executionInfo":{"status":"ok","timestamp":1682721497648,"user_tz":360,"elapsed":2,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"outputs":[],"source":["def rotacion_detect(startpoint,endpoint,angle,proyecciones,w,h,dim):\n","    \"\"\"Rotata el cuadro detectado en el sistema de coordenadas inicial\"\"\"\n","    point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","    min_y,min_x=point1[0],point1[1]\n","    point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","    max_y,max_x=point2[0],point2[1]\n","    min_y,min_x,max_y,max_x,proyecciones\n","    tipos=[\"casa\",\"terreno\"]\n","    y1,x1=startpoint\n","    y2,x2=endpoint\n","    x1,y1=(x1)*2-1,(y1)*2-1\n","    x2,y2=(x2)*2-1,(y2)*2-1\n","    angle=angle*math.pi/180\n","#     x1,y1=x1*(w/dim),y1*(h/dim)\n","#     x2,y2=x2*(w/dim),y2*(h/dim)\n","    #x_p, y_p son los puntos de un rectangulo en el orden inverso al manecillas del reloj\n","    x1p=max_x-((x1*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y1p=min_y+((x1*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x2p=max_x-((x2*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y2p=min_y+((x2*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x3p=max_x-((x2*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y3p=min_y+((x2*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x4p=max_x-((x1*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y4p=min_y+((x1*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    return Polygon(((y1p,x1p),(y2p,x2p),(y3p,x3p),(y4p,x4p),(y1p,x1p)))"]},{"cell_type":"code","source":["diccionario = {0: 'Hospital', 1: 'Jardin', 2: 'a_verdes', 3: 'a_verdes_1', 4: 'a_verdes_2', 5: 'bancos_google', 6: 'bar',\n","               7: 'cine', 8: 'correo', 9: 'cultural_3', 10: 'dinero', 11: 'educativo', 12: 'entretenimiento_google', \n","               13: 'establecimientos_2_google', 14: 'establecimientos_google', 15: 'gas_google', 16: 'gobierno_google', \n","               17: 'golf', 18: 'hospedaje_google', 19: 'juegos_google', 20: 'playa_google', 21: 'poli', 22: 'restaurante_google',\n","               23: 'salud_google', 24: 'sitios_interes_google', 25: 'templo_google', 26: 'tiendas_1', 27: 'tiendas_2', 28: 'turista_google'}\n","weights = '/content/drive/MyDrive/Equipo_Agua/Geo/Data/Chinchetas/checkpoint/best_modHector.pth'\n","modelo = models.mobilenet_v3_small(weights='DEFAULT')\n","mobilenet = mobilenet_class(modelo,weights,len(diccionario),diccionario)"],"metadata":{"id":"XLRnfwGRHvR4","executionInfo":{"status":"ok","timestamp":1682723303673,"user_tz":360,"elapsed":228,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6RWtZsTIUD6","executionInfo":{"status":"ok","timestamp":1682723397344,"user_tz":360,"elapsed":152,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}},"outputId":"39ef3289-20b6-4863-d7d5-a08404fe5592"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"GZ30sBy5G5ZY","executionInfo":{"status":"ok","timestamp":1682723564817,"user_tz":360,"elapsed":359,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hx8jL9qiI7Dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UmrpP_EyINb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mobilenet.predict_file('/content/drive/MyDrive/Equipo_Agua/Geo/Data/Chinchetas/chinchetas.zip (Unzipped Files)/0_33_20deteccion.png')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"eqJIp4JlJGCh","executionInfo":{"status":"ok","timestamp":1682723654083,"user_tz":360,"elapsed":282,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}},"outputId":"a63a3489-f1b1-4e59-f456-cad92c10126c"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'establecimientos_2_google'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfpH8WegACKC"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","\n","chincheta=[]\n","clases=[]\n","show_imagen = False\n","# Plantilla de reconociemientt\n","template = cv2.imread(r\"/content/drive/MyDrive/Equipo_Agua/Geo/Data/Chinchetas/nuevo.png\")\n","template_gray=template[:,:,1]\n","with rasterio.open(raster) as src:\n","    with tqdm.tqdm(total=alto*ancho*4) as pbar:\n","        for j in range(ancho*2):#ancho\n","            for i in range(alto*2):#alto\n","                generar=0\n","                label=raster.replace('\\\\','/').split('/')[-1][:-4]+'_'\n","                nameimg=label.lower()+str(i)+'_'+str(j)\n","                cuadro=[]\n","                for k in range(2):\n","                    for l in range(2):\n","                        cuadro.append((minx+(maxx-minx)/ancho*(j/2+k),maxy-(maxy-miny)/alto*(i/2+l)))\n","                cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n","                shapes=[{'type':'Polygon','coordinates':[cuadro]}]\n","                vector=[]\n","                array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","                if np.sum(array)<100:\n","                    pbar.update(1)\n","                    continue\n","                four_images=[array[2],array[1],array[0]]\n","                imagen_n = np.stack(four_images, axis=-1)\n","                image_o=imagen_n.copy()\n","                try:\n","                    imagen_n,startpoints, endpoints=matchingTemplate(imagen_n,template_gray,nameimg,threshold = .7)\n","                except:\n","                    pbar.update(1)\n","                    continue\n","                \n","                for s in range(len(startpoints)):\n","                    startpoint=startpoints[s]\n","                    endpoint=endpoints[s]\n","                    df_aux=image_o.copy()\n","                    x1,y1=startpoint\n","                    x2,y2=endpoint\n","                    df_aux=df_aux[y1:y2,x1:x2] \n","                    # clasificacion\n","\n","                    clase_aux, imagen_aux  = mobilenet.predict_image(df_aux)\n","                    if clase_aux:\n","                        clases.append(clase_aux)\n","                    # En caso de querer almacenar lo cuadritos, poner ruta\n","#                     cv2.imwrite(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\pines/\"+str(j)+\"_\"+str(i)+\"_\"+str(s)+\"deteccion.png\",df_aux)\n","\n","                    startpoint=[x/dim for x in startpoint]\n","                    endpoint=[x/dim for x in endpoint]\n","                    proyecciones=cuadro\n","                    chincheta.append(rotacion_detect(startpoint,endpoint,0,proyecciones,dim,dim,dim))\n","                if show_imagen:\n","                    cv2_imshow(imagen_n)\n","                    # cv2.waitKey()\n","                    # cv2.destroyAllWindows()\n","\n","                \n","                \n","                pbar.update(1)\n","                \n","                "]},{"cell_type":"code","source":["gps['Clase'].head(1).values"],"metadata":{"id":"xa7isIBYKl3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":40,"metadata":{"id":"3gcblWu8ACKD","executionInfo":{"status":"ok","timestamp":1682724593925,"user_tz":360,"elapsed":321,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"}}},"outputs":[],"source":["gps=gpd.GeoDataFrame({'Clase':clases}, geometry=chincheta,crs=crs)\n","gps\n","# gps[\"centroidx\"]=gps.centroid.x/10\n","# gps[\"centroidy\"]=gps.centroid.y/10\n","# gps[\"centroidx\"]=gps[\"centroidx\"].astype(\"int\")\n","# gps[\"centroidy\"]=gps[\"centroidy\"].astype(\"int\")\n","# gps=gps.drop_duplicates([\"centroidx\",\"centroidy\"])\n","gps.to_file(r\"/content/drive/MyDrive/Equipo_Agua/Geo/Data/Chinchetas/Shapes/ejemplo1.shp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7PZ2z0SACKD"},"outputs":[],"source":["def cv2_imshow(name,image):\n","    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n","    cv2.imshow(name,image)\n","    cv2.waitKey()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2JsCCM8ACKD"},"outputs":[],"source":["import glob\n","filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\pines/*.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ummNwNCuACKE"},"outputs":[],"source":["import tqdm\n","file='C:\\\\Users\\\\ASUS\\\\Inteligencia_Artificial\\\\chinchetas\\\\0_28_1deteccion.png'\n","valor=[]\n","color=[]\n","for file in tqdm.tqdm(filenames):\n","    image2=cv2.imread(file)\n","    Z = image2.reshape((-1,3))\n","    # convert to np.float32\n","    Z = np.float32(Z)\n","    # define criteria, number of clusters(K) and apply kmeans()\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","    K = 1\n","    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n","    # Now convert back into uint8, and make original image\n","    center = np.uint8(center[0])\n","    color.append(\"\".join([str(int(np.ceil(x/255*10))).zfill(3) for x in center]))\n","    _,image=cv2.threshold(image2[:,:,1],200,255,cv2.THRESH_BINARY)\n","    # image=image[5:41,6:29]\n","    image=image/255\n","    images=pd.DataFrame(image)\n","    x1=0\n","    x2=100\n","    for col in images.columns:\n","        if images[col].sum()>=len(images)-5:\n","            if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","                x1=int(col)+1\n","            if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","                x2=int(col)\n","    y1,y2=(0,len(images))\n","    image1=image[y1:y2,x1:x2]\n","    images=pd.DataFrame(image1)\n","    y1=0\n","    y2=100\n","    for i in range(len(images)):\n","        if images.iloc[i].sum()>=len(images.columns)-5:\n","            if int(i)>=y1 and int(i)<=int(len(images)/2):\n","    #             print(y1)\n","                y1=int(i)+1\n","            if int(i)>=y1 and int(i)<=y2 and int(i)>=int(len(images)/2):\n","                y2=int(i)\n","    image1=image1[y1:y2,0:len(images.columns)]\n","#     images=pd.DataFrame(image1)\n","#     x1=0\n","#     x2=100\n","#     for col in images.columns:\n","#         if images[col].sum()==len(images):\n","#             if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","#                 x1=int(col)+1\n","#             if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","#                 x2=int(col)\n","#     y1,y2=(0,len(images))\n","#     image1=image1[y1:y2,x1:x2]\n","#     cv2_imshow(\"a\",image1)\n","    valor.append(np.sum(image1))\n","res=pd.DataFrame({\"file\":filenames,\"valor\":valor,\"color\":color})\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8xNlZPGACKE"},"outputs":[],"source":["res[\"valor1\"]=[int(x/10) for x in res[\"valor\"]]\n","res[\"valor2\"]=[int(str(x).replace(\".\",\"\")) for x in res[\"color\"]]\n","Z = np.vstack((res[\"valor\"],res[\"valor2\"]))\n","# convert to np.float32\n","Z = np.float32(Z)\n","# define criteria and apply kmeans()\n","# criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","# ret,label,center=cv.kmeans(Z,2,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)\n","# res.groupby(\"valor2\").count()\n","import matplotlib.pyplot as plt\n","plt.scatter(res[\"valor1\"],res[\"valor2\"],cmap='viridis',marker=\"o\")\n","# A = Z[label.ravel()==0]\n","# B = Z[label.ravel()==1]\n","# # Plot the data\n","# plt.scatter(A[:,0],A[:,1])\n","# plt.scatter(B[:,0],B[:,1],c = 'r')\n","# plt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')\n","# plt.xlabel('Height'),plt.ylabel('Weight')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkRSuOO1ACKE"},"outputs":[],"source":["res[\"valor2\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PKzXCdFACKE"},"outputs":[],"source":["aux=res[res[\"valor2\"]==9009008].sort_values([\"valor1\",\"valor2\"]).reset_index(drop=True).head(100)\n","aux"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0VkOsEhACKF"},"outputs":[],"source":["for i in range(len(aux)):\n","    im=cv2.imread(aux[\"file\"][i])\n","    cv2_imshow(str(aux.loc[i,\"valor1\"])+\"_\"+str(aux.loc[i,\"valor2\"]),im)"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}