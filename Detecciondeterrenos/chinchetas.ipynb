<<<<<<< HEAD
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-hptFtUIAeOz"},"outputs":[],"source":["!pip install rasterio\n","!pip install geopandas"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4240,"status":"ok","timestamp":1682721378095,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"-pL7gYjYACJ6","outputId":"67dd4d69-03b0-4ff5-f386-ec2f7232e39f"},"outputs":[],"source":["%matplotlib inline\n","import os\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","from osgeo import gdal\n","import rasterio\n","import geopandas as gpd\n","import rasterio.mask\n","from rasterio.windows import Window\n","import sys\n","from shapely.geometry import mapping\n","sys.path.append(r'C:\\Users\\ruben\\Desktop\\GEM\\geoloc2\\Detecciondeterrenos')\n","from codigos import Generar_txt\n","###path de yolo dentro de computadora\n","os.chdir(r'C:\\Users\\ruben\\yolov7')\n","# from detect_Alberto_v4 import *\n","from scipy.ndimage import rotate as rotate_image\n","from shapely import geometry\n","import time\n","import datetime\n","from clasificacion_chinchetas import *"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":379,"status":"ok","timestamp":1682724500122,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"JAhc35fnACJ8"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Mar 29 10:45:35 2023\n","@author: Alberto\n","\"\"\"\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import math\n","from shapely.geometry import Polygon\n","import cv2\n","import time\n","from pathlib import Path\n","import torch\n","import tqdm\n","import numpy as np\n","from models.experimental import attempt_load\n","from utils.datasets import LoadImages , letterbox\n","from utils.general import check_img_size, non_max_suppression, scale_coords, xyxy2xywh, set_logging\n","from utils.torch_utils import select_device, time_synchronized, TracedModel\n","import os\n","from osgeo import gdal\n","import rasterio\n","import geopandas as gpd\n","import rasterio.mask\n","from rasterio.windows import Window\n","import sys\n","from shapely.geometry import mapping\n","from scipy.ndimage import rotate as rotate_image\n","from shapely import geometry\n","import cv2\n","import torch,torchvision\n","import numpy as np\n","import torch.nn as nn\n","from PIL import Image\n","from torchvision import models\n","from torchsummary import summary\n","opt_img_size=256\n","class modelo():\n","    def __init__(self,weights=[\"yolov7.pt\"]):\n","        \"\"\"inicializa el modelo con los pesos\"\"\"\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        model = attempt_load(weights, map_location=self.device)\n","        model = TracedModel(model, self.device, opt_img_size)\n","        self.model= model\n","        \n","    def detect(self,opt_conf_thres,opt_source=\"train/images\",display=False,imagen_s=np.array([1,1])):\n","        \"\"\"Genera las deteccion de objetos por imagen precargada o por carpeta/archivo\"\"\"\n","        vector=[]\n","        opt_no_trace=False\n","        opt_iou_thres=0.45\n","        opt_save_conf=True\n","        opt_classes=None\n","        opt_agnostic_nms=False\n","        opt_augment=False\n","        opt_no_trace=False\n","        source,  imgsz, trace = opt_source, opt_img_size, not opt_no_trace\n","        set_logging()\n","        half = self.device.type != 'cpu'  # half precision only supported on CUDA\n","    # load FP32 model\n","        stride = int(self.model.stride.max())  # self.model stride\n","        imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","        if half:\n","            self.model.half()  # to FP16\n","        names = self.model.module.names if hasattr(self.model, 'module') else self.model.names\n","        # Set Dataloader\n","        if imagen_s.shape[0]==2:\n","            dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","            t0 = time.time()\n","            for path, img, im0s, vid_cap in tqdm.tqdm(dataset):\n","                img = torch.from_numpy(img).to(self.device)\n","                img = img.half() if half else img.float()  # uint8 to fp16/32\n","                img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","                if img.ndimension() == 3:\n","                    img = img.unsqueeze(0)\n","                t1 = time_synchronized()\n","                with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","                    pred = self.model(img, augment=opt_augment)[0]\n","                t2 = time_synchronized()\n","                pred = non_max_suppression(pred, opt_conf_thres, opt_iou_thres, classes=opt_classes, agnostic=opt_agnostic_nms)\n","                t3 = time_synchronized()\n","                for i, det in enumerate(pred):  # detections per image\n","                    p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","                    p = Path(p)  # to Path\n","                    gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","                    if len(det):\n","                        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","                        for c in det[:, -1].unique():\n","                            n = (det[:, -1] == c).sum()  # detections per class\n","                            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","                        for *xyxy, conf, cls in reversed(det):\n","                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                            line = (cls, *xywh, conf) if opt_save_conf else (cls, *xywh)  # label format\n","                            vector.append(list(line)+[p.name[:-4]])  \n","                if display:\n","                    print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","        else:\n","            img0=imagen_s  \n","            img = letterbox(img0, imgsz, stride)[0]\n","            img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n","            img = np.ascontiguousarray(img)\n","            img = torch.from_numpy(img).to(self.device)\n","            img = img.half() if half else img.float()\n","            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","            if img.ndimension() == 3:\n","                img = img.unsqueeze(0)\n","            t1 = time_synchronized()\n","            with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","                pred = self.model(img, augment=opt_augment)[0]\n","                # pred_o=pred\n","            t2 = time_synchronized()\n","            pred = non_max_suppression(pred, opt_conf_thres, opt_iou_thres, classes=opt_classes, agnostic=opt_agnostic_nms)\n","            t3 = time_synchronized()\n","            for i, det in enumerate(pred):  # detections per image\n","                s, im0 =  '', img0\n","#                 p = Path(p)  # to Path\n","                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","                if len(det):\n","                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n","                    for c in det[:, -1].unique():\n","                        n = (det[:, -1] == c).sum()  # detections per class\n","                        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","                    for *xyxy, conf, cls in reversed(det):\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if opt_save_conf else (cls, *xywh)  # label format\n","                        vector.append(line)\n","        return vector\n","    \n","def correct_orientation(img_rgb,dim,pattern_path=\"pattern1.png\"):\n","    \"\"\"Determina el angulo donde existe la mayor deteccion de lineas rectas\"\"\"\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n","    template = cv2.imread(pattern_path,0)\n","    w, h = template.shape[::-1]\n","    template  = cv2.resize(template,(int(w/4),int(h/4)))\n","    image_ro=img_gray.copy()\n","    angulo=0\n","    an=[]\n","    le=0\n","    angulo_f=0\n","    imagen_final=img_rgb.copy()\n","    for i in range(-45,45,1):\n","        angulo=i\n","        M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n","        image_ro = cv2.warpAffine(img_gray, M, (dim,dim))\n","        res = cv2.matchTemplate(image_ro,template,cv2.TM_CCOEFF_NORMED)\n","        threshold =.5\n","        loc = np.where( res >= threshold)\n","        com=len(loc[0])\n","        if com>0:\n","            an.append(angulo)\n","            if le<com:\n","                le=com\n","                angulo_f=angulo\n","                M = cv2.getRotationMatrix2D((dim//2,dim//2), angulo, 1)\n","                imagen_final = cv2.warpAffine(img_rgb, M, (dim,dim))\n","    return angulo_f,imagen_final\n","\n","def verificacion(im):\n","    \"\"\"filtro para determinar cuanta area verde existe en la imagen\"\"\"\n","    hsv=cv2.cvtColor(im,cv2.COLOR_BGR2HSV)\n","    mask=cv2.inRange(hsv,(12,30,0),(160,232,160))\n","    verde=int((np.sum(mask)/im.shape[0]**2/255)*100)\n","    return verde \n","\n","def vector2xy(vector,w,h,dim=700,nameimg=\"image\",angle=0):\n","    \"\"\"Transforma el vector de deteccion en coordendas porcentuales y enteras de la imagen\"\"\"\n","    s=[]\n","    for v in vector:\n","        str_v=(str(v).replace(\"tensor(\",\"\").replace(\"=\",\"\").replace(\", device\",\"\").replace(\"[\",\"\").replace(\"'cuda:0'\",\"\").replace(\"]\",\"\").replace(\".)\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"']\",\"\").replace(\"'\",\"\").strip().split(\",\"))\n","#         h,w=dim,dim\n","        x1 = int( float(str_v[1]) * w )\n","        y1 = int( float(str_v[2]) * h )\n","        xw = int( float(str_v[3]) * w /2)\n","        yw = int( float(str_v[4]) * h /2)\n","        start_point_im = ((x1 - xw), (y1 - yw))\n","        end_point_im   = ((x1 + xw), (y1 + yw))\n","        start_point_100 = ((x1 - xw)/w, (y1 - yw)/h)\n","        end_point_100   = ((x1 + xw)/w, (y1 + yw)/h)\n","        area=xw*yw\n","        conf=str_v[5]\n","        try:\n","            nameimg=str_v[6]\n","        except:\n","            pass\n","        if str(str_v[0])==\"0\":\n","            tipo=\"casa\"\n","        else:\n","            tipo=\"terreno\"\n","        if int(xw)!=0 and int(yw)!=0:# and (xw/yw<=3.2 and yw/xw<=3.2):\n","            s.append([tipo,start_point_im,end_point_im,start_point_100,end_point_100,area,conf,nameimg,\" \".join(str_v[:5])])\n","    df_cache=pd.DataFrame(s,columns=[\"Tipo\",\"start_point_im\",\"end_point_im\",\"start_point_100\",\"end_point_100\",\"area\",\"conf\",\"imagen\",\"vector_o\"])\n","    df_cache.drop_duplicates().reset_index(drop=True,inplace=True)\n","    return df_cache\n","    \n","def imshow_detect(df_cache,imagen_n,nameimg=\"image\"):\n","    \"\"\"muestra la imagen con las detecciones\"\"\"\n","    for i in range(len(df_cache)):\n","            if df_cache[\"Tipo\"][i]==\"casa\":\n","                x,y=df_cache[\"start_point_im\"][i]\n","                cv2.rectangle(imagen_n,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,0,255),2)\n","#                 cv2.putText(imagen_n, str(df_cache[\"conf\"][i]), (x+50,y+50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n","            else:\n","                x,y=df_cache[\"start_point_im\"][i]\n","                cv2.rectangle(imagen_n,df_cache[\"start_point_im\"][i],df_cache[\"end_point_im\"][i],(0,255,0),2)\n","#                 cv2.putText(imagen_n, str(int(float(df_cache[\"conf\"][i])*100)/100),(x+50,y+50) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","    cv2.imshow(nameimg,imagen_n)\n","    cv2.waitKey()\n","    cv2.destroyAllWindows()\n","\n","def rotacion_detect(startpoint,endpoint,angle,proyecciones,w,h,dim):\n","    \"\"\"Rotata el cuadro detectado en el sistema de coordenadas inicial\"\"\"\n","    point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","    min_y,min_x=point1[0],point1[1]\n","    point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","    max_y,max_x=point2[0],point2[1]\n","    min_y,min_x,max_y,max_x,proyecciones\n","    tipos=[\"casa\",\"terreno\"]\n","    y1,x1=startpoint\n","    y2,x2=endpoint\n","    x1,y1=(x1)*2-1,(y1)*2-1\n","    x2,y2=(x2)*2-1,(y2)*2-1\n","    angle=angle*math.pi/180\n","    x1,y1=x1*(w/dim),y1*(h/dim)\n","    x2,y2=x2*(w/dim),y2*(h/dim)\n","    #x_p, y_p son los puntos de un rectangulo en el orden inverso al manecillas del reloj\n","    x1p=max_x-((x1*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y1p=min_y+((x1*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x2p=max_x-((x2*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y2p=min_y+((x2*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x3p=max_x-((x2*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y3p=min_y+((x2*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x4p=max_x-((x1*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y4p=min_y+((x1*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    return Polygon(((y1p,x1p),(y2p,x2p),(y3p,x3p),(y4p,x4p),(y1p,x1p)))\n","\n","def map_d(x, in_min, in_max, out_min, out_max):\n","    \"\"\"Genera una interpolacion para pasar de un rango a otro\"\"\"\n","    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n","\n","def postproceso(Modelo,model_class,casas,conf_casas,clase_casas,terreno,conf_terreno,clase_terreno,raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0,opt_conf_thres=0.05,imshow=False,imsave=False,path=\"\"):\n","    with rasterio.open(raster) as src:\n","        with tqdm.tqdm(total=alto*ancho) as pbar:\n","            for j in range(ancho):#ancho\n","                for i in range(alto):#alto\n","                    generar=0\n","                    label=raster.replace('\\\\','/').split('/')[-1][:-4]+'_'\n","                    nameimg=label.lower()+str(i)+'_'+str(j)\n","                    cuadro=[]\n","                    for k in range(2):\n","                        for l in range(2):\n","                            cuadro.append((minx+(maxx-minx)/ancho*(j+k),maxy-(maxy-miny)/alto*(i+l)))\n","                    cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n","                    cvees=[]\n","                    for punto in cuadro:\n","                        x=float(punto[0])\n","                        y=float(punto[1])\n","                        mini_df=shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)]\n","                        if len(mini_df)>0:\n","                            generar=1\n","                            cvees.append(mini_df[\"cve_cat\"].values)### traer todas las cve_catastrales del punto sobre el raster ...Pendiente\n","#                             print(cvees)\n","                    if generar==1:\n","                        shapes=[{'type':'Polygon','coordinates':[cuadro]}]\n","                        vector=[]\n","                        array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","                        if np.sum(array)<100:\n","                            pbar.update(1)\n","                            continue\n","                        four_images=[array[2],array[1],array[0]]\n","                        imagen_n = np.stack(four_images, axis=-1)\n","                        if imsave:\n","                            cv2.imwrite(path+\"/\"+nameimg+\".png\",imagen_n)\n","                            # print(path+\"/\"+nameimg+\".png\")\n","                        if angulo_get!=0:\n","                            angulo=-angulo_get\n","                        else:\n","                            angulo=correct_orientation(imagen_n,dim=dim)[0]\n","                        image_ro=imagen_n.copy()\n","                        image_ro=rotate_image(image_ro,angulo,reshape=True)\n","                        w=image_ro.shape[0]\n","                        h=image_ro.shape[1]\n","                        with torch.no_grad():\n","                            vector=Modelo.detect(opt_source=\"cache1.png\",opt_conf_thres=opt_conf_thres,imagen_s=image_ro)\n","                        proyecciones=shapes[0].get('coordinates')[0][:-1]\n","                        df_cache=vector2xy(vector,w,h,dim=dim,nameimg=nameimg)\n","                        for cs_1 in (range(len(df_cache))):\n","    #                         x1,y1=df_cache.loc[cs_1,'start_point_im']\n","    #                         x2,y2=df_cache.loc[cs_1,'end_point_im']\n","    #                         df_aux=image_ro.copy()\n","    #                         df_aux=df_aux[y1:y2,x1:x2]\n","    #                         clase,imagen=model_class.predict_iamge(df_aux)\n","    #                         if np.sum(df_aux)>500:\n","    #                             if crear:\n","    #                                 name=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\calsificador\\salida/\"+clase+\"/\"+str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\"_\").replace(\".\",\"_\").replace(\"-\",\"_\")+\".png\"\n","    #                                 cv2.imwrite(name,imagen)\n","                            x1,y1=df_cache.loc[cs_1,'start_point_im']\n","                            x2,y2=df_cache.loc[cs_1,'end_point_im']\n","                            df_aux=image_ro.copy()\n","                            df_aux=df_aux[y1:y2,x1:x2]\n","                            clase,imagen=model_class.predict_image(df_aux)\n","                            if df_cache['Tipo'][cs_1]=='casa':\n","                                if np.sum(df_aux)>500:\n","                                    casas.append(rotacion_detect(df_cache.loc[cs_1,'start_point_100'], df_cache.loc[cs_1,'end_point_100'],-angulo,proyecciones,w,h,dim))\n","                                    conf_casas.append(df_cache.loc[cs_1,'conf'])\n","                                    clase_casas.append(clase)\n","\n","                            else:\n","                                terreno.append(rotacion_detect(df_cache.loc[cs_1,'start_point_100'], df_cache.loc[cs_1,'end_point_100'],-angulo,proyecciones,w,h,dim))\n","                                conf_terreno.append(df_cache.loc[cs_1,'conf'])\n","                                clase_terreno.append(clase)\n","                        if imshow:\n","                            print(angulo)\n","                            imshow_detect(df_cache,image_ro)\n","\n","                    pbar.update(1)\n","                    \n","def Parametro_raster(raster,metros=120):\n","    \"\"\"Se obtienen las dimensiones del raster y del cuadro de corte\"\"\"\n","    gdal_interpeter = gdal.Open(raster)\n","    width = gdal_interpeter.RasterXSize\n","    height = gdal_interpeter.RasterYSize\n","    coordenadas_gdal = gdal_interpeter.GetGeoTransform()\n","    minx = coordenadas_gdal[0]\n","    miny = coordenadas_gdal[3] + width*coordenadas_gdal[4] + height*coordenadas_gdal[5] \n","    maxx = coordenadas_gdal[0] + width*coordenadas_gdal[1] + height*coordenadas_gdal[2]\n","    maxy = coordenadas_gdal[3]\n","    src_raster_path = raster\n","    src=rasterio.open(src_raster_path)\n","    H,W=src.shape\n","    dim=int(np.ceil(map_d(minx+metros,minx,maxx,0,W)))\n","    alto=np.max([1,int(np.floor(H/dim))])\n","    ancho=np.max([1,int(np.floor(W/dim))])\n","    return alto,ancho,dim,src.crs,H,W,minx,maxx,miny,maxy\n","\n","\n","def shape_transform(shape):\n","    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n","    c=[]\n","    angulo_manzana=[]\n","\n","    # for manzana in range(len(shape)):\n","    #     proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","    #     angulos=[]\n","    #     d=[]\n","    #     poly=pd.DataFrame(proyecciones1[0])\n","    #     for point in range(1,len(poly)):\n","    #         d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n","    #         angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n","    #     angulo_manzana.append(angulos[d.index(max(d))])\n","    shape[\"angulo_manzana\"]=0\n","    shape[\"geometry\"]=shape[\"geometry\"].envelope\n","    for manzana in range(len(shape)):\n","        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","        proyecciones=proyecciones1[0]\n","        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","        min_y,min_x=point1[0],point1[1]\n","        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","        max_y,max_x=point2[0],point2[1]\n","        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n","    shape1=pd.DataFrame()\n","    shape1['points']=c\n","    shape1=shape1['points'].str.split(',',expand=True)\n","    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n","    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n","    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n","    shape=shape1\n","    return shape\n","    \n","def ampliar_shape(shape,factor_ampliacion=2):\n","    \"\"\"Amplifica el polygon de cada manzana con el fin de extrar imagenes sin perder informacion de la manzana\"\"\"\n","    shape[\"geometry\"]=shape[\"geometry\"].envelope\n","    shape['centroid']=shape.centroid\n","    geometry=[]\n","    for i,polygon in enumerate(shape['geometry']):\n","        point=mapping(shape['centroid'][i]).get('coordinates')\n","        x=point[0]\n","        y=point[1]\n","        go=[]\n","        coodinates=mapping(polygon).get('coordinates')[0]\n","        for a in coodinates:\n","            x1=a[0]\n","            y1=a[1]\n","            x2=x+(x1-x)*factor_ampliacion\n","            y2=y+(y1-y)*factor_ampliacion\n","            go.append((x2,y2))\n","        geometry.append(Polygon(go))\n","    return gpd.GeoDataFrame(shape[\"cve_cat\"],geometry=geometry)\n","\n","# idx_to_class={0: 'area_verde', 1: 'carros', 2: 'casas', 3: 'en_construccion', 4: 'establecimiento', 5: 'multivivienda', 6: 'terreno_baldio'}\n","class alexnet():\n","    def __init__(self,weights,num_classes,idx_to_class):\n","        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n","        alexnet=models.alexnet(pretrained=True)\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        checkpoint=torch.load(weights,map_location=self.device)\n","        # alexnet.features[1]= nn.Hardtanh()\n","        alexnet.classifier[6] = nn.Linear(4096, num_classes)\n","        alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n","        summary(alexnet, (3, 224, 224))\n","        self.model=alexnet\n","        self.idx_to_class=idx_to_class\n","    \n","    def predict_file(self,file,pad=True):\n","        \"\"\"Genera prediccion sobre archivo\"\"\"\n","        # x = Image.open(file)\n","        # x = np.asarray(x)\n","        # x=np.stack([x[:,:,0],x[:,:,1],x[:,:,2]], axis=-1)\n","        x=cv2.imread(file)\n","        if pad:\n","            x=padding(x)\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase \n","    \n","    def predict_image(self,image,pad=True):\n","        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n","        x = np.array(image)\n","        # x=np.stack([x[:,:,0],x[:,:,1],x[:,:,2]], axis=-1)\n","        if pad:\n","            x=padding(x)\n","        imagen=x.copy()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase, imagen\n","    \n","def padding(img):\n","    \"\"\"Escala la imagen y completa el sobrante con franjas negras, para no perder proporciones\"\"\"                \n","    old_image_height, old_image_width, channels = img.shape\n","    new_image_width = 224\n","    new_image_height = 224\n","    color = (0,0,0)\n","    if old_image_height<=old_image_width:\n","        f=new_image_width/old_image_width\n","    else:\n","        f=new_image_height/old_image_height\n","    img=cv2.resize(img,(int(f*old_image_width),int(f*old_image_height)))\n","    old_image_height, old_image_width, channels = img.shape\n","    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n","    x_center = (new_image_width - old_image_width) // 2\n","    y_center = (new_image_height - old_image_height) // 2\n","    try:\n","        result[y_center:y_center+old_image_height, \n","            x_center:x_center+old_image_width] = img\n","    except:\n","        result=img \n","    return result        \n","class mobilenet_class():\n","    def __init__(self,alexnet,weights,num_classes,idx_to_class):\n","        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n","        # alexnet=models.alexnet(pretrained=True)\n","        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n","        \n","        checkpoint=torch.load(weights,map_location=self.device)\n","        # checkpoint=torch.load(weights)\n","        # \n","        alexnet.classifier[3] = nn.Linear(1024, num_classes)\n","        alexnet.classifier.add_module(\"4\", nn.LogSoftmax(dim = 1))\n","        # for param in alexnet.parameters():\n","        #     param.requires_grad = False\n","        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n","        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n","        alexnet.load_state_dict(checkpoint['model_state_dict'])\n","        summary(alexnet.to(self.device), (3, 224, 224))\n","        self.model=alexnet\n","        self.idx_to_class=idx_to_class\n","\n","    \n","    def predict_file(self,file,pad=True):\n","        \"\"\"Genera prediccion sobre archivo\"\"\"\n","        x = Image.open(file)\n","        x = np.asarray(x)\n","        # if pad:\n","        #     # resize\n","        #     x= x.resize()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        # Cambiar normalizacion\n","        x=x/255*2-1\n","\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase \n","    \n","    def predict_image(self,image,pad=True):\n","        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n","        x = np.asarray(image)\n","        # if pad:\n","        #     x=padding(x)\n","        imagen=x.copy()\n","        x=cv2.resize(x,(224,224))\n","        x=x.astype(\"float32\")\n","        # Cambiar normalizacion\n","        x=x/255*2-1\n","        x=np.moveaxis(x,-1,0)\n","        x = np.expand_dims(x, axis=0)\n","        with torch.no_grad():\n","            img = torch.from_numpy(x).to(self.device)\n","            res=list(self.model(img).cpu().detach().numpy()[0])\n","            indice=res.index(max(res))\n","            clase=self.idx_to_class.get(indice)\n","        return clase, imagen "]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1682721469663,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"H03QvtpAACKB"},"outputs":[],"source":["def matchingTemplate(img_rgb,template,threshold = .7):\n","    '''\n","(Function)\n","(Parameters)\n","    - threshold: Porcentaje de coincidencia \n","    '''\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n","    w, h = template.shape[::-1]\n","    res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n","    loc = np.where( res >=threshold)\n","    startpoints=[]\n","    endpoints=[]\n","    thresh=[]\n","    x=-10\n","    y=-10\n","    for i,pt in enumerate(zip(*loc[::-1])):\n","        if i==0:\n","            x=pt[0]\n","            y=pt[1]\n","            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","            cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","            startpoints.append(pt)\n","            endpoints.append((pt[0] + w, pt[1] + h))\n","            val=np.array(loc)[:,i]\n","            thresh.append(res[val[0],val[1]])\n","        if (pt[0]!=x and pt[0]+1!=x and pt[0]-1!=x and pt[0]+2!=x and pt[0]-2!=x) and (pt[1]!=y and pt[1]+1!=y and pt[1]-1!=y and pt[1]+2!=y and pt[1]-2!=y):\n","            x=pt[0]\n","            y=pt[1]\n","            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","            cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","            startpoints.append(pt)\n","            endpoints.append((pt[0] + w, pt[1] + h))\n","            val=np.array(loc)[:,i]\n","            thresh.append(res[val[0],val[1]])\n","    return img_rgb,startpoints,endpoints,thresh"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":778,"status":"ok","timestamp":1682721491409,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"2R-tQRcWACKC","outputId":"573597e0-71c6-49a8-e9ca-38d3425d81b0"},"outputs":[{"data":{"text/plain":["(11,\n"," 21,\n"," 2001,\n"," CRS.from_wkt('LOCAL_CS[\"WGS 84 / Pseudo-Mercator\",UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]'),\n"," 23708,\n"," 43215,\n"," -11098076.2292,\n"," -11093754.7532,\n"," 2135322.7351,\n"," 2137693.5448)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["raster=r\"C:\\Users\\ruben\\Downloads\\Ixtapan_centro_chinchetas.tif\"\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=200)\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["shape_o=gpd.read_file(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Full manzanas\\Manzana_Ixtapan_Sal.shp\")\n","shape_o=shape_o.to_crs('3857')\n","shape=shape_transform(shape_o.copy())\n","#shape_aumentado=ampliar_shape(shape_o.copy())"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682721497648,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"8cLkCch2ACKC"},"outputs":[],"source":["def rotacion_detect(startpoint,endpoint,angle,proyecciones,w,h,dim):\n","    \"\"\"Rotata el cuadro detectado en el sistema de coordenadas inicial\"\"\"\n","    point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","    min_y,min_x=point1[0],point1[1]\n","    point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","    max_y,max_x=point2[0],point2[1]\n","    min_y,min_x,max_y,max_x,proyecciones\n","    tipos=[\"casa\",\"terreno\"]\n","    y1,x1=startpoint\n","    y2,x2=endpoint\n","    x1,y1=(x1)*2-1,(y1)*2-1\n","    x2,y2=(x2)*2-1,(y2)*2-1\n","    angle=angle*math.pi/180\n","#     x1,y1=x1*(w/dim),y1*(h/dim)\n","#     x2,y2=x2*(w/dim),y2*(h/dim)\n","    #x_p, y_p son los puntos de un rectangulo en el orden inverso al manecillas del reloj\n","    x1p=max_x-((x1*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y1p=min_y+((x1*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x2p=max_x-((x2*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y2p=min_y+((x2*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x3p=max_x-((x2*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y3p=min_y+((x2*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x4p=max_x-((x1*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y4p=min_y+((x1*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    return Polygon(((y1p,x1p),(y2p,x2p),(y3p,x3p),(y4p,x4p),(y1p,x1p)))"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1682723303673,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"XLRnfwGRHvR4"},"outputs":[{"name":"stdout","output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n","|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n","|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n","|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n","|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n","|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n","|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n","|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n","|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n","|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n","|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n","|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n","|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n","|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n","├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n","├─Sequential: 1-3                        [-1, 29]                  --\n","|    └─Dropout: 2-14                     [-1, 9216]                --\n","|    └─Linear: 2-15                      [-1, 4096]                37,752,832\n","|    └─ReLU: 2-16                        [-1, 4096]                --\n","|    └─Dropout: 2-17                     [-1, 4096]                --\n","|    └─Linear: 2-18                      [-1, 4096]                16,781,312\n","|    └─ReLU: 2-19                        [-1, 4096]                --\n","|    └─Linear: 2-20                      [-1, 29]                  118,813\n","|    └─LogSoftmax: 2-21                  [-1, 29]                  --\n","==========================================================================================\n","Total params: 57,122,653\n","Trainable params: 57,122,653\n","Non-trainable params: 0\n","Total mult-adds (M): 767.32\n","==========================================================================================\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 3.76\n","Params size (MB): 217.91\n","Estimated Total Size (MB): 222.24\n","==========================================================================================\n"]}],"source":["diccionario = {0: 'Hospital', 1: 'Jardin', 2: 'a_verdes', 3: 'a_verdes_1', 4: 'a_verdes_2', 5: 'bancos_google', 6: 'bar',\n","               7: 'cine', 8: 'correo', 9: 'cultural_3', 10: 'dinero', 11: 'educativo', 12: 'entretenimiento_google', \n","               13: 'establecimientos_2_google', 14: 'establecimientos_google', 15: 'gas_google', 16: 'gobierno_google', \n","               17: 'golf', 18: 'hospedaje_google', 19: 'juegos_google', 20: 'playa_google', 21: 'poli', 22: 'restaurante_google',\n","               23: 'salud_google', 24: 'sitios_interes_google', 25: 'templo_google', 26: 'tiendas_1', 27: 'tiendas_2', 28: 'turista_google'}\n","weights = r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Alexnet\\Modelos\\best_mod1_pines.pth\"\n","# modelo = models.mobilenet_v3_small(weights='DEFAULT')\n","mobilenet = alexnet(weights,len(diccionario),diccionario)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from clasificacion_chinchetas import *\n","path_plantilla = '/home/hector/Documentos/Infis/Geo/Data/Plantillas'\n","path_plantilla_ruben = r\"C:\\Users\\ruben\\Downloads\\Plantillas-20230512T162122Z-001\\Plantillas\"\n","dict_gris = get_dict_plantilla_gris(path_plantilla)\n","#detectar_clase(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Alexnet\\nuevo.png\",dict_gris,True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dict_gris['turista_google']"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"NfpH8WegACKC"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 90/924 [01:06<10:15,  1.36it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[49], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m shapes\u001b[39m=\u001b[39m[{\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mPolygon\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcoordinates\u001b[39m\u001b[39m'\u001b[39m:[cuadro]}]\n\u001b[0;32m     32\u001b[0m vector\u001b[39m=\u001b[39m[]\n\u001b[1;32m---> 33\u001b[0m array, out_transform \u001b[39m=\u001b[39m rasterio\u001b[39m.\u001b[39;49mmask\u001b[39m.\u001b[39;49mmask(src, shapes, crop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(array)\u001b[39m<\u001b[39m\u001b[39m100\u001b[39m:\n\u001b[0;32m     35\u001b[0m     pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\ruben\\anaconda3\\envs\\venv\\lib\\site-packages\\rasterio\\mask.py:178\u001b[0m, in \u001b[0;36mmask\u001b[1;34m(dataset, shapes, all_touched, invert, nodata, filled, crop, pad, pad_width, indexes)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m         nodata \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 178\u001b[0m shape_mask, transform, window \u001b[39m=\u001b[39m raster_geometry_mask(\n\u001b[0;32m    179\u001b[0m     dataset, shapes, all_touched\u001b[39m=\u001b[39;49mall_touched, invert\u001b[39m=\u001b[39;49minvert, crop\u001b[39m=\u001b[39;49mcrop,\n\u001b[0;32m    180\u001b[0m     pad\u001b[39m=\u001b[39;49mpad, pad_width\u001b[39m=\u001b[39;49mpad_width)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m indexes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     out_shape \u001b[39m=\u001b[39m (dataset\u001b[39m.\u001b[39mcount, ) \u001b[39m+\u001b[39m shape_mask\u001b[39m.\u001b[39mshape\n","File \u001b[1;32mc:\\Users\\ruben\\anaconda3\\envs\\venv\\lib\\site-packages\\rasterio\\mask.py:104\u001b[0m, in \u001b[0;36mraster_geometry_mask\u001b[1;34m(dataset, shapes, all_touched, invert, crop, pad, pad_width)\u001b[0m\n\u001b[0;32m    101\u001b[0m     transform \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtransform\n\u001b[0;32m    102\u001b[0m     out_shape \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(dataset\u001b[39m.\u001b[39mheight), \u001b[39mint\u001b[39m(dataset\u001b[39m.\u001b[39mwidth))\n\u001b[1;32m--> 104\u001b[0m mask \u001b[39m=\u001b[39m geometry_mask(shapes, transform\u001b[39m=\u001b[39;49mtransform, invert\u001b[39m=\u001b[39;49minvert,\n\u001b[0;32m    105\u001b[0m                      out_shape\u001b[39m=\u001b[39;49mout_shape, all_touched\u001b[39m=\u001b[39;49mall_touched)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m mask, transform, window\n","File \u001b[1;32mc:\\Users\\ruben\\anaconda3\\envs\\venv\\lib\\site-packages\\rasterio\\env.py:398\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m local\u001b[39m.\u001b[39m_env:\n\u001b[1;32m--> 398\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    399\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m         \u001b[39mwith\u001b[39;00m Env\u001b[39m.\u001b[39mfrom_defaults():\n","File \u001b[1;32mc:\\Users\\ruben\\anaconda3\\envs\\venv\\lib\\site-packages\\rasterio\\features.py:71\u001b[0m, in \u001b[0;36mgeometry_mask\u001b[1;34m(geometries, out_shape, transform, all_touched, invert)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a mask from shapes.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39mBy default, mask is intended for use as a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m fill, mask_value \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m invert \u001b[39melse\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m \u001b[39mreturn\u001b[39;00m rasterize(\n\u001b[0;32m     72\u001b[0m     geometries,\n\u001b[0;32m     73\u001b[0m     out_shape\u001b[39m=\u001b[39;49mout_shape,\n\u001b[0;32m     74\u001b[0m     transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m     75\u001b[0m     all_touched\u001b[39m=\u001b[39;49mall_touched,\n\u001b[0;32m     76\u001b[0m     fill\u001b[39m=\u001b[39;49mfill,\n\u001b[0;32m     77\u001b[0m     default_value\u001b[39m=\u001b[39;49mmask_value)\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# from google.colab.patches import cv2_imshow\n","\n","chincheta=[]\n","clases=[]\n","show_imagen = False\n","# Plantilla de reconociemientt\n","template = cv2.imread(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Alexnet\\nuevo.png\")\n","dict_gris = get_dict_plantilla_gris(r\"C:\\Users\\ruben\\Downloads\\Plantillas-20230512T162122Z-001\\Plantillas\")\n","template_gray=template[:,:,1]\n","with rasterio.open(raster) as src:\n","    with tqdm.tqdm(total=alto*ancho*4) as pbar:\n","        for j in range(ancho*2):#ancho\n","            for i in range(alto*2):#alto\n","                generar=0\n","                label=raster.replace('\\\\','/').split('/')[-1][:-4]+'_'\n","                nameimg=label.lower()+str(i)+'_'+str(j)\n","                cuadro=[]\n","                for k in range(2):\n","                    for l in range(2):\n","                        cuadro.append((minx+(maxx-minx)/ancho*(j/2+k),maxy-(maxy-miny)/alto*(i/2+l)))\n","                cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n","                for punto in cuadro:\n","                    x=float(punto[0])\n","                    y=float(punto[1])\n","                    mini_df=shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)]\n","                    if len(mini_df)>0:\n","                        generar=1\n","                        #cvees.append(mini_df[\"cve_cat\"].values)### traer todas las cve_catastrales del punto sobre el raster ...Pendiente\n","#                             print(cvees)\n","                if generar==1:\n","                    shapes=[{'type':'Polygon','coordinates':[cuadro]}]\n","                    vector=[]\n","                    array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","                    if np.sum(array)<100:\n","                        pbar.update(1)\n","                        continue\n","                    four_images=[array[2],array[1],array[0]]\n","                    imagen_n = np.stack(four_images, axis=-1)\n","                    image_o=imagen_n.copy()\n","                    try:                        \n","                        imagen_n,startpoints, endpoints, thresh=matchingTemplate(imagen_n,template_gray,nameimg,threshold = .7)\n","                    except:                        \n","                        pbar.update(1)\n","                        continue\n","                    \n","                    for s in range(len(startpoints)):\n","                        startpoint=startpoints[s]\n","                        endpoint=endpoints[s]\n","                        df_aux=image_o.copy()\n","                        x1,y1=startpoint\n","                        x2,y2=endpoint\n","                        df_aux=df_aux[y1:y2,x1:x2] \n","                        # clasificacion\n","\n","                        clase_aux  = detectar_clase(df_aux, dict_gris)\n","                        # Clusterizamos la imagen\n","                        res2, ret, label, center = clusterizar_color(df_aux)\n","                        # Revisamos para los casos mas confusos\n","                        if clase_aux == 'a_verdes':\n","                            if comparacion_color(center1=center,\n","                                                 center2=dict_gris[clase_aux]['centro_color']):\n","                                # Es la clase adecuada\n","                                clase_aux = clase_aux \n","                            else:\n","                                clase_aux = 'establecimientos_google'\n","                        elif clase_aux == 'establecimientos_google':\n","                            if comparacion_color(center1=center,\n","                                                 center2=dict_gris[clase_aux]['centro_color']):\n","                                # Es la clase adecuada\n","                                clase_aux = clase_aux \n","                            else:\n","                                clase_aux = 'a_verdes'\n","                            \n","                            \n","                            \n","                        clases.append(clase_aux)\n","                        # En caso de querer almacenar lo cuadritos, poner ruta\n","    #                     cv2.imwrite(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\pines/\"+str(j)+\"_\"+str(i)+\"_\"+str(s)+\"deteccion.png\",df_aux)\n","\n","                        startpoint=[x/dim for x in startpoint]\n","                        endpoint=[x/dim for x in endpoint]\n","                        proyecciones=cuadro\n","                        chincheta.append(rotacion_detect(startpoint,endpoint,0,proyecciones,dim,dim,dim))\n","                    if show_imagen:\n","                        cv2_imshow(imagen_n)\n","                        # cv2.waitKey()\n","                        # cv2.destroyAllWindows()\n","\n","                \n","                \n","                pbar.update(1)\n","                \n","                "]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1682724593925,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"3gcblWu8ACKD"},"outputs":[],"source":["gps=gpd.GeoDataFrame({'Clase':clases}, geometry=chincheta,crs=3857)\n","gps\n","# gps[\"centroidx\"]=gps.centroid.x/10\n","# gps[\"centroidy\"]=gps.centroid.y/10\n","# gps[\"centroidx\"]=gps[\"centroidx\"].astype(\"int\")\n","# gps[\"centroidy\"]=gps[\"centroidy\"].astype(\"int\")\n","# gps=gps.drop_duplicates([\"centroidx\",\"centroidy\"])\n","gps.to_file(r\"C:\\Users\\ruben\\Downloads\\Ixtapan_centro_chinchetas.shp\")"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["clases"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7PZ2z0SACKD"},"outputs":[],"source":["def cv2_imshow(name,image):\n","    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n","    cv2.imshow(name,image)\n","    cv2.waitKey()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2JsCCM8ACKD"},"outputs":[],"source":["import glob\n","filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\pines/*.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ummNwNCuACKE"},"outputs":[],"source":["import tqdm\n","file='C:\\\\Users\\\\ASUS\\\\Inteligencia_Artificial\\\\chinchetas\\\\0_28_1deteccion.png'\n","valor=[]\n","color=[]\n","for file in tqdm.tqdm(filenames):\n","    image2=cv2.imread(file)\n","    Z = image2.reshape((-1,3))\n","    # convert to np.float32\n","    Z = np.float32(Z)\n","    # define criteria, number of clusters(K) and apply kmeans()\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","    K = 1\n","    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n","    # Now convert back into uint8, and make original image\n","    center = np.uint8(center[0])\n","    color.append(\"\".join([str(int(np.ceil(x/255*10))).zfill(3) for x in center]))\n","    _,image=cv2.threshold(image2[:,:,1],200,255,cv2.THRESH_BINARY)\n","    # image=image[5:41,6:29]\n","    image=image/255\n","    images=pd.DataFrame(image)\n","    x1=0\n","    x2=100\n","    for col in images.columns:\n","        if images[col].sum()>=len(images)-5:\n","            if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","                x1=int(col)+1\n","            if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","                x2=int(col)\n","    y1,y2=(0,len(images))\n","    image1=image[y1:y2,x1:x2]\n","    images=pd.DataFrame(image1)\n","    y1=0\n","    y2=100\n","    for i in range(len(images)):\n","        if images.iloc[i].sum()>=len(images.columns)-5:\n","            if int(i)>=y1 and int(i)<=int(len(images)/2):\n","    #             print(y1)\n","                y1=int(i)+1\n","            if int(i)>=y1 and int(i)<=y2 and int(i)>=int(len(images)/2):\n","                y2=int(i)\n","    image1=image1[y1:y2,0:len(images.columns)]\n","#     images=pd.DataFrame(image1)\n","#     x1=0\n","#     x2=100\n","#     for col in images.columns:\n","#         if images[col].sum()==len(images):\n","#             if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","#                 x1=int(col)+1\n","#             if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","#                 x2=int(col)\n","#     y1,y2=(0,len(images))\n","#     image1=image1[y1:y2,x1:x2]\n","#     cv2_imshow(\"a\",image1)\n","    valor.append(np.sum(image1))\n","res=pd.DataFrame({\"file\":filenames,\"valor\":valor,\"color\":color})\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8xNlZPGACKE"},"outputs":[],"source":["res[\"valor1\"]=[int(x/10) for x in res[\"valor\"]]\n","res[\"valor2\"]=[int(str(x).replace(\".\",\"\")) for x in res[\"color\"]]\n","Z = np.vstack((res[\"valor\"],res[\"valor2\"]))\n","# convert to np.float32\n","Z = np.float32(Z)\n","# define criteria and apply kmeans()\n","# criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","# ret,label,center=cv.kmeans(Z,2,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)\n","# res.groupby(\"valor2\").count()\n","import matplotlib.pyplot as plt\n","plt.scatter(res[\"valor1\"],res[\"valor2\"],cmap='viridis',marker=\"o\")\n","# A = Z[label.ravel()==0]\n","# B = Z[label.ravel()==1]\n","# # Plot the data\n","# plt.scatter(A[:,0],A[:,1])\n","# plt.scatter(B[:,0],B[:,1],c = 'r')\n","# plt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')\n","# plt.xlabel('Height'),plt.ylabel('Weight')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkRSuOO1ACKE"},"outputs":[],"source":["res[\"valor2\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PKzXCdFACKE"},"outputs":[],"source":["aux=res[res[\"valor2\"]==9009008].sort_values([\"valor1\",\"valor2\"]).reset_index(drop=True).head(100)\n","aux"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0VkOsEhACKF"},"outputs":[],"source":["for i in range(len(aux)):\n","    im=cv2.imread(aux[\"file\"][i])\n","    cv2_imshow(str(aux.loc[i,\"valor1\"])+\"_\"+str(aux.loc[i,\"valor2\"]),im)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-hptFtUIAeOz"},"outputs":[],"source":["#!pip install rasterio\n","#!pip install geopandas\n","\"\"\"\n","Created on Wed Mar 29 10:45:35 2023\n","@author: Alberto\n","\"\"\""]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import math\n","from shapely.geometry import Polygon\n","import cv2\n","from clasificacion_chinchetas import *\n","import tqdm\n","import numpy as np\n","from osgeo import gdal\n","import rasterio\n","import geopandas as gpd\n","import rasterio.mask\n","import sys\n","from shapely.geometry import mapping\n","from shapely import geometry\n","import cv2\n","import numpy as np\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1682721469663,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"H03QvtpAACKB"},"outputs":[],"source":["def matchingTemplate(img_rgb,template,threshold = .7):\n","    '''\n","(Function)\n","(Parameters)\n","    - threshold: Porcentaje de coincidencia \n","    '''\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n","    w, h = template.shape[::-1]\n","    res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n","    loc = np.where( res >=threshold)\n","    startpoints=[]\n","    endpoints=[]\n","    thresh=[]\n","    x=-10\n","    y=-10\n","    for i,pt in enumerate(zip(*loc[::-1])):\n","        #if i==0:\n","        x=pt[0]\n","        y=pt[1]\n","        cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","        cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","        startpoints.append(pt)\n","        endpoints.append((pt[0] + w, pt[1] + h))\n","        val=np.array(loc)[:,i]\n","        thresh.append(res[val[0],val[1]])\n","        if (pt[0]!=x and pt[0]+1!=x and pt[0]-1!=x and pt[0]+2!=x and pt[0]-2!=x) and (pt[1]!=y and pt[1]+1!=y and pt[1]-1!=y and pt[1]+2!=y and pt[1]-2!=y):\n","            x=pt[0]\n","            y=pt[1]\n","            cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","            cv2.putText(img_rgb,str(i) ,(x,y) , cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n","            startpoints.append(pt)\n","            endpoints.append((pt[0] + w, pt[1] + h))\n","            val=np.array(loc)[:,i]\n","            thresh.append(res[val[0],val[1]])\n","    return img_rgb,startpoints,endpoints,thresh\n","\n","def Parametro_raster(raster,metros=120):\n","    \"\"\"Se obtienen las dimensiones del raster y del cuadro de corte\"\"\"\n","    gdal_interpeter = gdal.Open(raster)\n","    width = gdal_interpeter.RasterXSize\n","    height = gdal_interpeter.RasterYSize\n","    coordenadas_gdal = gdal_interpeter.GetGeoTransform()\n","    minx = coordenadas_gdal[0]\n","    miny = coordenadas_gdal[3] + width*coordenadas_gdal[4] + height*coordenadas_gdal[5] \n","    maxx = coordenadas_gdal[0] + width*coordenadas_gdal[1] + height*coordenadas_gdal[2]\n","    maxy = coordenadas_gdal[3]\n","    src_raster_path = raster\n","    src=rasterio.open(src_raster_path)\n","    H,W=src.shape\n","    dim=int(np.ceil(map_d(minx+metros,minx,maxx,0,W)))\n","    alto=np.max([1,int(np.floor(H/dim))])\n","    ancho=np.max([1,int(np.floor(W/dim))])\n","    return alto,ancho,dim,src.crs,H,W,minx,maxx,miny,maxy\n","\n","def map_d(x, in_min, in_max, out_min, out_max):\n","    \"\"\"Genera una interpolacion para pasar de un rango a otro\"\"\"\n","    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n","\n","def shape_transform(shape):\n","    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n","    c=[]\n","    angulo_manzana=[]\n","\n","    # for manzana in range(len(shape)):\n","    #     proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","    #     angulos=[]\n","    #     d=[]\n","    #     poly=pd.DataFrame(proyecciones1[0])\n","    #     for point in range(1,len(poly)):\n","    #         d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n","    #         angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n","    #     angulo_manzana.append(angulos[d.index(max(d))])\n","    shape[\"angulo_manzana\"]=0\n","    shape[\"geometry\"]=shape[\"geometry\"].envelope\n","    for manzana in range(len(shape)):\n","        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n","        proyecciones=proyecciones1[0]\n","        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","        min_y,min_x=point1[0],point1[1]\n","        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","        max_y,max_x=point2[0],point2[1]\n","        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n","    shape1=pd.DataFrame()\n","    shape1['points']=c\n","    shape1=shape1['points'].str.split(',',expand=True)\n","    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n","    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n","    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n","    shape=shape1\n","    return shape\n","\n","def rotacion_detect(startpoint,endpoint,angle,proyecciones,w,h,dim):\n","    \"\"\"Rotata el cuadro detectado en el sistema de coordenadas inicial\"\"\"\n","    point1=np.min((proyecciones,proyecciones),axis=1)[0]\n","    min_y,min_x=point1[0],point1[1]\n","    point2=np.max((proyecciones,proyecciones),axis=1)[0]\n","    max_y,max_x=point2[0],point2[1]\n","    min_y,min_x,max_y,max_x,proyecciones\n","    tipos=[\"casa\",\"terreno\"]\n","    y1,x1=startpoint\n","    y2,x2=endpoint\n","    x1,y1=(x1)*2-1,(y1)*2-1\n","    x2,y2=(x2)*2-1,(y2)*2-1\n","    angle=angle*math.pi/180\n","#     x1,y1=x1*(w/dim),y1*(h/dim)\n","#     x2,y2=x2*(w/dim),y2*(h/dim)\n","    #x_p, y_p son los puntos de un rectangulo en el orden inverso al manecillas del reloj\n","    x1p=max_x-((x1*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y1p=min_y+((x1*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x2p=max_x-((x2*math.cos(angle)-y1*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y2p=min_y+((x2*math.sin(angle)+y1*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x3p=max_x-((x2*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y3p=min_y+((x2*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    x4p=max_x-((x1*math.cos(angle)-y2*math.sin(angle)+1)/2)*(max_x-min_x)\n","    y4p=min_y+((x1*math.sin(angle)+y2*math.cos(angle)+1)/2)*(max_y-min_y)\n","    return Polygon(((y1p,x1p),(y2p,x2p),(y3p,x3p),(y4p,x4p),(y1p,x1p)))\n","\n","def cv2_imshow(image):\n","    cv2.namedWindow('name', cv2.WINDOW_NORMAL)\n","    cv2.imshow('name',image)\n","    cv2.waitKey()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":778,"status":"ok","timestamp":1682721491409,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"2R-tQRcWACKC","outputId":"573597e0-71c6-49a8-e9ca-38d3425d81b0"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR 1: PROJ: internal_proj_identify: /home/hector/anaconda3/envs/Infis/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n"]},{"data":{"text/plain":["(23,\n"," 43,\n"," 286,\n"," CRS.from_wkt('LOCAL_CS[\"WGS 84 / Pseudo-Mercator\",UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]'),\n"," 6774,\n"," 12347,\n"," -11098076.2292,\n"," -11093754.7532,\n"," 2135322.7351,\n"," 2137693.5448)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["raster=r\"/home/hector/Descargas/temporal/Chinchetas_Ixtapan_centro.tif\"\n","metros = 100\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=metros)\n","alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["6*dim/100"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# No borrar paths de compañeros\n","\n","path_hector_nuevo = '/home/hector/Documentos/Infis/Geo/Data/nuevo.png'\n","\n","template = cv2.imread(path_hector_nuevo)\n","template.shape\n","factor = ((6*dim/metros)/21)\n","temp = cv2.resize(template,(int((factor)*template.shape[1]),int((factor)*template.shape[0])))\n","# pd.DataFrame(temp[:,:,0]).to_clipboard()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv2_imshow(template)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["factor"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# No borrar paths de compañeros\n","\n","path_hector = '/home/hector/Documentos/Infis/Geo/Data/Shapes/Ixtapan_de_la_sal/Manzana_Ixtapan_Sal.shp'\n","\n","shape_o=gpd.read_file(path_hector)\n","shape_o=shape_o.to_crs('3857')\n","shape=shape_transform(shape_o.copy())\n","#shape_aumentado=ampliar_shape(shape_o.copy())"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# No borrar path compañeros\n","\n","path_hector = '/home/hector/Documentos/Infis/Geo/Data/Plantillas'\n","dict_gris = get_dict_plantilla_gris(path_hector,True,(30,30))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"NfpH8WegACKC"},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 48/3956 [00:00<01:05, 60.00it/s]"]},{"name":"stdout","output_type":"stream","text":["educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    70    0.8599999999999999\n","educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 51/3956 [00:19<01:05, 60.00it/s]"]},{"name":"stdout","output_type":"stream","text":["educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    70    0.8599999999999999\n","educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 96/3956 [00:26<10:18,  6.25it/s]  "]},{"name":"stdout","output_type":"stream","text":["educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 96/3956 [00:40<10:18,  6.25it/s]"]},{"name":"stdout","output_type":"stream","text":["educativo    60    0.8799999999999999\n","educativo    70    0.8599999999999999\n","educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 97/3956 [00:48<1:14:39,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n","educativo    70    0.8599999999999999\n","educativo    70    0.8599999999999999\n","educativo    60    0.8799999999999999\n","educativo    60    0.8799999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 177/3956 [00:53<02:31, 24.96it/s] "]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 181/3956 [01:10<02:31, 24.96it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 222/3956 [02:54<46:16,  1.34it/s]  "]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 402/3956 [03:08<00:46, 77.26it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 408/3956 [03:20<00:45, 77.26it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█▏        | 447/3956 [03:31<07:08,  8.19it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█▏        | 454/3956 [03:50<07:07,  8.19it/s]"]},{"name":"stdout","output_type":"stream","text":["tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 455/3956 [04:00<1:12:00,  1.23s/it]"]},{"name":"stdout","output_type":"stream","text":["tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 500/3956 [04:37<16:23,  3.52it/s]  "]},{"name":"stdout","output_type":"stream","text":["tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 501/3956 [04:50<16:22,  3.52it/s]"]},{"name":"stdout","output_type":"stream","text":["tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n","tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 502/3956 [04:51<57:57,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["tiendas_2    60    0.8399999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 514/3956 [04:52<28:02,  2.05it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 871/3956 [05:03<00:43, 71.52it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 874/3956 [05:20<00:43, 71.52it/s]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 898/3956 [05:40<22:04,  2.31it/s]  "]},{"name":"stdout","output_type":"stream","text":["poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.9199999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 904/3956 [05:58<1:02:17,  1.22s/it]"]},{"name":"stdout","output_type":"stream","text":["poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.9199999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n","poli    50    0.8999999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 905/3956 [06:03<1:13:04,  1.44s/it]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 909/3956 [06:20<1:12:58,  1.44s/it]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 910/3956 [06:22<1:52:35,  2.22s/it]"]},{"name":"stdout","output_type":"stream","text":["establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n","establecimiento_google    60    0.9199999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 916/3956 [06:26<1:15:11,  1.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Jardin    50    0.8599999999999999\n","Jardin    60    0.8399999999999999\n","Jardin    50    0.8599999999999999\n","Jardin    50    0.8599999999999999\n","Jardin    60    0.8399999999999999\n","Jardin    60    0.8399999999999999\n","Jardin    50    0.8599999999999999\n","Jardin    60    0.8399999999999999\n","Jardin    50    0.8599999999999999\n","Jardin    60    0.8399999999999999\n","Jardin    50    0.8599999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 918/3956 [06:40<1:15:08,  1.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Jardin    50    0.8599999999999999\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 918/3956 [06:50<22:39,  2.23it/s]  \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[39mif\u001b[39;00m show_imagen:\n\u001b[1;32m     73\u001b[0m             cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m,df_aux)\n\u001b[0;32m---> 74\u001b[0m             cv2\u001b[39m.\u001b[39;49mwaitKey()\n\u001b[1;32m     75\u001b[0m             cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     79\u001b[0m pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# from google.colab.patches import cv2_imshow\n","\n","chincheta=[]\n","clases=[]\n","threshold=[]\n","show_imagen = True\n","save_detection = False\n","show_clasification = True\n","path_save = '/'\n","template = temp\n","\n","template_gray=template[:,:,1]\n","with rasterio.open(raster) as src:\n","    with tqdm.tqdm(total=alto*ancho*4) as pbar:\n","        for j in range(ancho*2):#ancho\n","            for i in range(alto*2):#alto\n","                generar=0\n","                label=raster.replace('\\\\','/').split('/')[-1][:-4]+'_'\n","                nameimg=label.lower()+str(i)+'_'+str(j)\n","                cuadro=[]\n","                for k in range(2):\n","                    for l in range(2):\n","                        cuadro.append((minx+(maxx-minx)/ancho*(j/2+k),maxy-(maxy-miny)/alto*(i/2+l)))\n","                cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n","                for punto in cuadro:\n","                    x=float(punto[0])\n","                    y=float(punto[1])\n","                    mini_df=shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)]\n","                    if len(mini_df)>0:\n","                        generar=1\n","                        #cvees.append(mini_df[\"cve_cat\"].values)### traer todas las cve_catastrales del punto sobre el raster ...Pendiente\n","#                             print(cvees)\n","                if generar==1:                    \n","                    shapes=[{'type':'Polygon','coordinates':[cuadro]}]\n","                    vector=[]\n","                    array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","                    if np.sum(array)<100:                        \n","                        pbar.update(1)\n","                        continue\n","                    four_images=[array[2],array[1],array[0]]\n","                    imagen_n = np.stack(four_images, axis=-1)\n","                    image_o=imagen_n.copy()\n","                    try:                                               \n","                        imagen_n,startpoints, endpoints, thresh=matchingTemplate(imagen_n,template_gray,threshold = .7)                        \n","                    except Exception as e:\n","                        # print(e)                                              \n","                        pbar.update(1)\n","                        continue\n","                    \n","                    for s in range(len(startpoints)):\n","                        startpoint=startpoints[s]                        \n","                        endpoint=endpoints[s]\n","                        df_aux=image_o.copy()\n","                        x1,y1=startpoint\n","                        x2,y2=endpoint\n","                        df_aux=df_aux[y1:y2,x1:x2] \n","                        # clasificacion\n","\n","                        clase_aux, n_aux, umbral_aux  = iter_umbral_fn(df_aux, dict_gris,n=100,salto_n=10,\n","                                                                       umbral=0.94,min_umbral=0.6)\n","                        if show_clasification:\n","                            print(clase_aux,'  ', n_aux, '  ', umbral_aux)\n","                        clases.append(clase_aux)\n","                        threshold.append(thresh[s])\n","                        # En caso de querer almacenar lo cuadritos, poner ruta\n","                        if save_detection:\n","                            cv2.imwrite(path_save +\"/\"+clase_aux+'_'+str(j)+\"_\"+str(i)+\"_\"+str(s)+\"deteccion.png\",df_aux)\n","\n","                        startpoint=[x/dim for x in startpoint]\n","                        endpoint=[x/dim for x in endpoint]\n","                        proyecciones=cuadro\n","                        chincheta.append(rotacion_detect(startpoint,endpoint,0,proyecciones,dim,dim,dim))\n","                        if show_imagen:\n","                            cv2.imshow('1',df_aux)\n","                            cv2.waitKey()\n","                            cv2.destroyAllWindows()\n","\n","                \n","                \n","                pbar.update(1)\n","                \n","                "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv2_imshow(df_aux)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1682724593925,"user":{"displayName":"Hector Limon","userId":"10624560036830165267"},"user_tz":360},"id":"3gcblWu8ACKD"},"outputs":[],"source":["gps=gpd.GeoDataFrame({'Clase':clases,'Threshold':threshold}, geometry=chincheta,crs=3857)\n","# gps[\"centroidx\"]=gps.centroid.x/10\n","# gps[\"centroidy\"]=gps.centroid.y/10\n","# gps[\"centroidx\"]=gps[\"centroidx\"].astype(\"int\")\n","# gps[\"centroidy\"]=gps[\"centroidy\"].astype(\"int\")\n","# gps=gps.drop_duplicates([\"centroidx\",\"centroidy\"])\n","gps.to_file(r\"C:\\Users\\ruben\\Downloads\\Ixtapan_centro_chinchetas.shp\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(chincheta), len(clases), len(threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2JsCCM8ACKD"},"outputs":[],"source":["import glob\n","filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\pines/*.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ummNwNCuACKE"},"outputs":[],"source":["import tqdm\n","file='C:\\\\Users\\\\ASUS\\\\Inteligencia_Artificial\\\\chinchetas\\\\0_28_1deteccion.png'\n","valor=[]\n","color=[]\n","for file in tqdm.tqdm(filenames):\n","    image2=cv2.imread(file)\n","    Z = image2.reshape((-1,3))\n","    # convert to np.float32\n","    Z = np.float32(Z)\n","    # define criteria, number of clusters(K) and apply kmeans()\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","    K = 1\n","    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n","    # Now convert back into uint8, and make original image\n","    center = np.uint8(center[0])\n","    color.append(\"\".join([str(int(np.ceil(x/255*10))).zfill(3) for x in center]))\n","    _,image=cv2.threshold(image2[:,:,1],200,255,cv2.THRESH_BINARY)\n","    # image=image[5:41,6:29]\n","    image=image/255\n","    images=pd.DataFrame(image)\n","    x1=0\n","    x2=100\n","    for col in images.columns:\n","        if images[col].sum()>=len(images)-5:\n","            if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","                x1=int(col)+1\n","            if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","                x2=int(col)\n","    y1,y2=(0,len(images))\n","    image1=image[y1:y2,x1:x2]\n","    images=pd.DataFrame(image1)\n","    y1=0\n","    y2=100\n","    for i in range(len(images)):\n","        if images.iloc[i].sum()>=len(images.columns)-5:\n","            if int(i)>=y1 and int(i)<=int(len(images)/2):\n","    #             print(y1)\n","                y1=int(i)+1\n","            if int(i)>=y1 and int(i)<=y2 and int(i)>=int(len(images)/2):\n","                y2=int(i)\n","    image1=image1[y1:y2,0:len(images.columns)]\n","#     images=pd.DataFrame(image1)\n","#     x1=0\n","#     x2=100\n","#     for col in images.columns:\n","#         if images[col].sum()==len(images):\n","#             if int(col)>=x1 and int(col)<=int(len(images.columns)/2):\n","#                 x1=int(col)+1\n","#             if int(col)>=x1 and int(col)<=x2 and int(col)>=int(len(images.columns)/2):\n","#                 x2=int(col)\n","#     y1,y2=(0,len(images))\n","#     image1=image1[y1:y2,x1:x2]\n","#     cv2_imshow(\"a\",image1)\n","    valor.append(np.sum(image1))\n","res=pd.DataFrame({\"file\":filenames,\"valor\":valor,\"color\":color})\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8xNlZPGACKE"},"outputs":[],"source":["res[\"valor1\"]=[int(x/10) for x in res[\"valor\"]]\n","res[\"valor2\"]=[int(str(x).replace(\".\",\"\")) for x in res[\"color\"]]\n","Z = np.vstack((res[\"valor\"],res[\"valor2\"]))\n","# convert to np.float32\n","Z = np.float32(Z)\n","# define criteria and apply kmeans()\n","# criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","# ret,label,center=cv.kmeans(Z,2,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)\n","# res.groupby(\"valor2\").count()\n","import matplotlib.pyplot as plt\n","plt.scatter(res[\"valor1\"],res[\"valor2\"],cmap='viridis',marker=\"o\")\n","# A = Z[label.ravel()==0]\n","# B = Z[label.ravel()==1]\n","# # Plot the data\n","# plt.scatter(A[:,0],A[:,1])\n","# plt.scatter(B[:,0],B[:,1],c = 'r')\n","# plt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')\n","# plt.xlabel('Height'),plt.ylabel('Weight')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkRSuOO1ACKE"},"outputs":[],"source":["res[\"valor2\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PKzXCdFACKE"},"outputs":[],"source":["aux=res[res[\"valor2\"]==9009008].sort_values([\"valor1\",\"valor2\"]).reset_index(drop=True).head(100)\n","aux"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0VkOsEhACKF"},"outputs":[],"source":["for i in range(len(aux)):\n","    im=cv2.imread(aux[\"file\"][i])\n","    cv2_imshow(str(aux.loc[i,\"valor1\"])+\"_\"+str(aux.loc[i,\"valor2\"]),im)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
>>>>>>> b710df93908a49c1af02508d2a35414c525d5d0d
