{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/anaconda3/envs/Infis/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_14799/398482322.py:5: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcodigos\u001b[39;00m \u001b[39mimport\u001b[39;00m Generar_txt\n\u001b[1;32m     12\u001b[0m \u001b[39m###path de yolo dentro de computadora\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# os.chdir(r'C:\\Users\\ruben\\yolov7')\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdetect_Alberto_v4\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m rotate \u001b[39mas\u001b[39;00m rotate_image\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshapely\u001b[39;00m \u001b[39mimport\u001b[39;00m geometry\n",
      "File \u001b[0;32m~/Documentos/Infis/Geo/geoloc2/Detecciondeterrenos/detect_Alberto_v4.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m attempt_load\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m LoadImages , letterbox\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneral\u001b[39;00m \u001b[39mimport\u001b[39;00m check_img_size, non_max_suppression, scale_coords, xyxy2xywh, set_logging\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "from rasterio.windows import Window\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "sys.path.append(r'/home/hector/Documentos/Infis/Geo/yolov7')\n",
    "from codigos import Generar_txt\n",
    "###path de yolo dentro de computadora\n",
    "# os.chdir(r'C:\\Users\\ruben\\yolov7')\n",
    "from detect_Alberto_v4 import *\n",
    "from scipy.ndimage import rotate as rotate_image\n",
    "from shapely import geometry\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "from clasificacion_chinchetas import *\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "from shapely import geometry\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de deteccion de objetos basado en yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelo=modelo(weights=r\"C:\\Users\\ruben\\yolov7\\Modelos\\best_Chinchetas_Alberto.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo clasificador basado en Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alexnet1():\n",
    "    def __init__(self,weights,num_classes,idx_to_class):\n",
    "        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n",
    "        alexnet=models.alexnet(pretrained=True)\n",
    "        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "        checkpoint=torch.load(weights,map_location=self.device)\n",
    "#         alexnet.features[1]= nn.Hardtanh()\n",
    "#         alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "#         alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        # alexnet\n",
    "        alexnet.features[1]= nn.Hardtanh()\n",
    "        alexnet.classifier[6] = nn.Linear(4096, 4096)\n",
    "        alexnet.classifier.add_module(\"7\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"8\", nn.Linear(4096, 4096))\n",
    "        alexnet.classifier.add_module(\"9\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"10\", nn.Linear(4096, 2048))\n",
    "        alexnet.classifier.add_module(\"11\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"12\", nn.Linear(2048, num_classes))\n",
    "        alexnet.classifier.add_module(\"13\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"14\",  nn.LogSoftmax(dim = 1))\n",
    "        # for param in alexnet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        alexnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "        summary(alexnet, (3, 224, 224))\n",
    "        self.model=alexnet\n",
    "        self.idx_to_class=idx_to_class\n",
    "    \n",
    "    def predict_file(self,file,pad=True):\n",
    "        \"\"\"Genera prediccion sobre archivo\"\"\"\n",
    "#         x = Image.open(file)\n",
    "#         x = np.asarray(x)\n",
    "#         x=np.stack([x[:,:,0],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=cv2.imread(file)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase \n",
    "    \n",
    "    def predict_image(self,image,pad=True):\n",
    "        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n",
    "#         x = np.asarray(image)\n",
    "#         x=np.stack([x[:,:,2],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=np.array(image)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        imagen=x.copy()\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase, imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint\\5clases\\best_modconstrucciones_2.pth\"\n",
    "num_classes=5\n",
    "diciconario={0: 'casas', 1: 'en_construccion', 2: 'establecimiento', 3: 'multivivienda', 4: 'terreno_baldio'}\n",
    "model_class=alexnet1(weights=weights,num_classes=num_classes,idx_to_class=diciconario)\n",
    "# num_classes=6\n",
    "# diciconario={0: 'carros', 1: 'casas', 2: 'en_construccion', 3: 'establecimiento', 4: 'multivivienda', 5: 'terreno_baldio'}\n",
    "# model_class=alexnet(weights=weights,num_classes=num_classes,idx_to_class=diciconario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test clasificador sobre archivo\n",
    "file=r\"D:\\alexnet\\train_pad\\en_construccion\\Copia de Huixqui_1.PNG\"\n",
    "print(model_class.predict_file(file,pad=True))\n",
    "##test clasificador sobre imagen precargada\n",
    "image=cv2.imread(file)\n",
    "print(model_class.predict_image(image,pad=True)[0])\n",
    "cv2_imshow(\"a\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch #or pytorch, works for the same shit and contains the same libraries that you need such as Numpy (as far as I know)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# y_true = []\n",
    "# y_predict =[]\n",
    "# import glob\n",
    "# filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\train_pad/*/*\")\n",
    "# for file in tqdm.tqdm(filenames):\n",
    "#     file=file.replace(\"\\\\\",\"/\")\n",
    "#     y_true.append(file.split(\"/\")[-2])\n",
    "#     y_predict.append(model_class.predict_file(file,pad=False))\n",
    "# labels=[]\n",
    "# for k,v in diciconario.items():\n",
    "#     labels.append(v)\n",
    "# labels\n",
    "# confusion_mat = confusion_matrix(y_true, y_predict,labels=labels)\n",
    "# conteos=pd.DataFrame(y_true,columns=[\"clases\"]).value_counts()\n",
    "# conteos=conteos.reset_index(drop=False)\n",
    "# matrix=[]\n",
    "# for i,label in enumerate(labels):\n",
    "#     matrix.append(confusion_mat[i]/conteos[conteos[\"clases\"]==label][0].values[0])\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(matrix)\n",
    "# matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros del raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 12,\n",
       " 94,\n",
       " CRS.from_epsg(3857),\n",
       " 1199,\n",
       " 1196,\n",
       " -11105766.042973932,\n",
       " -11104489.368700342,\n",
       " 2247276.633907954,\n",
       " 2248556.5105417613)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detect_Alberto_v4 import Parametro_raster\n",
    "raster=r\"C:\\Users\\dlara\\Downloads\\MODELO_3D_SANTIAGO_ESTE_falta_georeferenciado_modified.tif\"\n",
    "\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=100)\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimitacion por shape de municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_o=gpd.read_file(r'C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Full manzanas\\Manzana_Naucalpan.shp')\n",
    "shape_o = gpd.read_file(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape_o=shape_o.to_crs('3857')\n",
    "shape=shape_transform(shape_o.copy())\n",
    "#shape_aumentado=ampliar_shape(shape_o.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_transform(shape):\n",
    "    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n",
    "    c=[]\n",
    "    angulo_manzana=[]\n",
    "\n",
    "    # for manzana in range(len(shape)):\n",
    "    #     proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "    #     angulos=[]\n",
    "    #     d=[]\n",
    "    #     poly=pd.DataFrame(proyecciones1[0])\n",
    "    #     for point in range(1,len(poly)):\n",
    "    #         d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n",
    "    #         angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n",
    "    #     angulo_manzana.append(angulos[d.index(max(d))])\n",
    "    shape[\"angulo_manzana\"]=0\n",
    "    shape[\"geometry\"]=shape[\"geometry\"].envelope\n",
    "    for manzana in range(len(shape)):\n",
    "        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "        proyecciones=proyecciones1[0]\n",
    "        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "        min_y,min_x=point1[0],point1[1]\n",
    "        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "        max_y,max_x=point2[0],point2[1]\n",
    "        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n",
    "    shape1=pd.DataFrame()\n",
    "    shape1['points']=c\n",
    "    shape1=shape1['points'].str.split(',',expand=True)\n",
    "    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n",
    "    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n",
    "    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n",
    "    shape=shape1\n",
    "    return shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre raster(municipio) con salida en shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No borrar path compañeros\n",
    "\n",
    "path_ruben = r'C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Plantillas'\n",
    "path_hector = '/home/hector/Documentos/Infis/Geo/Data/Plantillas'\n",
    "dict_gris = get_dict_plantilla_gris(path_ruben,True,(30,30))\n",
    "\n",
    "\n",
    "nombres=[]\n",
    "imshow=False\n",
    "result=pd.DataFrame()\n",
    "casas=[]\n",
    "terreno=[]\n",
    "angulosget=[]\n",
    "conf_casas=[]\n",
    "conf_terreno=[]\n",
    "clase_casas=[]\n",
    "clase_terreno=[]\n",
    "clase_chinchetas=[]\n",
    "umbrales=[]\n",
    "sizes=[]\n",
    "s=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementar modelos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproceso(Modelo,'model_class',casas,conf_casas,\n",
    "            clase_casas,terreno,conf_terreno,clase_terreno,\n",
    "            clase_chinchetas, umbrales,sizes,\n",
    "            raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0.000001,\n",
    "            opt_conf_thres=0.2,imshow=False,imsave=False,path=\"C:/Users/ASUS/salida/imagen\",\n",
    "            clasificar_casas=False, clasificar_chinchetas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_casas=gpd.GeoDataFrame({\"clase_detectada\":clase_casas,\"conf\":conf_casas},geometry=casas,crs=3857)\n",
    "gdf_casas.set_crs=crs\n",
    "gdf_casas[\"area\"]=gdf_casas.area\n",
    "gdf_casas=gdf_casas.astype({\"conf\":\"float64\"})\n",
    "gdf_casas.to_file(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Salidas\\Chinchetas\\Chinchetas_Naucalpan_yolo.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_terreno=gpd.GeoDataFrame({\"clase_detectada\":clase_terreno,\"conf\":conf_terreno},geometry=terreno,crs=crs)\n",
    "gdf_terreno.set_crs=crs\n",
    "gdf_terreno[\"area\"]=gdf_terreno.area\n",
    "gdf_terreno=gdf_terreno.astype({\"conf\":\"float64\"})\n",
    "gdf_terreno.to_file(r\"C:/Users/ASUS/salida/shape/ortofoto_terrenos_nuevomodeloa22_mod4_5_80.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint=torch.load(r'C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint/best_mod11.pth',map_location=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterio.open(raster).meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ñ ##breakpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar imagenes mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = rasterio.open(raster)\n",
    "shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cuadro(alto,ancho,j,i):\n",
    "    cuadro=[]\n",
    "    for k in range(2):\n",
    "        for l in range(2):\n",
    "            cuadro.append((minx+(maxx-minx)/ancho*(j+k),\n",
    "                            maxy-(maxy-miny)/alto*(i+l)))\n",
    "    cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n",
    "    for punto in cuadro:\n",
    "        x=float(punto[0])\n",
    "        y=float(punto[1])\n",
    "    return(cuadro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "def normalizar_array(img):\n",
    "    \n",
    "    return (img-np.min(img))/(np.max(img)-np.min(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 100/144 [01:20<00:35,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path donde se guardan images\n",
    "import tqdm as tqdm\n",
    "from detect_Alberto_v4 import Parametro_raster\n",
    "import numpy as np\n",
    "\n",
    "path_mosaico_input=r\"E:\\ORTOFOTOS\\Mosaicos_input\"\n",
    "path_mosaico_output=r\"E:\\ORTOFOTOS\\Mosaicos_output\"\n",
    "raster=r\"E:\\ORTOFOTOS\\folder\\corte_ESTE_ATLACOMULCO_1_satellite.tif\"\n",
    "raster2=r\"E:\\ORTOFOTOS\\folder\\corte_ESTE_ATALCOMULCO_0.tif\"\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=100)\n",
    "# alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy\n",
    "src = rasterio.open(raster)\n",
    "print(src.crs)\n",
    "src.meta.update(nodata=-3000)\n",
    "generar_imagenes=int(input(\"Generar imagenes: 1 si, 0 no \"))\n",
    "if generar_imagenes==1:\n",
    "    generar_imagenes_sinrotar=int(input(\"Generar imagenes sin rotar: 1 si, 0 no \"))\n",
    "    generar_imagenes_rotadas=int(input(\"Generar imagenes rotadas: 1 si, 0 no \"))\n",
    "    with tqdm.tqdm(total=alto*ancho) as pbar:\n",
    "        for j in range(1,ancho-1):#ancho\n",
    "            for i in (range(1,alto-1)):#alto\n",
    "                generar=0\n",
    "                label=raster.replace(\"\\\\\",\"/\").split(\"/\")[-1][:-4]+\"_\"\n",
    "                nameimg=label.lower()+str(i)+\"_\"+str(j)\n",
    "                cuadro= create_cuadro(alto,ancho,j,i)\n",
    "                    # if len(shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)])>0:\n",
    "                    #     generar=1             \n",
    "                # if generar==1:\n",
    "                shapes=[{\"type\":'Polygon','coordinates':[cuadro]}]\n",
    "                array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "                four_images=[array[2],array[1],array[0]]\n",
    "                # bin_image= [array]\n",
    "                \n",
    "                imagen_n = np.stack(four_images, axis=-1)\n",
    "                # imagen_n = array[0]\n",
    "                if generar_imagenes_sinrotar==1:\n",
    "                    src2 = rasterio.open(raster2)\n",
    "                    # src2.meta.update(nodata=0)\n",
    "                    alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster2,metros=100)\n",
    "                    cuadro2= create_cuadro(alto,ancho,j,i)\n",
    "                    shapes2=[{\"type\":'Polygon','coordinates':[cuadro2]}]\n",
    "                    array2, out_transform2 = rasterio.mask.mask(src2, shapes2, crop=True)\n",
    "                    # four_images=[array2[2],array2[1],array2[0]]\n",
    "                    # array2_0=normalizar_array(array2[0])\n",
    "                    # array2_0=array2[0][array2[0]==0]\n",
    "                    # array2_1=normalizar_array(array2[0][array2[0]!=0])\n",
    "                    # array_f=np.stack([array2_0,array2_1], axis=0)\n",
    "                    img=array2[0]\n",
    "                    if np.sum(img)>10:\n",
    "                        mini=np.min(img[img!=0])\n",
    "                        img[img==0]=mini\n",
    "                        imagen_n2=normalizar_array(img)\n",
    "                        imagen_n2= np.array(imagen_n2*255, dtype='uint8')\n",
    "                        imagen_n2=np.stack([imagen_n2,imagen_n2,imagen_n2],axis=-1)\n",
    "                        # imagen_n2 = array2[0]array_f\n",
    "                        cv2.imwrite(path_mosaico_input+\"\\\\\"+nameimg+\".png\",imagen_n)\n",
    "                        \n",
    "                        cv2.imwrite(path_mosaico_output+\"\\\\\"+nameimg+\".png\",imagen_n2)\n",
    "                    else:\n",
    "                        continue\n",
    "                if generar_imagenes_rotadas==1:\n",
    "                    angulo_1,imagen_ro=correct_orientation(imagen_n,dim)\n",
    "                    cv2.imwrite(path_mosaico_salida+nameimg+\"_\"+str(angulo_1)+\".png\",imagen_ro)\n",
    "                clear_output(wait=True)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts=glob.glob(\"E:\\ORTOFOTOS\\Mosaicos_input\\*.png\")\n",
    "fotos=glob.glob(\"E:\\ORTOFOTOS\\Mosaicos_output\\*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:00<00:00, 189510.75it/s]\n"
     ]
    }
   ],
   "source": [
    "all_txt = []\n",
    "all_pngs = []\n",
    "for txt in tqdm.tqdm(txts):\n",
    "    name_txt = str(txt).replace(\"\\\\\",\"/\").split(\"/\")[-1].split('.')[0]\n",
    "    all_txt.append(name_txt)\n",
    "\n",
    "for foto in all_txt:\n",
    "    name_foto = str(foto).replace(\"\\\\\",\"/\").split(\"/\")[-1].split('.')[0]\n",
    "    all_pngs.append(name_foto)\n",
    "    if foto in all_pngs:\n",
    "        continue\n",
    "    else:\n",
    "        for s in all_pngs: \n",
    "            if (foto not in s):\n",
    "                print(s,'Borrar foto')\n",
    "                path= r'E:/ORTOFOTOS/Mosaicos_output/'+str(s)+'.png'\n",
    "                os.remove(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre imagen con salida txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codigos import split_images_directory\n",
    "\n",
    "# Path donde se guardan images\n",
    "path_mosaico_salida=r\"/content/drive/MyDrive/Equipo_Agua/Geo/Data/Prueba/Atlacomulco/Images/\"\n",
    "\n",
    "split_images_directory(alto,ancho,raster,minx,maxx,miny,maxy,shape,dim,path_mosaico_salida,correct_orientation,src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector=Modelo.detect(opt_source=path_mosaico_salida,opt_conf_thres=0.3)\n",
    "Generar_txt(vector,path_mosaico_salida+\"labels\")\n",
    "with open(path_mosaico_salida+\"labels/classes.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join([\"casa\",\"terreno_baldio\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
