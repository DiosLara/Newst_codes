{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "from rasterio.windows import Window\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "sys.path.append(r'E:/gitlab/geoloc2/Detecciondeterrenos')\n",
    "from codigos import Generar_txt\n",
    "###path de yolo dentro de computadora\n",
    "os.chdir(r'C:/Users/ASUS/Inteligencia_Artificial/yolov7')\n",
    "from detect_Alberto_v4 import *\n",
    "from scipy.ndimage import rotate as rotate_image\n",
    "from shapely import geometry\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de deteccion de objetos basado en yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8216/3639419434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mModelo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\Modelos\\best_Fer_11.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\gitlab\\geoloc2\\Detecciondeterrenos\\detect_Alberto_v4.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTracedModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_img_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Inteligencia_Artificial\\yolov7\\utils\\torch_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, device, img_size)\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mrand_example\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mtraced_script_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand_example\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;31m#traced_script_module = torch.jit.script(self.model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[0mtraced_script_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"traced_model.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m         return trace_module(\n\u001b[0m\u001b[0;32m    742\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[1;34m\"forward\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    981\u001b[0m                     )\n\u001b[0;32m    982\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m                     _check_trace(\n\u001b[0m\u001b[0;32m    984\u001b[0m                         \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36m_check_trace\u001b[1;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mall_ok\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mtraced_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_mod_and_filter_tensor_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraced_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m         \u001b[0mfn_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_mod_and_filter_tensor_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Python function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompare_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraced_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Python function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mrun_mod_and_filter_tensor_outputs\u001b[1;34m(mod, inputs, running_what)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrun_mod_and_filter_tensor_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_what\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_retval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_clone_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mouts\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Modelo=modelo(weights=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\Modelos\\best_Fer_11.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo clasificador basado en Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alexnet1():\n",
    "    def __init__(self,weights,num_classes,idx_to_class):\n",
    "        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n",
    "        alexnet=models.alexnet(pretrained=True)\n",
    "        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "        checkpoint=torch.load(weights,map_location=self.device)\n",
    "#         alexnet.features[1]= nn.Hardtanh()\n",
    "#         alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "#         alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        # alexnet\n",
    "        alexnet.features[1]= nn.Hardtanh()\n",
    "        alexnet.classifier[6] = nn.Linear(4096, 4096)\n",
    "        alexnet.classifier.add_module(\"7\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"8\", nn.Linear(4096, 4096))\n",
    "        alexnet.classifier.add_module(\"9\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"10\", nn.Linear(4096, 2048))\n",
    "        alexnet.classifier.add_module(\"11\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"12\", nn.Linear(2048, num_classes))\n",
    "        alexnet.classifier.add_module(\"13\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"14\",  nn.LogSoftmax(dim = 1))\n",
    "        # for param in alexnet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        alexnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "        summary(alexnet, (3, 224, 224))\n",
    "        self.model=alexnet\n",
    "        self.idx_to_class=idx_to_class\n",
    "    \n",
    "    def predict_file(self,file,pad=True):\n",
    "        \"\"\"Genera prediccion sobre archivo\"\"\"\n",
    "#         x = Image.open(file)\n",
    "#         x = np.asarray(x)\n",
    "#         x=np.stack([x[:,:,0],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=cv2.imread(file)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase \n",
    "    \n",
    "    def predict_image(self,image,pad=True):\n",
    "        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n",
    "#         x = np.asarray(image)\n",
    "#         x=np.stack([x[:,:,2],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=np.array(image)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        imagen=x.copy()\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase, imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n",
      "|    └─Hardtanh: 2-2                     [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 5]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 4096]                37,752,832\n",
      "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
      "|    └─Linear: 2-18                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
      "|    └─Linear: 2-20                      [-1, 4096]                16,781,312\n",
      "|    └─Softplus: 2-21                    [-1, 4096]                --\n",
      "|    └─Linear: 2-22                      [-1, 4096]                16,781,312\n",
      "|    └─Softplus: 2-23                    [-1, 4096]                --\n",
      "|    └─Linear: 2-24                      [-1, 2048]                8,390,656\n",
      "|    └─Softplus: 2-25                    [-1, 2048]                --\n",
      "|    └─Linear: 2-26                      [-1, 5]                   10,245\n",
      "|    └─Softplus: 2-27                    [-1, 5]                   --\n",
      "|    └─LogSoftmax: 2-28                  [-1, 5]                   --\n",
      "==========================================================================================\n",
      "Total params: 98,967,365\n",
      "Trainable params: 98,967,365\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 850.99\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.84\n",
      "Params size (MB): 377.53\n",
      "Estimated Total Size (MB): 381.95\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "weights=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint\\5clases\\best_modconstrucciones_2.pth\"\n",
    "num_classes=5\n",
    "diciconario={0: 'casas', 1: 'en_construccion', 2: 'establecimiento', 3: 'multivivienda', 4: 'terreno_baldio'}\n",
    "model_class=alexnet1(weights=weights,num_classes=num_classes,idx_to_class=diciconario)\n",
    "# num_classes=6\n",
    "# diciconario={0: 'carros', 1: 'casas', 2: 'en_construccion', 3: 'establecimiento', 4: 'multivivienda', 5: 'terreno_baldio'}\n",
    "# model_class=alexnet(weights=weights,num_classes=num_classes,idx_to_class=diciconario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test clasificador sobre archivo\n",
    "# file=r\"D:\\alexnet\\train_pad\\en_construccion\\Copia de Huixqui_1.PNG\"\n",
    "# print(model_class.predict_file(file,pad=True))\n",
    "# ##test clasificador sobre imagen precargada\n",
    "# image=cv2.imread(file)\n",
    "# print(model_class.predict_image(image,pad=True)[0])\n",
    "# cv2_imshow(\"a\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch #or pytorch, works for the same shit and contains the same libraries that you need such as Numpy (as far as I know)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# y_true = []\n",
    "# y_predict =[]\n",
    "# import glob\n",
    "# filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\train_pad/*/*\")\n",
    "# for file in tqdm.tqdm(filenames):\n",
    "#     file=file.replace(\"\\\\\",\"/\")\n",
    "#     y_true.append(file.split(\"/\")[-2])\n",
    "#     y_predict.append(model_class.predict_file(file,pad=False))\n",
    "# labels=[]\n",
    "# for k,v in diciconario.items():\n",
    "#     labels.append(v)\n",
    "# labels\n",
    "# confusion_mat = confusion_matrix(y_true, y_predict,labels=labels)\n",
    "# conteos=pd.DataFrame(y_true,columns=[\"clases\"]).value_counts()\n",
    "# conteos=conteos.reset_index(drop=False)\n",
    "# matrix=[]\n",
    "# for i,label in enumerate(labels):\n",
    "#     matrix.append(confusion_mat[i]/conteos[conteos[\"clases\"]==label][0].values[0])\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(matrix)\n",
    "# matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros del raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,\n",
       " 40,\n",
       " 267,\n",
       " CRS.from_epsg(3857),\n",
       " 9817,\n",
       " 10942,\n",
       " -11107755.1928,\n",
       " -11104472.4441,\n",
       " 2246231.7061,\n",
       " 2249176.7781)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster=r\"D:\\otros\\MONCLOVA\\a2.tif\"\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=80)\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimitacion por shape de municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_o=gpd.read_file(r\"C:\\Users\\ASUS\\Documents\\GobiernoEdomex\\Agua\\geoshapes\\Full_manzanas\\Manzana_Lerma.shp\")\n",
    "shape_o=shape_o.to_crs('3857')\n",
    "shape=shape_transform(shape_o.copy())\n",
    "#shape_aumentado=ampliar_shape(shape_o.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_transform(shape):\n",
    "    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n",
    "    c=[]\n",
    "    angulo_manzana=[]\n",
    "\n",
    "    # for manzana in range(len(shape)):\n",
    "    #     proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "    #     angulos=[]\n",
    "    #     d=[]\n",
    "    #     poly=pd.DataFrame(proyecciones1[0])\n",
    "    #     for point in range(1,len(poly)):\n",
    "    #         d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n",
    "    #         angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n",
    "    #     angulo_manzana.append(angulos[d.index(max(d))])\n",
    "    shape[\"angulo_manzana\"]=0\n",
    "    shape[\"geometry\"]=shape[\"geometry\"].envelope\n",
    "    for manzana in range(len(shape)):\n",
    "        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "        proyecciones=proyecciones1[0]\n",
    "        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "        min_y,min_x=point1[0],point1[1]\n",
    "        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "        max_y,max_x=point2[0],point2[1]\n",
    "        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n",
    "    shape1=pd.DataFrame()\n",
    "    shape1['points']=c\n",
    "    shape1=shape1['points'].str.split(',',expand=True)\n",
    "    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n",
    "    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n",
    "    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n",
    "    shape=shape1\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre raster(municipio) con salida en shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres=[]\n",
    "imshow=False\n",
    "result=pd.DataFrame()\n",
    "casas=[]\n",
    "terreno=[]\n",
    "angulosget=[]\n",
    "conf_casas=[]\n",
    "conf_terreno=[]\n",
    "clase_casas=[]\n",
    "clase_terreno=[]\n",
    "s=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impementar modelos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproceso(Modelo,model_class,casas,conf_casas,clase_casas,terreno,conf_terreno,clase_terreno,raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0,opt_conf_thres=0.2,imshow=False,imsave=False,path=\"C:/Users/ASUS/salida/imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_casas=gpd.GeoDataFrame({\"clase_detectada\":clase_casas,\"conf\":conf_casas},geometry=casas,crs=crs)\n",
    "gdf_casas.set_crs=crs\n",
    "gdf_casas[\"area\"]=gdf_casas.area\n",
    "gdf_casas=gdf_casas.astype({\"conf\":\"float64\"})\n",
    "gdf_casas.to_file(r\"C:/Users/ASUS/salida/shape/ortofoto_casas_nuevomodeloa22_mod4_5_80.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_terreno=gpd.GeoDataFrame({\"clase_detectada\":clase_terreno,\"conf\":conf_terreno},geometry=terreno,crs=crs)\n",
    "gdf_terreno.set_crs=crs\n",
    "gdf_terreno[\"area\"]=gdf_terreno.area\n",
    "gdf_terreno=gdf_terreno.astype({\"conf\":\"float64\"})\n",
    "gdf_terreno.to_file(r\"C:/Users/ASUS/salida/shape/ortofoto_terrenos_nuevomodeloa22_mod4_5_80.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint=torch.load(r'C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint/best_mod11.pth',map_location=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ñ ##breakpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo por manzanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_aumentado=shape_o.copy()\n",
    "shape_aumentado[\"geometry\"]=shape_aumentado[\"geometry\"].envelope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"-11071219.930636004 2196398.621671967 781.7447473723441 397.1567366491072\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,4393194.400080584)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"5.211631649148961\" opacity=\"0.6\" d=\"M -11070737.118998097,2196712.3532977006 L -11070710.325287491,2196679.158447657 L -11070643.69113026,2196654.646556378 L -11070606.364675445,2196622.847160101 L -11070559.170907544,2196584.4743161234 L -11070467.139397793,2196540.9584082845 L -11070471.992062546,2196526.20825438 L -11070528.468075326,2196520.6735035833 L -11070636.028179843,2196509.5941150384 L -11070754.344791744,2196503.853792404 L -11070840.326873956,2196490.057286543 L -11070942.342519669,2196465.3356174664 L -11071055.113935178,2196448.6081637098 L -11071171.32318644,2196427.5751811294 L -11071180.528158227,2196442.56193638 L -11071190.71389073,2196466.066233555 L -11071190.977126842,2196480.7724768887 L -11071180.31334239,2196502.0576372235 L -11071141.885321656,2196518.3837627885 L -11071115.023783265,2196524.463757174 L -11071102.514695523,2196538.3785538077 L -11071107.668270146,2196552.4420872536 L -11071154.979848549,2196602.175513464 L -11071164.642597845,2196628.793562486 L -11071163.80250204,2196639.984785655 L -11071155.83933073,2196652.7683017543 L -11071117.48855085,2196697.739256649 L -11071095.554301936,2196721.498267997 L -11071082.969068954,2196729.137347936 L -11071058.155247528,2196732.3231616956 L -11071035.701572113,2196753.615238641 L -11071023.536632352,2196760.2044930523 L -11070986.46464208,2196764.7369163358 L -11070980.69897218,2196766.824899454 L -11070944.233413575,2196751.0046805535 L -11070850.145631948,2196742.8893951112 L -11070797.088619053,2196724.735635494 L -11070759.250137938,2196715.3732241113 L -11070737.118998097,2196712.3532977006 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x1e053edceb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_o[\"geometry\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(raster) as scr:\n",
    "    for s in (range(len(shape_aumentado))):\n",
    "        print(str(s)+\" de \"+str(len(shape_aumentado)))\n",
    "        nombres=[]\n",
    "        result=pd.DataFrame()\n",
    "        casas=[]\n",
    "        terreno=[]\n",
    "        angulosget=[]\n",
    "        conf_casas=[]\n",
    "        conf_terreno=[]\n",
    "        clase_casas=[]\n",
    "        clase_terreno=[]\n",
    "        shapes=[shape_aumentado['geometry'][s]]\n",
    "        manzana,out_transform = rasterio.mask.mask(scr, shapes, crop=True)\n",
    "        out_meta = scr.meta\n",
    "        out_meta.update({'driver': 'GTiff',\n",
    "        'height': manzana.shape[1],\n",
    "        'width': manzana.shape[2],\n",
    "        'transform': out_transform})\n",
    "        output_file = r'D:/neza/manzana.tif'#+str(shape['cve_cat'][s])+'.tif'\n",
    "        with rasterio.open(output_file, 'w', **out_meta) as dest:\n",
    "            dest.write(manzana)\n",
    "        cve_cat=shape[\"cve_cat\"][s]\n",
    "        print(cve_cat)\n",
    "        alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(r\"D:\\neza\\manzana.tif\",metros=80)\n",
    "        postproceso(Modelo,model_class,casas,conf_casas,clase_casas,terreno,conf_terreno,clase_terreno,raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0,opt_conf_thres=0.1,imshow=False,imsave=False,path=\"C:/Users/ASUS/salida/imagen\")\n",
    "#         postproceso(raster,ancho,alto,dim,angulo_get=shape['angulo_manzana'][s],opt_conf_thres=0.05)\n",
    "        polygon=shape_o[shape_o['cve_cat']==cve_cat][\"geometry\"].values[0]\n",
    "        gdf_casas=gpd.GeoDataFrame({'conf':conf_casas},geometry=casas,crs=scr.crs)\n",
    "        gdf_casas.set_crs=scr.crs\n",
    "        gdf_casas['area']=gdf_casas.area\n",
    "        gdf_casas=gdf_casas.astype({'conf':'float64'})\n",
    "        gdf_casas[\"cve_cat\"]=cve_cat\n",
    "        indices=[]\n",
    "        for i,point in enumerate(gdf_casas[\"geometry\"].centroid):\n",
    "            if polygon.contains(point)==True:\n",
    "                indices.append(i)\n",
    "        gdf_casas=gdf_casas.iloc[indices].reset_index(drop=True)\n",
    "        gdf_casas[\"centroid_x\"]=[int(x/18) for x in gdf_casas.centroid.x]\n",
    "        gdf_casas[\"centroid_y\"]=[int(y/18) for y in gdf_casas.centroid.y]\n",
    "        gdf_casas=gdf_casas.sort_values(by=\"conf\",ascending=False).drop_duplicates([\"centroid_x\",\"centroid_y\"],keep=\"first\")\n",
    "        if s==0:\n",
    "            gdf_casas.to_file(r'C:/Users/ASUS/salida/shape/neza222_new_casas.shp')\n",
    "        else:\n",
    "            \n",
    "            gdf_casas.to_file(r'C:/Users/ASUS/salida/shape/neza222_new_casas.shp',mode=\"a\")\n",
    "        gdf_terreno=gpd.GeoDataFrame({'conf':conf_terreno},geometry=terreno,crs=scr.crs)\n",
    "        gdf_terreno.set_crs=scr.crs\n",
    "        indices=[]\n",
    "        for i,point in enumerate(gdf_terreno[\"geometry\"].centroid):\n",
    "            if polygon.contains(point)==True:\n",
    "                indices.append(i)\n",
    "        gdf_terreno=gdf_terreno.iloc[indices].reset_index(drop=True)\n",
    "        gdf_terreno[\"centroid_x\"]=[int(x/5) for x in gdf_terreno.centroid.x]\n",
    "        gdf_terreno[\"centroid_y\"]=[int(y/5) for y in gdf_terreno.centroid.y]\n",
    "        gdf_terreno=gdf_terreno.sort_values(by=\"conf\",ascending=False).drop_duplicates([\"centroid_x\",\"centroid_y\"],keep=\"first\")\n",
    "        if s==0:\n",
    "            gdf_terreno.to_file(r'C:/Users/ASUS/salida/shape/neza222_new_terreno.shp')\n",
    "        else:\n",
    "            gdf_terreno.to_file(r'C:/Users/ASUS/salida/shape/neza222_new_terreno.shp',mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar imagenes mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path donde se guardan images\n",
    "path_mosaico_salida=r\"D:\\instream\\Mi unidad\\geoshaps\\neza\\images/\"\n",
    "generar_imagenes=int(input(\"Generar imagenes: 1 si, 0 no \"))\n",
    "if generar_imagenes==1:\n",
    "    generar_imagenes_sinrotar=int(input(\"Generar imagenes sin rotar: 1 si, 0 no \"))\n",
    "    generar_imagenes_rotadas=int(input(\"Generar imagenes rotadas: 1 si, 0 no \"))\n",
    "    with tqdm.tqdm(total=alto*ancho) as pbar:\n",
    "        for j in range(0,ancho):#ancho\n",
    "            for i in (range(alto)):#alto\n",
    "                generar=0\n",
    "                label=raster.replace(\"\\\\\",\"/\").split(\"/\")[-1][:-4]+\"_\"\n",
    "                nameimg=label.lower()+str(i)+\"_\"+str(j)\n",
    "                cuadro=[]\n",
    "                for k in range(2):\n",
    "                    for l in range(2):\n",
    "                        cuadro.append((minx+(maxx-minx)/ancho*(j+k),\n",
    "                                       maxy-(maxy-miny)/alto*(i+l),\n",
    "                                       0.0))\n",
    "                cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n",
    "                for punto in cuadro:\n",
    "                    x=float(punto[0])\n",
    "                    y=float(punto[1])\n",
    "                    if len(shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)])>0:\n",
    "                        generar=1             \n",
    "                if generar==1:\n",
    "                    shapes=[{\"type\":'Polygon','coordinates':[cuadro]}]\n",
    "                    array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "                    four_images=[array[2],array[1],array[0]]\n",
    "                    imagen_n = np.stack(four_images, axis=-1)\n",
    "                    if generar_imagenes_sinrotar==1:\n",
    "                        cv2.imwrite(path_mosaico_salida+nameimg+\".png\",imagen_n)\n",
    "                    if generar_imagenes_rotadas==1:\n",
    "                        angulo_1,imagen_ro=correct_orientation(imagen_n,dim)\n",
    "                        cv2.imwrite(path_mosaico_salida+nameimg+\"_\"+str(angulo_1)+\".png\",imagen_ro)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre imagen con salida txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mosaico_salida=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\train\\imagess\"\n",
    "vector=Modelo.detect(opt_source=path_mosaico_salida,opt_conf_thres=0.3)\n",
    "Generar_txt(vector,path_mosaico_salida+\"labels\")\n",
    "with open(path_mosaico_salida+\"labels/classes.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join([\"casa\",\"terreno_baldio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "filenames=glob.glob(\"train/images/*\")\n",
    "# for file in filenames:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(3476,len(filenames))):\n",
    "    file=filenames[i]\n",
    "    imagen_n=cv2.imread(file)\n",
    "    # assert imagen_n is not None,  \"file could not be read, check with os.path.exists()\"\n",
    "    try:\n",
    "        imagen_n=cv2.resize(imagen_n,(256,256))\n",
    "    except:\n",
    "        continue\n",
    "    dim=imagen_n.shape[0]\n",
    "    angulo=correct_orientation(imagen_n,dim=dim)[0]\n",
    "    image_ro=imagen_n.copy()\n",
    "    image_ro=rotate_image(image_ro,angulo,reshape=True)\n",
    "    image_ro=cv2.resize(image_ro,(256,256))\n",
    "    cv2.imwrite(file.replace(\"images\",\"imagess\"),image_ro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shape igecem de manzanas por municipio (solo pora tener la delimitacion geografica del municipio)\n",
    "shape=gpd.read_file(r\"C:\\Users\\ASUS\\Documents\\GobiernoEdomex\\Agua\\geoshapes\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape=shape.to_crs(\"3857\")\n",
    "c=[]\n",
    "for manzana in range(len(shape)):\n",
    "    proyecciones1=mapping(shape[\"geometry\"][manzana]).get(\"coordinates\")\n",
    "    if len(proyecciones1)>1:\n",
    "        for manzan in proyecciones1:\n",
    "            print(manzana)\n",
    "            try:\n",
    "                proyecciones=manzan\n",
    "            except:\n",
    "                proyecciones=manzan[0]\n",
    "            point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "            min_y,min_x=point1[0],point1[1]\n",
    "            point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "            max_y,max_x=point2[0],point2[1]\n",
    "            c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones\n",
    "    else:\n",
    "        proyecciones=proyecciones1[0]\n",
    "        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "        min_y,min_x=point1[0],point1[1]\n",
    "        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "        max_y,max_x=point2[0],point2[1]\n",
    "        c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones    \n",
    "    \n",
    "    # point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "    # min_y,min_x=point1[0],point1[1]\n",
    "    # point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "    # max_y,max_x=point2[0],point2[1]\n",
    "    # c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones\n",
    "shape1=pd.DataFrame()\n",
    "shape1[\"points\"]=c\n",
    "shape1=shape1[\"points\"].str.split(\",\",expand=True)\n",
    "shape1=shape1.astype({0:\"float64\",1:\"float64\",2:\"float64\",3:\"float64\"})\n",
    "shape=shape1\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "geo=[]\n",
    "shape=gpd.read_file(r\"C:\\Users\\ASUS\\Documents\\GobiernoEdomex\\Agua\\geoshapes\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape=shape.to_crs(\"3857\")\n",
    "c=[]\n",
    "for manzana in range(len(shape)):\n",
    "    proyecciones1=mapping(shape[\"geometry\"][manzana]).get(\"coordinates\")\n",
    "    for i in proyecciones1[0]:\n",
    "        geo.append(Point(i))\n",
    "sa=gpd.GeoDataFrame(geometry=geo)\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.to_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\pointnau.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.sjoin(shape,shape1 , how='left', op='intersects').to_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\sol.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\new_terreno1.shp\")z\n",
    "shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[]\n",
    "for i,pol in enumerate(shape1[\"geometry\"]):\n",
    "    generar=0\n",
    "    cuadro=mapping(pol).get(\"coordinates\")[0]\n",
    "    for punto in cuadro:\n",
    "            x=float(punto[0])\n",
    "            y=float(punto[1])\n",
    "            if len(shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)])>0:\n",
    "                generar=1             \n",
    "    if generar==1:\n",
    "         indices.append(i)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1.loc[indices].to_file(r\"C:\\Users\\ASUS\\Desktop\\nau/solo_naucalpan.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.sjoin(shape,shape1 , how='inner', op='intersects').to_file(r\"C:\\Users\\ASUS\\Desktop\\nau/sol.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_polys = [polygon for polygon in  if (polygon.centroid.x**2 + polygon.centroid.y**2 < 4**2)]\n",
    "\n",
    "complete_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "with rasterio.open(r\"D:\\haar\\classes\\carros.tif\") as src:\n",
    "\n",
    "    # The size in pixels of your desired window\n",
    "    xsize, ysize = 1000,1000\n",
    "\n",
    "    # Generate a random window origin (upper left) that ensures the window \n",
    "    # doesn't go outside the image. i.e. origin can only be between \n",
    "    # 0 and image width or height less the window width or height\n",
    "    xmin, xmax = 0, src.width - xsize\n",
    "    ymin, ymax = 0, src.height - ysize\n",
    "    xoff, yoff = random.randint(xmin, xmax), random.randint(ymin, ymax)\n",
    "\n",
    "    # Create a Window and calculate the transform from the source dataset    \n",
    "    window = Window(0, 0, xsize, ysize)\n",
    "    transform = src.window_transform(window)\n",
    "\n",
    "    # Create a new cropped raster to write to\n",
    "    profile = src.profile\n",
    "    profile.update({\n",
    "        'height': xsize,\n",
    "        'width': ysize,\n",
    "        'transform': transform})\n",
    "\n",
    "    with rasterio.open('D:/haar/classes/carros_output.tif', 'w', **profile) as dst:\n",
    "        # Read the data from the window and write it to the output raster\n",
    "        dst.write(src.read(window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "shape_o=gpd.read_file(r\"D:\\alexnet\\carros.shp\")\n",
    "shape_o=shape_o.to_crs('3857')\n",
    "# shape=shape_transform(shape_o.copy())\n",
    "shape_aumentado=ampliar_shape(shape_o.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_aumentado.to_file(r\"D:\\alexnet\\carros1.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping,Polygon\n",
    "src_raster_path = r\"C:\\Users\\ASUS\\Desktop\\presentacionyolov7\\etiquetas_google1\\neza.tif\"\n",
    "src=rasterio.open(src_raster_path)\n",
    "H,W=src.shape\n",
    "terrenos=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\presentacionyolov7\\vero 2\\vero\\vero1.shp\")\n",
    "terrenos=terrenos.set_crs(3857)\n",
    "terrenos=terrenos.to_crs(3857)\n",
    "terrenos=ampliar_shape(terrenos,factor_ampliacion=1.25)\n",
    "import tqdm\n",
    "import cv2\n",
    "for i,polygo in tqdm.tqdm(enumerate(terrenos[\"geometry\"]),total=len(terrenos)):\n",
    "    det=\"a\"\n",
    "    try:\n",
    "        shapes=[mapping(polygo)]\n",
    "    except:\n",
    "        continue\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    four_images=[array[2],array[1],array[0]]\n",
    "    stacked_images = np.stack(four_images, axis=-1)\n",
    "    cv2.imwrite(r\"D:\\alexnet\\train/\"+terrenos.loc[i,\"clase_dete\"]+\"4anew_\"+str(i)+\".png\",stacked_images)\n",
    "    # cv2.imshow(\"s\",stacked_images)\n",
    "    # k=cv2.waitKey(0) & 0xFF\n",
    "    # if k==ord(\"a\"):\n",
    "    #     det=\"casa_\"\n",
    "    # elif k==ord(\"s\"):\n",
    "    #     det=\"carros_\"\n",
    "    # elif k==ord(\"d\"):\n",
    "    #     det=\"establecimiento_\"\n",
    "    # elif k==ord(\"f\"):\n",
    "    #     det=\"multivivienda_\"\n",
    "    # elif k==ord(\"g\"):\n",
    "    #     det=\"encontruccion_\"\n",
    "    # elif k==ord(\"h\"):\n",
    "    #     det=\"terreno_\"\n",
    "    # elif k<28:\n",
    "    #     cv2.destroyAllWindows()\n",
    "    #     break\n",
    "    cv2.imwrite(r\"D:\\alexnet\\train/\"+terrenos.loc[i,\"clase_dete\"]+\"4anew_\"+str(i)+\".png\",stacked_images)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampliar_shape(shape,factor_ampliacion=2):\n",
    "    \"\"\"Amplifica el polygon de cada manzana con el fin de extrar imagenes sin perder informacion de la manzana\"\"\"\n",
    "    shape[\"geometry\"]=shape[\"geometry\"]\n",
    "    shape['centroid']=shape.centroid\n",
    "    geometry=[]\n",
    "    clase=[]\n",
    "    for i,polygon in enumerate(shape['geometry']):\n",
    "        try:\n",
    "            point=mapping(shape['centroid'][i]).get('coordinates')\n",
    "        except:\n",
    "            continue\n",
    "        x=point[0]\n",
    "        y=point[1]\n",
    "        go=[]\n",
    "        coodinates=mapping(polygon).get('coordinates')[0]\n",
    "        for a in coodinates:\n",
    "            x1=a[0]\n",
    "            y1=a[1]\n",
    "            x2=x+(x1-x)*factor_ampliacion\n",
    "            y2=y+(y1-y)*factor_ampliacion\n",
    "            go.append((x2,y2))\n",
    "        geometry.append(Polygon(go))\n",
    "        clase.append(shape.loc[i,\"clase_dete\"])\n",
    "    return gpd.GeoDataFrame({\"clase_dete\":clase},geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
