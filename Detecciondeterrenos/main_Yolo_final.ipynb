{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "from rasterio.windows import Window\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "# sys.path.append(r'C:\\Users\\ruben\\Desktop\\GEM\\geoloc2\\Detecciondeterrenos')\n",
    "from codigos import Generar_txt\n",
    "###path de yolo dentro de computadora\n",
    "# os.chdir(r'C:\\Users\\ruben\\yolov7')\n",
    "# from detect_Alberto_v4 import *\n",
    "from scipy.ndimage import rotate as rotate_image\n",
    "from shapely import geometry\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "from clasificacion_chinchetas import *\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "from shapely import geometry\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de deteccion de objetos basado en yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelo=modelo(weights=r\"C:\\Users\\ruben\\yolov7\\Modelos\\best_Chinchetas_Alberto.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo clasificador basado en Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alexnet1():\n",
    "    def __init__(self,weights,num_classes,idx_to_class):\n",
    "        \"\"\"inicializa el model, con los pesos entrenados\"\"\"\n",
    "        alexnet=models.alexnet(pretrained=True)\n",
    "        self.device = torch.device(0 if torch.cuda.is_available() else \"cpu\")\n",
    "        checkpoint=torch.load(weights,map_location=self.device)\n",
    "#         alexnet.features[1]= nn.Hardtanh()\n",
    "#         alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "#         alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        # alexnet\n",
    "        alexnet.features[1]= nn.Hardtanh()\n",
    "        alexnet.classifier[6] = nn.Linear(4096, 4096)\n",
    "        alexnet.classifier.add_module(\"7\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"8\", nn.Linear(4096, 4096))\n",
    "        alexnet.classifier.add_module(\"9\",nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"10\", nn.Linear(4096, 2048))\n",
    "        alexnet.classifier.add_module(\"11\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"12\", nn.Linear(2048, num_classes))\n",
    "        alexnet.classifier.add_module(\"13\", nn.Softplus())\n",
    "        alexnet.classifier.add_module(\"14\",  nn.LogSoftmax(dim = 1))\n",
    "        # for param in alexnet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "        # alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
    "        alexnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "        summary(alexnet, (3, 224, 224))\n",
    "        self.model=alexnet\n",
    "        self.idx_to_class=idx_to_class\n",
    "    \n",
    "    def predict_file(self,file,pad=True):\n",
    "        \"\"\"Genera prediccion sobre archivo\"\"\"\n",
    "#         x = Image.open(file)\n",
    "#         x = np.asarray(x)\n",
    "#         x=np.stack([x[:,:,0],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=cv2.imread(file)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase \n",
    "    \n",
    "    def predict_image(self,image,pad=True):\n",
    "        \"\"\"Generar predeccion de clase sobre imagen precargada\"\"\"\n",
    "#         x = np.asarray(image)\n",
    "#         x=np.stack([x[:,:,2],x[:,:,1],x[:,:,2]], axis=-1)\n",
    "        x=np.array(image)\n",
    "        if pad:\n",
    "            x=padding(x)\n",
    "        imagen=x.copy()\n",
    "        x=cv2.resize(x,(224,224))\n",
    "        x=x.astype(\"float32\")\n",
    "        x=x/255*2-1\n",
    "        x=np.moveaxis(x,-1,0)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(x).to(self.device)\n",
    "            res=list(self.model(img).cpu().detach().numpy()[0])\n",
    "            indice=res.index(max(res))\n",
    "            clase=self.idx_to_class.get(indice)\n",
    "        return clase, imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint\\5clases\\best_modconstrucciones_2.pth\"\n",
    "num_classes=5\n",
    "diciconario={0: 'casas', 1: 'en_construccion', 2: 'establecimiento', 3: 'multivivienda', 4: 'terreno_baldio'}\n",
    "model_class=alexnet1(weights=weights,num_classes=num_classes,idx_to_class=diciconario)\n",
    "# num_classes=6\n",
    "# diciconario={0: 'carros', 1: 'casas', 2: 'en_construccion', 3: 'establecimiento', 4: 'multivivienda', 5: 'terreno_baldio'}\n",
    "# model_class=alexnet(weights=weights,num_classes=num_classes,idx_to_class=diciconario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test clasificador sobre archivo\n",
    "file=r\"D:\\alexnet\\train_pad\\en_construccion\\Copia de Huixqui_1.PNG\"\n",
    "print(model_class.predict_file(file,pad=True))\n",
    "##test clasificador sobre imagen precargada\n",
    "image=cv2.imread(file)\n",
    "print(model_class.predict_image(image,pad=True)[0])\n",
    "cv2_imshow(\"a\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch #or pytorch, works for the same shit and contains the same libraries that you need such as Numpy (as far as I know)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# y_true = []\n",
    "# y_predict =[]\n",
    "# import glob\n",
    "# filenames=glob.glob(r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\train_pad/*/*\")\n",
    "# for file in tqdm.tqdm(filenames):\n",
    "#     file=file.replace(\"\\\\\",\"/\")\n",
    "#     y_true.append(file.split(\"/\")[-2])\n",
    "#     y_predict.append(model_class.predict_file(file,pad=False))\n",
    "# labels=[]\n",
    "# for k,v in diciconario.items():\n",
    "#     labels.append(v)\n",
    "# labels\n",
    "# confusion_mat = confusion_matrix(y_true, y_predict,labels=labels)\n",
    "# conteos=pd.DataFrame(y_true,columns=[\"clases\"]).value_counts()\n",
    "# conteos=conteos.reset_index(drop=False)\n",
    "# matrix=[]\n",
    "# for i,label in enumerate(labels):\n",
    "#     matrix.append(confusion_mat[i]/conteos[conteos[\"clases\"]==label][0].values[0])\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(matrix)\n",
    "# matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros del raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 12,\n",
       " 94,\n",
       " CRS.from_epsg(3857),\n",
       " 1199,\n",
       " 1196,\n",
       " -11105766.042973932,\n",
       " -11104489.368700342,\n",
       " 2247276.633907954,\n",
       " 2248556.5105417613)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detect_Alberto_v4 import Parametro_raster\n",
    "raster=r\"C:\\Users\\dlara\\Downloads\\MODELO_3D_SANTIAGO_ESTE_falta_georeferenciado_modified.tif\"\n",
    "\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=100)\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimitacion por shape de municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_o=gpd.read_file(r'C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Full manzanas\\Manzana_Naucalpan.shp')\n",
    "shape_o = gpd.read_file(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape_o=shape_o.to_crs('3857')\n",
    "shape=shape_transform(shape_o.copy())\n",
    "#shape_aumentado=ampliar_shape(shape_o.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_transform(shape):\n",
    "    \"\"\"Convierte el shape en dataframe de coordenadas que engloba el polygon del shape para delimitar el raster\"\"\"\n",
    "    c=[]\n",
    "    angulo_manzana=[]\n",
    "\n",
    "    # for manzana in range(len(shape)):\n",
    "    #     proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "    #     angulos=[]\n",
    "    #     d=[]\n",
    "    #     poly=pd.DataFrame(proyecciones1[0])\n",
    "    #     for point in range(1,len(poly)):\n",
    "    #         d.append(((poly[1][point]-poly[1][point-1])**2+(poly[0][point]-poly[0][point-1])**2))\n",
    "    #         angulos.append(math.atan(((poly[1][point]-poly[1][point-1])/(poly[0][point]-poly[0][point-1])))*180/math.pi)\n",
    "    #     angulo_manzana.append(angulos[d.index(max(d))])\n",
    "    shape[\"angulo_manzana\"]=0\n",
    "    shape[\"geometry\"]=shape[\"geometry\"].envelope\n",
    "    for manzana in range(len(shape)):\n",
    "        proyecciones1=mapping(shape['geometry'][manzana]).get('coordinates')\n",
    "        proyecciones=proyecciones1[0]\n",
    "        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "        min_y,min_x=point1[0],point1[1]\n",
    "        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "        max_y,max_x=point2[0],point2[1]\n",
    "        c.append(','.join([str(min_y),str(min_x),str(max_y),str(max_x)]))\n",
    "    shape1=pd.DataFrame()\n",
    "    shape1['points']=c\n",
    "    shape1=shape1['points'].str.split(',',expand=True)\n",
    "    shape1=shape1.astype({0:'float64',1:'float64',2:'float64',3:'float64'})\n",
    "    shape1[\"cve_cat\"]=shape[\"cve_cat\"]\n",
    "    shape1[\"angulo_manzana\"]=shape[\"angulo_manzana\"]\n",
    "    shape=shape1\n",
    "    return shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre raster(municipio) con salida en shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No borrar path compañeros\n",
    "\n",
    "path_ruben = r'C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Bases\\Plantillas'\n",
    "path_hector = '/home/hector/Documentos/Infis/Geo/Data/Plantillas'\n",
    "dict_gris = get_dict_plantilla_gris(path_ruben,True,(30,30))\n",
    "\n",
    "\n",
    "nombres=[]\n",
    "imshow=False\n",
    "result=pd.DataFrame()\n",
    "casas=[]\n",
    "terreno=[]\n",
    "angulosget=[]\n",
    "conf_casas=[]\n",
    "conf_terreno=[]\n",
    "clase_casas=[]\n",
    "clase_terreno=[]\n",
    "clase_chinchetas=[]\n",
    "umbrales=[]\n",
    "sizes=[]\n",
    "s=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementar modelos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproceso(Modelo,'model_class',casas,conf_casas,\n",
    "            clase_casas,terreno,conf_terreno,clase_terreno,\n",
    "            clase_chinchetas, umbrales,sizes,\n",
    "            raster,ancho,alto,dim,minx,maxx,miny,maxy,shape,angulo_get=0.000001,\n",
    "            opt_conf_thres=0.2,imshow=False,imsave=False,path=\"C:/Users/ASUS/salida/imagen\",\n",
    "            clasificar_casas=False, clasificar_chinchetas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_casas=gpd.GeoDataFrame({\"clase_detectada\":clase_casas,\"conf\":conf_casas},geometry=casas,crs=3857)\n",
    "gdf_casas.set_crs=crs\n",
    "gdf_casas[\"area\"]=gdf_casas.area\n",
    "gdf_casas=gdf_casas.astype({\"conf\":\"float64\"})\n",
    "gdf_casas.to_file(r\"C:\\Users\\ruben\\Desktop\\GEM\\Geo\\Salidas\\Chinchetas\\Chinchetas_Naucalpan_yolo.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_terreno=gpd.GeoDataFrame({\"clase_detectada\":clase_terreno,\"conf\":conf_terreno},geometry=terreno,crs=crs)\n",
    "gdf_terreno.set_crs=crs\n",
    "gdf_terreno[\"area\"]=gdf_terreno.area\n",
    "gdf_terreno=gdf_terreno.astype({\"conf\":\"float64\"})\n",
    "gdf_terreno.to_file(r\"C:/Users/ASUS/salida/shape/ortofoto_terrenos_nuevomodeloa22_mod4_5_80.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint=torch.load(r'C:\\Users\\ASUS\\Inteligencia_Artificial\\clasificador\\ckpoint/best_mod11.pth',map_location=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterio.open(raster).meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ñ ##breakpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar imagenes mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = rasterio.open(raster)\n",
    "shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cuadro(alto,ancho,j,i):\n",
    "    cuadro=[]\n",
    "    for k in range(2):\n",
    "        for l in range(2):\n",
    "            cuadro.append((minx+(maxx-minx)/ancho*(j+k),\n",
    "                            maxy-(maxy-miny)/alto*(i+l)))\n",
    "    cuadro=[cuadro[0],cuadro[1],cuadro[3],cuadro[2],cuadro[0]]\n",
    "    for punto in cuadro:\n",
    "        x=float(punto[0])\n",
    "        y=float(punto[1])\n",
    "    return(cuadro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "def normalizar_array(img):\n",
    "    \n",
    "    return (img-np.min(img))/(np.max(img)-np.min(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 100/144 [01:20<00:35,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path donde se guardan images\n",
    "import tqdm as tqdm\n",
    "from detect_Alberto_v4 import Parametro_raster\n",
    "import numpy as np\n",
    "\n",
    "path_mosaico_input=r\"E:\\ORTOFOTOS\\Mosaicos_input\"\n",
    "path_mosaico_output=r\"E:\\ORTOFOTOS\\Mosaicos_output\"\n",
    "raster=r\"E:\\ORTOFOTOS\\folder\\corte_ESTE_ATLACOMULCO_1_satellite.tif\"\n",
    "raster2=r\"E:\\ORTOFOTOS\\folder\\corte_ESTE_ATALCOMULCO_0.tif\"\n",
    "alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster,metros=100)\n",
    "# alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy\n",
    "src = rasterio.open(raster)\n",
    "print(src.crs)\n",
    "src.meta.update(nodata=-3000)\n",
    "generar_imagenes=int(input(\"Generar imagenes: 1 si, 0 no \"))\n",
    "if generar_imagenes==1:\n",
    "    generar_imagenes_sinrotar=int(input(\"Generar imagenes sin rotar: 1 si, 0 no \"))\n",
    "    generar_imagenes_rotadas=int(input(\"Generar imagenes rotadas: 1 si, 0 no \"))\n",
    "    with tqdm.tqdm(total=alto*ancho) as pbar:\n",
    "        for j in range(1,ancho-1):#ancho\n",
    "            for i in (range(1,alto-1)):#alto\n",
    "                generar=0\n",
    "                label=raster.replace(\"\\\\\",\"/\").split(\"/\")[-1][:-4]+\"_\"\n",
    "                nameimg=label.lower()+str(i)+\"_\"+str(j)\n",
    "                cuadro= create_cuadro(alto,ancho,j,i)\n",
    "                    # if len(shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)])>0:\n",
    "                    #     generar=1             \n",
    "                # if generar==1:\n",
    "                shapes=[{\"type\":'Polygon','coordinates':[cuadro]}]\n",
    "                array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "                four_images=[array[2],array[1],array[0]]\n",
    "                # bin_image= [array]\n",
    "                \n",
    "                imagen_n = np.stack(four_images, axis=-1)\n",
    "                # imagen_n = array[0]\n",
    "                if generar_imagenes_sinrotar==1:\n",
    "                    src2 = rasterio.open(raster2)\n",
    "                    # src2.meta.update(nodata=0)\n",
    "                    alto,ancho,dim,crs,H,W,minx,maxx,miny,maxy=Parametro_raster(raster2,metros=100)\n",
    "                    cuadro2= create_cuadro(alto,ancho,j,i)\n",
    "                    shapes2=[{\"type\":'Polygon','coordinates':[cuadro2]}]\n",
    "                    array2, out_transform2 = rasterio.mask.mask(src2, shapes2, crop=True)\n",
    "                    # four_images=[array2[2],array2[1],array2[0]]\n",
    "                    # array2_0=normalizar_array(array2[0])\n",
    "                    # array2_0=array2[0][array2[0]==0]\n",
    "                    # array2_1=normalizar_array(array2[0][array2[0]!=0])\n",
    "                    # array_f=np.stack([array2_0,array2_1], axis=0)\n",
    "                    img=array2[0]\n",
    "                    if np.sum(img)>10:\n",
    "                        mini=np.min(img[img!=0])\n",
    "                        img[img==0]=mini\n",
    "                        imagen_n2=normalizar_array(img)\n",
    "                        imagen_n2= np.array(imagen_n2*255, dtype='uint8')\n",
    "                        imagen_n2=np.stack([imagen_n2,imagen_n2,imagen_n2],axis=-1)\n",
    "                        # imagen_n2 = array2[0]array_f\n",
    "                        cv2.imwrite(path_mosaico_input+\"\\\\\"+nameimg+\".png\",imagen_n)\n",
    "                        \n",
    "                        cv2.imwrite(path_mosaico_output+\"\\\\\"+nameimg+\".png\",imagen_n2)\n",
    "                    else:\n",
    "                        continue\n",
    "                if generar_imagenes_rotadas==1:\n",
    "                    angulo_1,imagen_ro=correct_orientation(imagen_n,dim)\n",
    "                    cv2.imwrite(path_mosaico_salida+nameimg+\"_\"+str(angulo_1)+\".png\",imagen_ro)\n",
    "                clear_output(wait=True)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts=glob.glob(\"E:\\ORTOFOTOS\\Mosaicos_input\\*.png\")\n",
    "fotos=glob.glob(\"E:\\ORTOFOTOS\\Mosaicos_output\\*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:00<00:00, 189510.75it/s]\n"
     ]
    }
   ],
   "source": [
    "all_txt = []\n",
    "all_pngs = []\n",
    "for txt in tqdm.tqdm(txts):\n",
    "    name_txt = str(txt).replace(\"\\\\\",\"/\").split(\"/\")[-1].split('.')[0]\n",
    "    all_txt.append(name_txt)\n",
    "\n",
    "for foto in all_txt:\n",
    "    name_foto = str(foto).replace(\"\\\\\",\"/\").split(\"/\")[-1].split('.')[0]\n",
    "    all_pngs.append(name_foto)\n",
    "    if foto in all_pngs:\n",
    "        continue\n",
    "    else:\n",
    "        for s in all_pngs: \n",
    "            if (foto not in s):\n",
    "                print(s,'Borrar foto')\n",
    "                path= r'E:/ORTOFOTOS/Mosaicos_output/'+str(s)+'.png'\n",
    "                os.remove(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar prediccion sobre imagen con salida txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mosaico_salida=r\"C:\\Users\\ASUS\\Inteligencia_Artificial\\yolov7\\train\\imagess\"\n",
    "vector=Modelo.detect(opt_source=path_mosaico_salida,opt_conf_thres=0.3)\n",
    "Generar_txt(vector,path_mosaico_salida+\"labels\")\n",
    "with open(path_mosaico_salida+\"labels/classes.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join([\"casa\",\"terreno_baldio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "filenames=glob.glob(\"train/images/*\")\n",
    "# for file in filenames:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(3476,len(filenames))):\n",
    "    file=filenames[i]\n",
    "    imagen_n=cv2.imread(file)\n",
    "    # assert imagen_n is not None,  \"file could not be read, check with os.path.exists()\"\n",
    "    try:\n",
    "        imagen_n=cv2.resize(imagen_n,(256,256))\n",
    "    except:\n",
    "        continue\n",
    "    dim=imagen_n.shape[0]\n",
    "    angulo=correct_orientation(imagen_n,dim=dim)[0]\n",
    "    image_ro=imagen_n.copy()\n",
    "    image_ro=rotate_image(image_ro,angulo,reshape=True)\n",
    "    image_ro=cv2.resize(image_ro,(256,256))\n",
    "    cv2.imwrite(file.replace(\"images\",\"imagess\"),image_ro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shape igecem de manzanas por municipio (solo pora tener la delimitacion geografica del municipio)\n",
    "shape=gpd.read_file(r\"C:\\Users\\ASUS\\Documents\\GobiernoEdomex\\Agua\\geoshapes\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape=shape.to_crs(\"3857\")\n",
    "c=[]\n",
    "for manzana in range(len(shape)):\n",
    "    proyecciones1=mapping(shape[\"geometry\"][manzana]).get(\"coordinates\")\n",
    "    if len(proyecciones1)>1:\n",
    "        for manzan in proyecciones1:\n",
    "            print(manzana)\n",
    "            try:\n",
    "                proyecciones=manzan\n",
    "            except:\n",
    "                proyecciones=manzan[0]\n",
    "            point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "            min_y,min_x=point1[0],point1[1]\n",
    "            point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "            max_y,max_x=point2[0],point2[1]\n",
    "            c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones\n",
    "    else:\n",
    "        proyecciones=proyecciones1[0]\n",
    "        point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "        min_y,min_x=point1[0],point1[1]\n",
    "        point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "        max_y,max_x=point2[0],point2[1]\n",
    "        c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones    \n",
    "    \n",
    "    # point1=np.min((proyecciones,proyecciones),axis=1)[0]\n",
    "    # min_y,min_x=point1[0],point1[1]\n",
    "    # point2=np.max((proyecciones,proyecciones),axis=1)[0]\n",
    "    # max_y,max_x=point2[0],point2[1]\n",
    "    # c.append(\",\".join([str(min_y),str(min_x),str(max_y),str(max_x)]))#,proyecciones\n",
    "shape1=pd.DataFrame()\n",
    "shape1[\"points\"]=c\n",
    "shape1=shape1[\"points\"].str.split(\",\",expand=True)\n",
    "shape1=shape1.astype({0:\"float64\",1:\"float64\",2:\"float64\",3:\"float64\"})\n",
    "shape=shape1\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "geo=[]\n",
    "shape=gpd.read_file(r\"C:\\Users\\ASUS\\Documents\\GobiernoEdomex\\Agua\\geoshapes\\Full manzanas\\Manzana_Naucalpan.shp\")\n",
    "shape=shape.to_crs(\"3857\")\n",
    "c=[]\n",
    "for manzana in range(len(shape)):\n",
    "    proyecciones1=mapping(shape[\"geometry\"][manzana]).get(\"coordinates\")\n",
    "    for i in proyecciones1[0]:\n",
    "        geo.append(Point(i))\n",
    "sa=gpd.GeoDataFrame(geometry=geo)\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.to_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\pointnau.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.sjoin(shape,shape1 , how='left', op='intersects').to_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\sol.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\nau\\new_terreno1.shp\")z\n",
    "shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[]\n",
    "for i,pol in enumerate(shape1[\"geometry\"]):\n",
    "    generar=0\n",
    "    cuadro=mapping(pol).get(\"coordinates\")[0]\n",
    "    for punto in cuadro:\n",
    "            x=float(punto[0])\n",
    "            y=float(punto[1])\n",
    "            if len(shape[(shape[0]<=x)&(shape[2]>=x)&(shape[1]<=y)&(shape[3]>=y)])>0:\n",
    "                generar=1             \n",
    "    if generar==1:\n",
    "         indices.append(i)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1.loc[indices].to_file(r\"C:\\Users\\ASUS\\Desktop\\nau/solo_naucalpan.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.sjoin(shape,shape1 , how='inner', op='intersects').to_file(r\"C:\\Users\\ASUS\\Desktop\\nau/sol.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_polys = [polygon for polygon in  if (polygon.centroid.x**2 + polygon.centroid.y**2 < 4**2)]\n",
    "\n",
    "complete_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "with rasterio.open(r\"D:\\haar\\classes\\carros.tif\") as src:\n",
    "\n",
    "    # The size in pixels of your desired window\n",
    "    xsize, ysize = 1000,1000\n",
    "\n",
    "    # Generate a random window origin (upper left) that ensures the window \n",
    "    # doesn't go outside the image. i.e. origin can only be between \n",
    "    # 0 and image width or height less the window width or height\n",
    "    xmin, xmax = 0, src.width - xsize\n",
    "    ymin, ymax = 0, src.height - ysize\n",
    "    xoff, yoff = random.randint(xmin, xmax), random.randint(ymin, ymax)\n",
    "\n",
    "    # Create a Window and calculate the transform from the source dataset    \n",
    "    window = Window(0, 0, xsize, ysize)\n",
    "    transform = src.window_transform(window)\n",
    "\n",
    "    # Create a new cropped raster to write to\n",
    "    profile = src.profile\n",
    "    profile.update({\n",
    "        'height': xsize,\n",
    "        'width': ysize,\n",
    "        'transform': transform})\n",
    "\n",
    "    with rasterio.open('D:/haar/classes/carros_output.tif', 'w', **profile) as dst:\n",
    "        # Read the data from the window and write it to the output raster\n",
    "        dst.write(src.read(window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "shape_o=gpd.read_file(r\"D:\\alexnet\\carros.shp\")\n",
    "shape_o=shape_o.to_crs('3857')\n",
    "# shape=shape_transform(shape_o.copy())\n",
    "shape_aumentado=ampliar_shape(shape_o.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_aumentado.to_file(r\"D:\\alexnet\\carros1.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping,Polygon\n",
    "src_raster_path = r\"C:\\Users\\ASUS\\Desktop\\presentacionyolov7\\etiquetas_google1\\neza.tif\"\n",
    "src=rasterio.open(src_raster_path)\n",
    "H,W=src.shape\n",
    "terrenos=gpd.read_file(r\"C:\\Users\\ASUS\\Desktop\\presentacionyolov7\\vero 2\\vero\\vero1.shp\")\n",
    "terrenos=terrenos.set_crs(3857)\n",
    "terrenos=terrenos.to_crs(3857)\n",
    "terrenos=ampliar_shape(terrenos,factor_ampliacion=1.25)\n",
    "import tqdm\n",
    "import cv2\n",
    "for i,polygo in tqdm.tqdm(enumerate(terrenos[\"geometry\"]),total=len(terrenos)):\n",
    "    det=\"a\"\n",
    "    try:\n",
    "        shapes=[mapping(polygo)]\n",
    "    except:\n",
    "        continue\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    array, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    four_images=[array[2],array[1],array[0]]\n",
    "    stacked_images = np.stack(four_images, axis=-1)\n",
    "    cv2.imwrite(r\"D:\\alexnet\\train/\"+terrenos.loc[i,\"clase_dete\"]+\"4anew_\"+str(i)+\".png\",stacked_images)\n",
    "    # cv2.imshow(\"s\",stacked_images)\n",
    "    # k=cv2.waitKey(0) & 0xFF\n",
    "    # if k==ord(\"a\"):\n",
    "    #     det=\"casa_\"\n",
    "    # elif k==ord(\"s\"):\n",
    "    #     det=\"carros_\"\n",
    "    # elif k==ord(\"d\"):\n",
    "    #     det=\"establecimiento_\"\n",
    "    # elif k==ord(\"f\"):\n",
    "    #     det=\"multivivienda_\"\n",
    "    # elif k==ord(\"g\"):\n",
    "    #     det=\"encontruccion_\"\n",
    "    # elif k==ord(\"h\"):\n",
    "    #     det=\"terreno_\"\n",
    "    # elif k<28:\n",
    "    #     cv2.destroyAllWindows()\n",
    "    #     break\n",
    "    cv2.imwrite(r\"D:\\alexnet\\train/\"+terrenos.loc[i,\"clase_dete\"]+\"4anew_\"+str(i)+\".png\",stacked_images)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampliar_shape(shape,factor_ampliacion=2):\n",
    "    \"\"\"Amplifica el polygon de cada manzana con el fin de extrar imagenes sin perder informacion de la manzana\"\"\"\n",
    "    shape[\"geometry\"]=shape[\"geometry\"]\n",
    "    shape['centroid']=shape.centroid\n",
    "    geometry=[]\n",
    "    clase=[]\n",
    "    for i,polygon in enumerate(shape['geometry']):\n",
    "        try:\n",
    "            point=mapping(shape['centroid'][i]).get('coordinates')\n",
    "        except:\n",
    "            continue\n",
    "        x=point[0]\n",
    "        y=point[1]\n",
    "        go=[]\n",
    "        coodinates=mapping(polygon).get('coordinates')[0]\n",
    "        for a in coodinates:\n",
    "            x1=a[0]\n",
    "            y1=a[1]\n",
    "            x2=x+(x1-x)*factor_ampliacion\n",
    "            y2=y+(y1-y)*factor_ampliacion\n",
    "            go.append((x2,y2))\n",
    "        geometry.append(Polygon(go))\n",
    "        clase.append(shape.loc[i,\"clase_dete\"])\n",
    "    return gpd.GeoDataFrame({\"clase_dete\":clase},geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img = cv2.imread(r\"C:\\Users\\ruben\\Downloads\\prueba2.png\")\n",
    "iter_umbral_fn(img, dict_gris,n=120, salto_n=10,umbral=0.94,min_umbral=0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
